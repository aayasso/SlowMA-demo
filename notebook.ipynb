{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üñºÔ∏è Loading image: /Users/alievanayasso/Documents/SlowMA/2B--glory%20days.jpg\n",
            "   ‚Ä¢ Image size: 534√ó369\n",
            "   ‚Ä¢ Rescaled for fidelity: 1613√ó1115\n",
            "üé® Deep color clustering (k=6,8,10)‚Ä¶ ‚úì (selected k=6)\n",
            "ü™∂ Texture analysis (Gabor pyramid)‚Ä¶ ‚úì\n",
            "üî• Saliency mapping (two-scale)‚Ä¶ ‚úì\n",
            "üìê Composition metrics‚Ä¶ ‚úì\n",
            "üí° Illumination gradients‚Ä¶ ‚úì\n",
            "‚ú® Building composite visualization‚Ä¶ ‚úì\n",
            "üìú Writing curatorial summary‚Ä¶ ‚úì\n",
            "üßæ Saving metrics.json‚Ä¶ ‚úì\n",
            "\n",
            "‚úÖ Deep analysis done in 16.79s (thorough mode)\n",
            "üìÅ Results saved to: /Users/alievanayasso/Documents/SlowMA/2B--glory%20days_analysis\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# High-Fidelity Artwork Analyzer v13.5 (Deep Fidelity)\n",
        "# ==========================================================\n",
        "# Local-only: OpenCV + NumPy + Pillow\n",
        "# Outputs per image:\n",
        "#   /<image>_analysis/\n",
        "#     ‚îú‚îÄ overlay_final_composite.png\n",
        "#     ‚îú‚îÄ curatorial_summary.txt\n",
        "#     ‚îî‚îÄ metrics.json\n",
        "# ==========================================================\n",
        "\n",
        "import os, json, time, textwrap, math\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from math import atan2, degrees\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "def load_rgb(path):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    return np.array(img)\n",
        "\n",
        "def ensure_dir(p): os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def to_uint8(img_f32): \n",
        "    return np.clip(img_f32*255.0, 0, 255).astype(np.uint8)\n",
        "\n",
        "def safe_gamma(img_f32):\n",
        "    m = float(img_f32.mean())\n",
        "    if m < 0.20:\n",
        "        img_f32 = np.power(img_f32, 0.6)   # brighten dark\n",
        "    elif m > 0.85:\n",
        "        img_f32 = np.power(img_f32, 1.2)   # compress bright\n",
        "    return np.clip(img_f32, 0, 1)\n",
        "\n",
        "def resize_min_pixels(img, target_pixels=1_800_000):\n",
        "    H, W = img.shape[:2]\n",
        "    cur = H*W\n",
        "    if cur >= target_pixels:\n",
        "        return img, 1.0\n",
        "    scale = math.sqrt(target_pixels/float(cur))\n",
        "    newW, newH = int(W*scale), int(H*scale)\n",
        "    new = cv2.resize(img, (newW, newH), interpolation=cv2.INTER_CUBIC)\n",
        "    return new, scale\n",
        "\n",
        "# -----------------------------\n",
        "# JSON-safe conversion\n",
        "# -----------------------------\n",
        "def make_json_safe(obj):\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: make_json_safe(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, (list, tuple)):\n",
        "        return [make_json_safe(x) for x in obj]\n",
        "    elif isinstance(obj, (np.generic, np.number)):\n",
        "        return obj.item()\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "# -----------------------------\n",
        "# Legend bars (hue & orientation)\n",
        "# -----------------------------\n",
        "def make_hue_bar(hist, width=420, height=50):\n",
        "    # hist: 36-bin circular hue histogram (0..360)\n",
        "    bar = np.zeros((height, width, 3), np.uint8)\n",
        "    for x in range(width):\n",
        "        h = int((x/width)*179)\n",
        "        rgb = cv2.cvtColor(np.uint8([[[h, 200, 220]]]), cv2.COLOR_HSV2RGB)[0,0]\n",
        "        bar[:, x] = rgb\n",
        "    bins = len(hist)\n",
        "    if bins <= 0: \n",
        "        return bar\n",
        "    bin_w = max(1, width // bins)\n",
        "    norm = hist.astype(np.float32)\n",
        "    if norm.sum() > 0:\n",
        "        norm /= (norm.max() + 1e-6)\n",
        "    for i, v in enumerate(norm):\n",
        "        x1 = i*bin_w\n",
        "        x2 = min(width-1, (i+1)*bin_w-1)\n",
        "        h_px = int(v*(height-10))\n",
        "        cv2.rectangle(bar, (x1, height-1), (x2, height-1-h_px), (0,0,0), -1)\n",
        "    return bar\n",
        "\n",
        "def make_orientation_bar(angles, energies, width=420, height=50):\n",
        "    bar = np.full((height, width, 3), 240, np.uint8)\n",
        "    if energies is None or len(energies) == 0:\n",
        "        return bar\n",
        "    e = np.array(energies, dtype=np.float32)\n",
        "    e = (e - e.min())/(e.max()-e.min()+1e-6)\n",
        "    for a, v in zip(angles, e):\n",
        "        x = int((a/180.0)*width)\n",
        "        h_px = int(v*(height-10))\n",
        "        cv2.rectangle(bar, (x-2, height-1), (x+2, height-1-h_px), (60,60,60), -1)\n",
        "    cv2.putText(bar, \"0¬∞\", (5, 18), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n",
        "    cv2.putText(bar, \"90¬∞\", (width//2-15, 18), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n",
        "    cv2.putText(bar, \"180¬∞\", (width-50, 18), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n",
        "    return bar\n",
        "# -----------------------------\n",
        "# CIEDE2000 (pairwise for cluster centers)\n",
        "# -----------------------------\n",
        "def ciede2000(Lab1, Lab2):\n",
        "    L1,a1,b1 = Lab1; L2,a2,b2 = Lab2\n",
        "    C1 = np.sqrt(a1*a1 + b1*b1); C2 = np.sqrt(a2*a2 + b2*b2)\n",
        "    avg_C = (C1 + C2)/2.0\n",
        "    G = 0.5*(1 - np.sqrt((avg_C**7)/((avg_C**7)+25**7)))\n",
        "    a1p, a2p = (1+G)*a1, (1+G)*a2\n",
        "    C1p, C2p = np.sqrt(a1p*a1p + b1*b1), np.sqrt(a2p*a2p + b2*b2)\n",
        "    h1p = (np.degrees(np.arctan2(b1, a1p)) + 360) % 360\n",
        "    h2p = (np.degrees(np.arctan2(b2, a2p)) + 360) % 360\n",
        "    dLp = L2-L1; dCp = C2p-C1p\n",
        "    dhp = h2p-h1p\n",
        "    if C1p*C2p == 0: dhp = 0\n",
        "    else:\n",
        "        if dhp > 180: dhp -= 360\n",
        "        elif dhp < -180: dhp += 360\n",
        "    dHp = 2*np.sqrt(C1p*C2p)*np.sin(np.radians(dhp)/2.0)\n",
        "    avg_Lp = (L1+L2)/2.0\n",
        "    if C1p*C2p == 0:\n",
        "        avg_hp = h1p + h2p\n",
        "    else:\n",
        "        if abs(h1p-h2p) > 180:\n",
        "            avg_hp = (h1p + h2p + 360)/2.0 if (h1p+h2p) < 360 else (h1p + h2p - 360)/2.0\n",
        "        else:\n",
        "            avg_hp = (h1p + h2p)/2.0\n",
        "    T = (1 - 0.17*np.cos(np.radians(avg_hp-30)) +\n",
        "         0.24*np.cos(np.radians(2*avg_hp)) +\n",
        "         0.32*np.cos(np.radians(3*avg_hp+6)) -\n",
        "         0.20*np.cos(np.radians(4*avg_hp-63)))\n",
        "    d_ro = 30*np.exp(-((avg_hp-275)/25)**2)\n",
        "    Rc = 2*np.sqrt(( ( ( ( (avg_C := (C1p+C2p)/2.0) )**7 ) / ((avg_C**7)+25**7) ) ))\n",
        "    Sl = 1 + 0.015*(avg_Lp-50)**2 / np.sqrt(20 + (avg_Lp-50)**2)\n",
        "    Sc = 1 + 0.045*avg_C\n",
        "    Sh = 1 + 0.015*avg_C*T\n",
        "    Rt = -np.sin(np.radians(2*d_ro))*Rc\n",
        "    return float(np.sqrt((dLp/Sl)**2 + (dCp/Sc)**2 + (dHp/Sh)**2 + Rt*(dCp/Sc)*(dHp/Sh)))\n",
        "\n",
        "def _kmeans_lab(lab_img, k, attempts=10):\n",
        "    H, W = lab_img.shape[:2]\n",
        "    Z = lab_img.reshape(-1,3).astype(np.float32)\n",
        "    crit = (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 80, 0.2)\n",
        "    _r, labels, centers = cv2.kmeans(Z, k, None, crit, attempts, cv2.KMEANS_PP_CENTERS)\n",
        "    labels2 = labels.reshape(H, W)\n",
        "    return labels2, centers.astype(np.float32)\n",
        "\n",
        "def _palette_quality(centers):\n",
        "    # combine entropy (area distribution unknown here) + mean ŒîE proxy among centers\n",
        "    # fallback uses variance of centers as spread metric + mean ŒîE among pairwise centers\n",
        "    if centers.shape[0] < 2:\n",
        "        return 0.0, 0.0\n",
        "    # ŒîE across centers\n",
        "    dEs = [ciede2000(centers[i], centers[j]) for i in range(len(centers)) for j in range(i+1, len(centers))]\n",
        "    mean_dE = float(np.mean(dEs)) if dEs else 0.0\n",
        "    spread = float(np.std(centers, axis=0).mean())\n",
        "    score = 0.7*mean_dE + 0.3*spread\n",
        "    return score, mean_dE\n",
        "\n",
        "def analyze_color_deep_ensemble(img, ks=(6,8,10)):\n",
        "    H, W = img.shape[:2]\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "    best = None\n",
        "    best_score = -1\n",
        "    results = {}\n",
        "\n",
        "    # hue histogram for legend\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    hue = (hsv[:,:,0].astype(np.float32) * 2.0) % 360.0\n",
        "    hue_hist, _ = np.histogram(hue, bins=36, range=(0,360))\n",
        "    hue_hist = hue_hist.astype(np.float32)\n",
        "\n",
        "    for k in ks:\n",
        "        labels2, centers = _kmeans_lab(lab, k)\n",
        "        counts = np.bincount(labels2.reshape(-1), minlength=k).astype(np.float32)\n",
        "        masks = [(labels2 == i).astype(np.uint8)*255 for i in range(k)]\n",
        "        # entropy using area fractions\n",
        "        frac = counts/(H*W + 1e-6)\n",
        "        p = frac[frac > 0]\n",
        "        entropy = -float(np.sum(p*np.log2(p)))\n",
        "        score, mean_dE = _palette_quality(centers)\n",
        "        quality = 0.6*score + 0.4*entropy  # composite quality\n",
        "\n",
        "        results[k] = dict(centers=centers, masks=masks, counts=counts, entropy=entropy, mean_dE=mean_dE)\n",
        "\n",
        "        if quality > best_score:\n",
        "            best_score = quality\n",
        "            best = (k, labels2, centers, masks, counts, entropy, mean_dE)\n",
        "\n",
        "    k_sel, labels2, centers, masks, counts, entropy, mean_dE = best\n",
        "    rgb_centers = cv2.cvtColor(centers.reshape(-1,1,3).astype(np.uint8),\n",
        "                               cv2.COLOR_Lab2RGB).reshape(-1,3)\n",
        "    palette = [tuple(map(int, c)) for c in rgb_centers]\n",
        "\n",
        "    a, b = centers[:,1]-128, centers[:,2]-128\n",
        "    hues_c = (np.degrees(np.arctan2(b, a)) + 360) % 360\n",
        "    warm_ratio = float(((hues_c < 90) | (hues_c > 330)).sum()/len(hues_c))\n",
        "    cool_ratio = float(((hues_c > 180) & (hues_c < 300)).sum()/len(hues_c))\n",
        "    harmony = \"mixed\"\n",
        "    if np.ptp(hues_c) < 35: harmony = \"analogous\"\n",
        "    elif any(abs(hues_c[i]-hues_c[j])%360 > 150 for i in range(len(hues_c)) for j in range(i+1, len(hues_c))):\n",
        "        harmony = \"complementary\"\n",
        "\n",
        "    # ŒîE proxy field from Lab gradients\n",
        "    labf = lab.astype(np.float32)\n",
        "    gxL = cv2.Sobel(labf[:,:,0], cv2.CV_32F, 1, 0); gyL = cv2.Sobel(labf[:,:,0], cv2.CV_32F, 0, 1)\n",
        "    gxa = cv2.Sobel(labf[:,:,1], cv2.CV_32F, 1, 0); gya = cv2.Sobel(labf[:,:,1], cv2.CV_32F, 0, 1)\n",
        "    gxb = cv2.Sobel(labf[:,:,2], cv2.CV_32F, 1, 0); gyb = cv2.Sobel(labf[:,:,2], cv2.CV_32F, 0, 1)\n",
        "    grad_mag = np.sqrt((gxL**2 + gyL**2) + (gxa**2 + gya**2) + (gxb**2 + gyb**2))\n",
        "    contrast_map = (grad_mag - grad_mag.min())/(grad_mag.max()-grad_mag.min()+1e-6)\n",
        "\n",
        "    return dict(\n",
        "        palette_rgb=palette,\n",
        "        masks=masks,\n",
        "        spatial_cohesion=float((counts/(H*W+1e-6)).max()),\n",
        "        palette_entropy=float(entropy),\n",
        "        mean_deltaE=float(mean_dE),\n",
        "        max_deltaE=float(np.max([ciede2000(centers[i], centers[j]) \n",
        "                                 for i in range(len(centers)) for j in range(i+1,len(centers))])) if len(centers)>1 else 0.0,\n",
        "        warm_ratio=warm_ratio,\n",
        "        cool_ratio=cool_ratio,\n",
        "        harmony=harmony,\n",
        "        contrast_map=contrast_map,\n",
        "        hue_hist=hue_hist,\n",
        "        k_selected=int(k_sel),\n",
        "        ks=list(ks)\n",
        "    )\n",
        "# -----------------------------\n",
        "# Texture: Gabor pyramid (scales 3..13, orientations 12)\n",
        "# -----------------------------\n",
        "def gabor_energy_pyramid(gray, scales=(3,5,7,9,11,13), orientations=12):\n",
        "    H, W = gray.shape\n",
        "    angles = np.linspace(0, 180, orientations, endpoint=False)\n",
        "    combined = np.zeros((H,W), np.float32)\n",
        "    angle_energy = np.zeros(orientations, np.float32)\n",
        "\n",
        "    for oi, theta in enumerate(angles):\n",
        "        theta_rad = np.deg2rad(theta)\n",
        "        e_sum = np.zeros((H,W), np.float32)\n",
        "        for k in scales:\n",
        "            kernel = cv2.getGaborKernel((21,21), sigma=k, theta=theta_rad,\n",
        "                                        lambd=10, gamma=0.5, psi=0)\n",
        "            resp = cv2.filter2D(gray, cv2.CV_32F, kernel)\n",
        "            e_sum += resp*resp\n",
        "        combined = np.maximum(combined, e_sum)\n",
        "        angle_energy[oi] = e_sum.mean()\n",
        "\n",
        "    anisotropy = float((angle_energy.max() - angle_energy.min())/(angle_energy.mean()+1e-6))\n",
        "    dom_angle = float(angles[int(np.argmax(angle_energy))])\n",
        "    gmap = (combined - combined.min())/(combined.max()-combined.min()+1e-6)\n",
        "\n",
        "    # entropy & roughness proxies\n",
        "    hist, _ = np.histogram(gray, bins=256, range=(0,256))\n",
        "    hist = hist.astype(np.float32); hist /= (hist.sum()+1e-6)\n",
        "    entropy = -float(np.sum(hist*np.log2(hist + 1e-12)))\n",
        "    roughness = float(gray.std())\n",
        "\n",
        "    return dict(\n",
        "        gabor_angles=angles,\n",
        "        gabor_energy=angle_energy,\n",
        "        gabor_map=gmap,\n",
        "        gabor_anisotropy=anisotropy,\n",
        "        gabor_dom_angle=dom_angle,\n",
        "        lbp_entropy=entropy,\n",
        "        lbp_roughness=roughness\n",
        "    )\n",
        "\n",
        "# -----------------------------\n",
        "# Saliency: two-scale spectral residual + mask fusion\n",
        "# -----------------------------\n",
        "def spectral_saliency(grayf, blur=(9,9), sigma=2):\n",
        "    fft = np.fft.fft2(grayf)\n",
        "    loga = np.log(np.abs(fft)+1e-8)\n",
        "    spec = np.exp((loga - cv2.blur(loga,(3,3))) + 1j*np.angle(fft))\n",
        "    sal = np.abs(np.fft.ifft2(spec))**2\n",
        "    sal = cv2.GaussianBlur(sal, blur, sigma)\n",
        "    sal = (sal - sal.min())/(sal.max()-sal.min()+1e-6)\n",
        "    return (sal*255).astype(np.uint8)\n",
        "\n",
        "def subject_from_saliency_fused(s1, s2):\n",
        "    H, W = s1.shape\n",
        "    m1 = cv2.threshold(s1, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
        "    m2 = cv2.threshold(s2, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
        "    m = cv2.bitwise_and(m1, m2)\n",
        "    m = cv2.morphologyEx(m, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))\n",
        "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, np.ones((7,7), np.uint8))\n",
        "    cnts,_ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if cnts:\n",
        "        x,y,w,h = cv2.boundingRect(max(cnts, key=cv2.contourArea))\n",
        "    else:\n",
        "        x,y,w,h = W//4, H//4, W//2, H//2\n",
        "        cv2.rectangle(m, (x,y), (x+w, y+h), 255, -1)\n",
        "    return dict(mask=m, bbox=(x,y,w,h))\n",
        "\n",
        "def analyze_saliency_deep(img):\n",
        "    g = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY).astype(np.float32)\n",
        "    s_coarse = spectral_saliency(cv2.GaussianBlur(g,(0,0), 3.0), blur=(11,11), sigma=3)\n",
        "    s_fine   = spectral_saliency(cv2.GaussianBlur(g,(0,0), 1.0), blur=(7,7),  sigma=1.5)\n",
        "    fused = np.maximum(s_coarse, s_fine)\n",
        "    sub = subject_from_saliency_fused(s_coarse, s_fine)\n",
        "    Y, X = np.indices(fused.shape); w = fused.astype(np.float32)+1\n",
        "    cx, cy = int((X*w).sum()/w.sum()), int((Y*w).sum()/w.sum())\n",
        "    return dict(saliency_map=fused, focal=(cx,cy), subject_mask=sub[\"mask\"], subject_bbox=sub[\"bbox\"])\n",
        "\n",
        "# -----------------------------\n",
        "# Composition: multi-sweep Hough + vanishing point clustering\n",
        "# -----------------------------\n",
        "def line_intersection(p1, p2):\n",
        "    (x1,y1,x2,y2), (x3,y3,x4,y4) = p1, p2\n",
        "    den = (x1-x2)*(y3-y4) - (y1-y2)*(x3-x4)\n",
        "    if abs(den) < 1e-6: return None\n",
        "    px = ((x1*y2 - y1*x2)*(x3-x4) - (x1-x2)*(x3*y4 - y3*x4))/den\n",
        "    py = ((x1*y2 - y1*x2)*(y3-y4) - (y1-y2)*(x3*y4 - y3*x4))/den\n",
        "    return (px, py)\n",
        "\n",
        "def cluster_points(points, grid=40):\n",
        "    # simple grid binning to find dense intersection area\n",
        "    if not points: \n",
        "        return None\n",
        "    pts = np.array(points, dtype=np.float32)\n",
        "    xs, ys = pts[:,0], pts[:,1]\n",
        "    xbin = np.round(xs/grid).astype(int)\n",
        "    ybin = np.round(ys/grid).astype(int)\n",
        "    keys = xbin*100000 + ybin\n",
        "    uniq, counts = np.unique(keys, return_counts=True)\n",
        "    best_key = uniq[np.argmax(counts)]\n",
        "    bx = (best_key // 100000) * grid\n",
        "    by = (best_key % 100000) * grid\n",
        "    # average of points in the best bin\n",
        "    mask = (keys == best_key)\n",
        "    bx = float(xs[mask].mean())\n",
        "    by = float(ys[mask].mean())\n",
        "    return (bx, by)\n",
        "\n",
        "def analyze_composition_deep(img, focal_xy):\n",
        "    g = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    H, W = g.shape\n",
        "    edges = cv2.Canny(g, 80, 200)\n",
        "\n",
        "    lines = []\n",
        "    # multi-sweep Hough\n",
        "    params = [\n",
        "        (1, np.pi/180, 100, min(H,W)//12, 15),\n",
        "        (1, np.pi/180, 80,  min(H,W)//14, 20),\n",
        "        (1, np.pi/180, 120, min(H,W)//10, 15)\n",
        "    ]\n",
        "    for rho, theta, thr, minL, gap in params:\n",
        "        linesP = cv2.HoughLinesP(edges, rho, theta, thr, minLineLength=minL, maxLineGap=gap)\n",
        "        if linesP is not None:\n",
        "            for l in linesP:\n",
        "                ln = tuple(map(int, l[0]))\n",
        "                lines.append(ln)\n",
        "\n",
        "    # deduplicate short or near-identical lines\n",
        "    dedup = []\n",
        "    for (x1,y1,x2,y2) in lines:\n",
        "        if math.hypot(x2-x1, y2-y1) < min(H,W)//14: \n",
        "            continue\n",
        "        dedup.append((x1,y1,x2,y2))\n",
        "    lines = dedup[:300]\n",
        "\n",
        "    # vanishing point via line intersections inside image bounds\n",
        "    inters = []\n",
        "    for i in range(len(lines)):\n",
        "        for j in range(i+1, len(lines)):\n",
        "            ip = line_intersection(lines[i], lines[j])\n",
        "            if ip is None: \n",
        "                continue\n",
        "            if -W*0.5 <= ip[0] <= W*1.5 and -H*0.5 <= ip[1] <= H*1.5:\n",
        "                inters.append(ip)\n",
        "    vp = cluster_points(inters, grid=max(20, min(H,W)//30))\n",
        "    if vp is None:\n",
        "        vp = (W/2, H/2)\n",
        "\n",
        "    # rule-of-thirds & golden deltas\n",
        "    fx, fy = focal_xy\n",
        "    thirds_pts = [(W/3,H/3),(2*W/3,H/3),(W/3,2*H/3),(2*W/3,2*H/3)]\n",
        "    gfac = 0.618\n",
        "    golden_pts = [(gfac*W,gfac*H),((1-gfac)*W,gfac*H),\n",
        "                  (gfac*W,(1-gfac)*H),((1-gfac)*W,(1-gfac)*H)]\n",
        "    diag = np.hypot(W,H)\n",
        "    thirds_delta = min(np.hypot(fx-x,fy-y) for (x,y) in thirds_pts)/(diag+1e-6)\n",
        "    golden_delta = min(np.hypot(fx-x,fy-y) for (x,y) in golden_pts)/(diag+1e-6)\n",
        "\n",
        "    # symmetry & edge balance\n",
        "    g_f = g.astype(np.float32)/255.0\n",
        "    left = g_f[:, :W//2]\n",
        "    right = np.fliplr(g_f[:, W - left.shape[1]:])\n",
        "    mse = float(np.mean((left - right)**2))\n",
        "    symmetry = float(1.0 - min(1.0, mse*4.0))\n",
        "    lw, rw = float(np.sum(edges[:,:W//2])), float(np.sum(edges[:,W//2:]))\n",
        "    balance = (rw - lw)/(lw + rw + 1e-6)\n",
        "\n",
        "    return dict(\n",
        "        lines=lines,\n",
        "        vanishing_point=vp,\n",
        "        thirds_delta=thirds_delta,\n",
        "        golden_delta=golden_delta,\n",
        "        symmetry=symmetry,\n",
        "        edge_balance=balance\n",
        "    )\n",
        "\n",
        "# -----------------------------\n",
        "# Illumination (direction + skew)\n",
        "# -----------------------------\n",
        "def illumination(img):\n",
        "    L = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)[:,:,0].astype(np.float32)\n",
        "    mu, sig = L.mean(), L.std()+1e-6\n",
        "    skew = float((((L-mu)/sig)**3).mean())\n",
        "    gx, gy = cv2.Sobel(L, cv2.CV_32F, 1,0), cv2.Sobel(L, cv2.CV_32F, 0,1)\n",
        "    hi = (L > np.percentile(L, 90)).astype(np.uint8)\n",
        "    if hi.sum() > 0:\n",
        "        gx, gy = (gx*hi).sum(), (gy*hi).sum()\n",
        "        ang = float((degrees(atan2(-gy, -gx)) + 360) % 360)\n",
        "    else:\n",
        "        ang = None\n",
        "    return dict(lightness_skew=skew, light_direction_deg=ang)\n",
        "# -----------------------------\n",
        "# Curatorial summary (encouraging)\n",
        "# -----------------------------\n",
        "def generate_curatorial_summary(M):\n",
        "    C, T, P, I = M[\"color\"], M[\"texture\"], M[\"composition\"], M[\"illumination\"]\n",
        "    tone = {\"analogous\":\"a gentle, harmonious range\",\n",
        "            \"complementary\":\"a lively conversation of opposites\"}.get(C[\"harmony\"], \"a balanced and nuanced palette\")\n",
        "    if C[\"mean_deltaE\"] > 25: contrast = \"confident contrasts that energize the field\"\n",
        "    elif C[\"mean_deltaE\"] > 10: contrast = \"measured contrasts that keep the eye engaged\"\n",
        "    else: contrast = \"soft transitions that encourage a calm reading\"\n",
        "    texture_phrase = (\n",
        "        f\"Texture carries a directional current (peak near {T['gabor_dom_angle']:.0f}¬∞), guiding the eye\"\n",
        "        if T[\"gabor_anisotropy\"] > 0.5 else\n",
        "        \"Texture feels even and poised, letting color and shape lead\"\n",
        "    )\n",
        "    comp_phrase = (\n",
        "        \"The focal area resonates with classical proportion.\"\n",
        "        if P[\"golden_delta\"] < 0.12 else\n",
        "        \"The focal area settles near the rule-of-thirds, feeling intuitive and open.\"\n",
        "        if P[\"thirds_delta\"] < 0.12 else\n",
        "        \"The focal area resists fixed proportion, inviting free exploration.\"\n",
        "    )\n",
        "    light_phrase = (\n",
        "        f\"Light arrives around {int(I['light_direction_deg'])}¬∞, gently shaping perception.\"\n",
        "        if I[\"light_direction_deg\"] is not None else\n",
        "        \"Light diffuses evenly, letting the whole surface breathe.\"\n",
        "    )\n",
        "    mood = \"bright and open\" if I[\"lightness_skew\"] > 0.5 else \\\n",
        "           \"quietly contemplative\" if I[\"lightness_skew\"] < -0.5 else \\\n",
        "           \"balanced and steady\"\n",
        "\n",
        "    micro = textwrap.fill(\n",
        "        \" ‚Ä¢ Palette: \" + tone + \". \" +\n",
        "        \" ‚Ä¢ Contrast: \" + contrast + \". \" +\n",
        "        \" ‚Ä¢ Texture: \" + (\"directional\" if T[\"gabor_anisotropy\"]>0.5 else \"even\") + \". \" +\n",
        "        \" ‚Ä¢ Composition: classical cues with flexible balance. \" +\n",
        "        \" ‚Ä¢ Light: \" + (\"directional\" if I[\"light_direction_deg\"] else \"diffuse\") + \".\",\n",
        "        width=90\n",
        "    )\n",
        "    narrative = textwrap.fill(\n",
        "        \"This work invites an attentive gaze. The palette offers \" + tone + \", with \" + contrast +\n",
        "        \". \" + texture_phrase + \". \" + comp_phrase + \" \" + light_phrase +\n",
        "        \" The mood feels \" + mood + \", encouraging you to linger as color, gesture, and structure support one another.\",\n",
        "        width=90\n",
        "    )\n",
        "    return micro, narrative\n",
        "\n",
        "# -----------------------------\n",
        "# Composite with strong overlays + minimal legend\n",
        "# -----------------------------\n",
        "def build_composite(img, M):\n",
        "    base = img.astype(np.float32)/255.0\n",
        "    H, W = base.shape[:2]\n",
        "\n",
        "    # 1) Color clusters (tinted wash)\n",
        "    color_layer = np.zeros_like(base)\n",
        "    for m, c in zip(M[\"color\"][\"masks\"], M[\"color\"][\"palette_rgb\"]):\n",
        "        if m.sum() == 0: continue\n",
        "        mask = cv2.GaussianBlur((m > 0).astype(np.float32), (0,0), 6)\n",
        "        color_layer += np.dstack([mask]*3) * (np.array(c)/255.0)\n",
        "    color_layer *= 0.14\n",
        "\n",
        "    # 2) Texture (Gabor energy) ‚Üí amber\n",
        "    gmap = M[\"texture\"][\"gabor_map\"]\n",
        "    gmap = cv2.GaussianBlur(gmap, (0,0), 1.0)\n",
        "    gmap = (gmap - gmap.min())/(gmap.max()-gmap.min()+1e-6)\n",
        "    tex_layer = np.dstack([gmap, gmap*0.45, 0*gmap]) * 0.38\n",
        "\n",
        "    # 3) ŒîE proxy ‚Üí magenta\n",
        "    contrast = M[\"color\"][\"contrast_map\"]\n",
        "    contrast = cv2.GaussianBlur(contrast, (0,0), 1.0)\n",
        "    contrast = (contrast - contrast.min())/(contrast.max()-contrast.min()+1e-6)\n",
        "    de_layer = np.dstack([contrast*0.60, 0*contrast, contrast*0.60]) * 0.36\n",
        "\n",
        "    # 4) Saliency ‚Üí soft red\n",
        "    sal = M[\"saliency\"][\"saliency_map\"].astype(np.float32)\n",
        "    if sal.shape[:2] != (H, W):\n",
        "        sal = cv2.resize(sal, (W, H), interpolation=cv2.INTER_CUBIC)\n",
        "    sal = cv2.normalize(sal, None, 0, 1, cv2.NORM_MINMAX)\n",
        "    sal_layer = np.dstack([sal*0.70, sal*0.30, sal*0.30]) * 0.30\n",
        "\n",
        "    # 5) Lines (cyan/green/yellow by angle)\n",
        "    line_layer = np.zeros_like(base)\n",
        "    for (x1,y1,x2,y2) in M[\"composition\"][\"lines\"][:240]:\n",
        "        ang = (np.rad2deg(np.arctan2(y2-y1, x2-x1)) + 180) % 180\n",
        "        col = (0,1,0) if 60<ang<120 else (0,0,1) if ang<30 or ang>150 else (1,1,0)\n",
        "        cv2.line(line_layer,(x1,y1),(x2,y2),(col[2],col[1],col[0]),1,cv2.LINE_AA)\n",
        "    line_layer = cv2.GaussianBlur(line_layer, (0,0), 2) * 0.55\n",
        "\n",
        "    comp = base*0.82 + color_layer + tex_layer + de_layer + sal_layer + line_layer\n",
        "    comp = np.clip(comp, 0, 1)\n",
        "\n",
        "    # Subject contour + glow and focal rings\n",
        "    comp_bgr = (comp[:,:,::-1]*255).astype(np.uint8).copy()\n",
        "    mask = M[\"saliency\"][\"subject_mask\"]\n",
        "    cnts,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if cnts:\n",
        "        glow = np.zeros_like(comp_bgr)\n",
        "        cv2.drawContours(glow, cnts, -1, (255, 0, 255), thickness=cv2.FILLED)\n",
        "        glow = cv2.GaussianBlur(glow, (0,0), 15)\n",
        "        comp_bgr = cv2.addWeighted(glow, 0.14, comp_bgr, 0.86, 0)\n",
        "        cv2.drawContours(comp_bgr, cnts, -1, (255, 0, 255), 2)\n",
        "    fx, fy = M[\"saliency\"][\"focal\"]\n",
        "    for r in range(6, 30, 6):\n",
        "        cv2.circle(comp_bgr, (int(fx), int(fy)), r, (0,0,255), 1)\n",
        "\n",
        "    # Thirds & Golden lines\n",
        "    thirds_x, thirds_y = [W//3, 2*W//3], [H//3, 2*H//3]\n",
        "    for x in thirds_x: cv2.line(comp_bgr, (x,0), (x,H), (240,240,240), 1)\n",
        "    for y in thirds_y: cv2.line(comp_bgr, (0,y), (W,y), (240,240,240), 1)\n",
        "    gfac = 0.618\n",
        "    gx = [int(gfac*W), int((1-gfac)*W)]\n",
        "    gy = [int(gfac*H), int((1-gfac)*H)]\n",
        "    for x in gx: cv2.line(comp_bgr, (x,0), (x,H), (0,255,255), 1)\n",
        "    for y in gy: cv2.line(comp_bgr, (0,y), (W,y), (0,255,255), 1)\n",
        "\n",
        "    # Vanishing point + Light arrow\n",
        "    vp = M[\"composition\"].get(\"vanishing_point\")\n",
        "    if vp: cv2.circle(comp_bgr, tuple(map(int, vp)), 6, (0,255,255), -1)\n",
        "    ang = M[\"illumination\"].get(\"light_direction_deg\")\n",
        "    if ang is not None:\n",
        "        cx, cy = W-60, 60; r = min(H,W)//3\n",
        "        ex, ey = int(cx - r*np.cos(np.radians(ang))), int(cy + r*np.sin(np.radians(ang)))\n",
        "        cv2.arrowedLine(comp_bgr, (cx,cy), (ex,ey), (0,150,255), 3, tipLength=0.1)\n",
        "\n",
        "    comp_rgb = comp_bgr[:,:,::-1].astype(np.float32)/255.0\n",
        "\n",
        "    # Legend (minimal text)\n",
        "    legend_h = 140\n",
        "    legend = np.zeros((legend_h, W, 3), np.uint8)\n",
        "    f = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    cv2.putText(legend, \"Legend\", (20, 34), f, 1.0, (255,255,255), 2)\n",
        "\n",
        "    sw = [\n",
        "        ((150,10),(185,40),(0,0,255),   \"Focal\"),\n",
        "        ((200,10),(235,40),(255,0,255), \"Subject\"),\n",
        "        ((250,10),(285,40),(0,255,255), \"Lines\"),\n",
        "        ((300,10),(335,40),(255,128,0), \"Texture\"),\n",
        "        ((350,10),(385,40),(255,0,255), \"ŒîE\"),\n",
        "        ((400,10),(435,40),(255,255,255),\"Thirds\"),\n",
        "        ((450,10),(485,40),(0,255,255), \"Golden\"),\n",
        "        ((500,10),(535,40),(0,150,255), \"Light‚Üí\"),\n",
        "        ((550,10),(585,40),(0,255,255), \"Vanishing\"),\n",
        "        ((600,10),(635,40),(200,200,200),\"Hue\"),\n",
        "        ((650,10),(685,40),(180,180,180),\"Texture dir\")\n",
        "    ]\n",
        "    for (x1,y1),(x2,y2), col, label in sw:\n",
        "        if x2 < W - 10:\n",
        "            cv2.rectangle(legend, (x1,y1), (x2,y2), col, -1)\n",
        "            cv2.putText(legend, label, (x2+8, y2), f, 0.55, (230,230,230), 1)\n",
        "\n",
        "    # hue & orientation bars on right\n",
        "    hue_bar = make_hue_bar(M[\"color\"][\"hue_hist\"], width=min(480, max(360, W//2)), height=44)\n",
        "    ori_bar = make_orientation_bar(M[\"texture\"][\"gabor_angles\"], M[\"texture\"][\"gabor_energy\"],\n",
        "                                   width=min(480, max(360, W//2)), height=44)\n",
        "    hb_h, hb_w = hue_bar.shape[:2]; ob_h, ob_w = ori_bar.shape[:2]\n",
        "    x0 = max(0, W - max(hb_w, ob_w) - 20)\n",
        "    hue_bar_resized = hue_bar[:, :min(hb_w, W - x0)]\n",
        "    ori_bar_resized = ori_bar[:, :min(ob_w, W - x0)]\n",
        "    y1,y2 = 10, 10 + hb_h; x1,x2 = x0, x0 + hue_bar_resized.shape[1]\n",
        "    if y2 <= legend.shape[0] and x2 <= legend.shape[1]:\n",
        "        legend[y1:y2, x1:x2] = hue_bar_resized\n",
        "    y1b,y2b = 10 + hb_h + 5, 10 + hb_h + 5 + ob_h\n",
        "    x1b,x2b = x0, x0 + ori_bar_resized.shape[1]\n",
        "    if y2b <= legend.shape[0] and x2b <= legend.shape[1]:\n",
        "        legend[y1b:y2b, x1b:x2b] = ori_bar_resized\n",
        "\n",
        "    final = np.vstack([to_uint8(safe_gamma(comp_rgb)), legend])\n",
        "    final = final.astype(np.uint8)\n",
        "    return final\n",
        "\n",
        "# -----------------------------\n",
        "# Main pipeline (deep fidelity)\n",
        "# -----------------------------\n",
        "def analyze_artwork_high_fidelity(path, verbose=True, thorough=True):\n",
        "    t0 = time.time()\n",
        "    if verbose: print(f\"üñºÔ∏è Loading image: {path}\")\n",
        "    img = load_rgb(path)\n",
        "    H0, W0 = img.shape[:2]\n",
        "    if verbose: print(f\"   ‚Ä¢ Image size: {W0}√ó{H0}\")\n",
        "\n",
        "    # Upscale small inputs to ~1.8MP for fidelity\n",
        "    if thorough:\n",
        "        img, scale = resize_min_pixels(img, target_pixels=1_800_000)\n",
        "        H, W = img.shape[:2]\n",
        "        if verbose and (H!=H0 or W!=W0):\n",
        "            print(f\"   ‚Ä¢ Rescaled for fidelity: {W}√ó{H}\")\n",
        "    else:\n",
        "        H, W = H0, W0\n",
        "\n",
        "    # Color (multi-k ensemble)\n",
        "    if verbose: print(\"üé® Deep color clustering (k=6,8,10)‚Ä¶\", end=\"\", flush=True)\n",
        "    color = analyze_color_deep_ensemble(img, ks=(6,8,10))\n",
        "    if verbose: print(f\" ‚úì (selected k={color['k_selected']})\")\n",
        "\n",
        "    # Texture (expanded Gabor pyramid)\n",
        "    if verbose: print(\"ü™∂ Texture analysis (Gabor pyramid)‚Ä¶\", end=\"\", flush=True)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    texture = gabor_energy_pyramid(gray, scales=(3,5,7,9,11,13), orientations=12)\n",
        "    if verbose: print(\" ‚úì\")\n",
        "\n",
        "    # Saliency (two-scale)\n",
        "    if verbose: print(\"üî• Saliency mapping (two-scale)‚Ä¶\", end=\"\", flush=True)\n",
        "    sal = analyze_saliency_deep(img)\n",
        "    if verbose: print(\" ‚úì\")\n",
        "\n",
        "    # Composition (multi-sweep Hough + VP clustering)\n",
        "    if verbose: print(\"üìê Composition metrics‚Ä¶\", end=\"\", flush=True)\n",
        "    comp = analyze_composition_deep(img, sal[\"focal\"])\n",
        "    if verbose: print(\" ‚úì\")\n",
        "\n",
        "    # Illumination\n",
        "    if verbose: print(\"üí° Illumination gradients‚Ä¶\", end=\"\", flush=True)\n",
        "    illum = illumination(img)\n",
        "    if verbose: print(\" ‚úì\")\n",
        "\n",
        "    # Composite\n",
        "    if verbose: print(\"‚ú® Building composite visualization‚Ä¶\", end=\"\", flush=True)\n",
        "    M = dict(color=color, texture=texture, saliency=sal, composition=comp, illumination=illum)\n",
        "    composite = build_composite(img, M)\n",
        "    if verbose: print(\" ‚úì\")\n",
        "\n",
        "    # Outputs\n",
        "    out_dir = os.path.splitext(path)[0] + \"_analysis\"\n",
        "    ensure_dir(out_dir)\n",
        "    out_png = os.path.join(out_dir, \"overlay_final_composite.png\")\n",
        "    cv2.imwrite(out_png, composite)\n",
        "\n",
        "    # Curatorial text\n",
        "    if verbose: print(\"üìú Writing curatorial summary‚Ä¶\", end=\"\", flush=True)\n",
        "    micro, narrative = generate_curatorial_summary(M)\n",
        "    out_txt = os.path.join(out_dir, \"curatorial_summary.txt\")\n",
        "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"--- MICRO SUMMARY ---\\n\")\n",
        "        f.write(micro + \"\\n\\n--- CURATORIAL SUMMARY ---\\n\")\n",
        "        f.write(narrative + \"\\n\")\n",
        "    if verbose: print(\" ‚úì\")\n",
        "\n",
        "    # Metrics JSON\n",
        "    if verbose: print(\"üßæ Saving metrics.json‚Ä¶\", end=\"\", flush=True)\n",
        "    metrics_py = make_json_safe(M)\n",
        "    out_json = os.path.join(out_dir, \"metrics.json\")\n",
        "    with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metrics_py, f, indent=2)\n",
        "    if verbose: print(\" ‚úì\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n‚úÖ Deep analysis done in {time.time()-t0:.2f}s (thorough mode)\")\n",
        "        print(f\"üìÅ Results saved to: {out_dir}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Run\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # ‚¨áÔ∏è Set your image path here\n",
        "    IMAGE_PATH = \"/Users/alievanayasso/Documents/SlowMA/2B--glory%20days.jpg\"\n",
        "    analyze_artwork_high_fidelity(IMAGE_PATH, verbose=True, thorough=True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
