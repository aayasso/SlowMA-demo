{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Analysis complete for: VG_-_skeleton.jpg\n",
            "üìÅ Results saved to: /Users/alievanayasso/Documents/SlowMA/VG_-_skeleton_analysis\n",
            "‚è±Ô∏è  Elapsed: 31.96s\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# High-Fidelity Artwork Analyzer v13.2 (Stable Local Edition)\n",
        "# ==========================================================\n",
        "# Local-only (OpenCV, NumPy, Pillow)\n",
        "#\n",
        "# Outputs per image:\n",
        "#   /<image>_analysis/\n",
        "#     ‚îú‚îÄ overlay_final_composite.png\n",
        "#     ‚îú‚îÄ curatorial_summary.txt\n",
        "#     ‚îî‚îÄ metrics.json\n",
        "# ==========================================================\n",
        "\n",
        "import os, json, time, textwrap\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from math import atan2, degrees\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "def load_rgb(path):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    return np.array(img)\n",
        "\n",
        "def ensure_dir(p): os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def to_uint8(img_f32): return np.clip(img_f32*255.0,0,255).astype(np.uint8)\n",
        "\n",
        "def safe_gamma(img_f32):\n",
        "    m = float(img_f32.mean())\n",
        "    if m < 0.20: img_f32 = np.power(img_f32, 0.6)\n",
        "    elif m > 0.85: img_f32 = np.power(img_f32, 1.2)\n",
        "    return np.clip(img_f32, 0, 1)\n",
        "\n",
        "# -----------------------------\n",
        "# Color Analysis\n",
        "# -----------------------------\n",
        "def ciede2000(Lab1, Lab2):\n",
        "    L1,a1,b1 = Lab1; L2,a2,b2 = Lab2\n",
        "    avg_L = (L1 + L2) / 2.0\n",
        "    C1,C2 = np.sqrt(a1*a1 + b1*b1), np.sqrt(a2*a2 + b2*b2)\n",
        "    avg_C = (C1 + C2) / 2.0\n",
        "    G = 0.5*(1 - np.sqrt((avg_C**7)/((avg_C**7)+25**7)))\n",
        "    a1p,a2p = (1+G)*a1,(1+G)*a2\n",
        "    C1p,C2p = np.sqrt(a1p*a1p + b1*b1), np.sqrt(a2p*a2p + b2*b2)\n",
        "    avg_Cp = (C1p + C2p)/2\n",
        "    h1p = np.degrees(np.arctan2(b1,a1p))%360; h2p = np.degrees(np.arctan2(b2,a2p))%360\n",
        "    dLp = L2-L1; dCp = C2p-C1p; dhp = h2p-h1p\n",
        "    if C1p*C2p==0: dhp=0\n",
        "    else:\n",
        "        if dhp>180: dhp-=360\n",
        "        elif dhp<-180: dhp+=360\n",
        "    dHp = 2*np.sqrt(C1p*C2p)*np.sin(np.radians(dhp)/2)\n",
        "    avg_Lp=(L1+L2)/2\n",
        "    if C1p*C2p==0: avg_hp=h1p+h2p\n",
        "    else:\n",
        "        if abs(h1p-h2p)>180: avg_hp=(h1p+h2p+360)/2 if (h1p+h2p)<360 else (h1p+h2p-360)/2\n",
        "        else: avg_hp=(h1p+h2p)/2\n",
        "    T=(1-0.17*np.cos(np.radians(avg_hp-30))+0.24*np.cos(np.radians(2*avg_hp))\n",
        "        +0.32*np.cos(np.radians(3*avg_hp+6))-0.20*np.cos(np.radians(4*avg_hp-63)))\n",
        "    d_ro=30*np.exp(-((avg_hp-275)/25)**2)\n",
        "    Rc=2*np.sqrt((avg_Cp**7)/((avg_Cp**7)+25**7))\n",
        "    Sl=1+0.015*(avg_Lp-50)**2/np.sqrt(20+(avg_Lp-50)**2)\n",
        "    Sc=1+0.045*avg_Cp; Sh=1+0.015*avg_Cp*T; Rt=-np.sin(np.radians(2*d_ro))*Rc\n",
        "    return float(np.sqrt((dLp/Sl)**2 + (dCp/Sc)**2 + (dHp/Sh)**2 + Rt*(dCp/Sc)*(dHp/Sh)))\n",
        "\n",
        "def analyze_color_deep(img, k=6):\n",
        "    H,W = img.shape[:2]\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "    Z = lab.reshape(-1,3).astype(np.float32)\n",
        "    crit=(cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER,60,0.3)\n",
        "    _r,labels,centers=cv2.kmeans(Z,k,None,crit,10,cv2.KMEANS_PP_CENTERS)\n",
        "    labels2 = labels.reshape(H,W)\n",
        "    centers = centers.astype(np.float32)\n",
        "    rgb_centers = cv2.cvtColor(centers.reshape(-1,1,3).astype(np.uint8),cv2.COLOR_Lab2RGB).reshape(-1,3)\n",
        "    palette=[tuple(map(int,c)) for c in rgb_centers]\n",
        "    counts=np.bincount(labels.flatten(),minlength=k).astype(np.float32)\n",
        "    masks=[(labels2==i).astype(np.uint8)*255 for i in range(k)]\n",
        "    cluster_area_frac=counts/(H*W+1e-6)\n",
        "    spatial_cohesion=float(cluster_area_frac.max())\n",
        "    p=cluster_area_frac[cluster_area_frac>0]\n",
        "    palette_entropy=-float(np.sum(p*np.log2(p)))\n",
        "    hsv=cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
        "    Hh,Sh,Vh=hsv[:,:,0].astype(np.float32),hsv[:,:,1].astype(np.float32),hsv[:,:,2].astype(np.float32)\n",
        "    hue_deg=(Hh*2.0)%360.0\n",
        "    hist,_=np.histogram(hue_deg,bins=36,range=(0,360)); hist=hist.astype(np.float32); hist/=hist.sum()+1e-6\n",
        "    a,b=centers[:,1]-128,centers[:,2]-128\n",
        "    hues_c=(np.degrees(np.arctan2(b,a))+360)%360\n",
        "    warm_ratio=float(((hues_c<90)|(hues_c>330)).sum()/len(hues_c))\n",
        "    cool_ratio=float(((hues_c>180)&(hues_c<300)).sum()/len(hues_c))\n",
        "    harmony=\"mixed\"\n",
        "    if np.ptp(hues_c)<35: harmony=\"analogous\"\n",
        "    elif any(abs(hues_c[i]-hues_c[j])%360>150 for i in range(len(hues_c)) for j in range(i+1,len(hues_c))):\n",
        "        harmony=\"complementary\"\n",
        "    dEs=[ciede2000(centers[i],centers[j]) for i in range(len(centers)) for j in range(i+1,len(centers))]\n",
        "    mean_dE=float(np.mean(dEs)) if dEs else 0.0; max_dE=float(np.max(dEs)) if dEs else 0.0\n",
        "    labf=lab.astype(np.float32)\n",
        "    gxL,gyL=cv2.Sobel(labf[:,:,0],cv2.CV_32F,1,0),cv2.Sobel(labf[:,:,0],cv2.CV_32F,0,1)\n",
        "    gxa,gya=cv2.Sobel(labf[:,:,1],cv2.CV_32F,1,0),cv2.Sobel(labf[:,:,1],cv2.CV_32F,0,1)\n",
        "    gxb,gyb=cv2.Sobel(labf[:,:,2],cv2.CV_32F,1,0),cv2.Sobel(labf[:,:,2],cv2.CV_32F,0,1)\n",
        "    grad_mag=np.sqrt((gxL**2+gyL**2)+(gxa**2+gya**2)+(gxb**2+gyb**2))\n",
        "    contrast_map=(grad_mag-grad_mag.min())/(grad_mag.max()-grad_mag.min()+1e-6)\n",
        "    return dict(palette_rgb=palette,masks=masks,color_variability=float(np.std(centers,0).mean()),\n",
        "                warm_ratio=warm_ratio,cool_ratio=cool_ratio,harmony=harmony,\n",
        "                hue_hist=hist,spatial_cohesion=spatial_cohesion,\n",
        "                palette_entropy=palette_entropy,mean_deltaE=mean_dE,max_deltaE=max_dE,\n",
        "                contrast_map=contrast_map)\n",
        "\n",
        "# -----------------------------\n",
        "# Texture, Saliency, Composition, Illumination\n",
        "# -----------------------------\n",
        "def gabor_energy(gray):\n",
        "    H,W=gray.shape; angles=np.linspace(0,180,6,endpoint=False)\n",
        "    ori_energy=[]\n",
        "    combined=np.zeros((H,W),np.float32)\n",
        "    for theta in angles:\n",
        "        theta_rad=np.deg2rad(theta)\n",
        "        e_sum=np.zeros((H,W),np.float32)\n",
        "        for k in (3,5,7):\n",
        "            kernel=cv2.getGaborKernel((21,21),sigma=k,theta=theta_rad,lambd=10,gamma=0.5,psi=0)\n",
        "            resp=cv2.filter2D(gray,cv2.CV_32F,kernel); e_sum+=resp*resp\n",
        "        ori_energy.append(e_sum.mean()); combined=np.maximum(combined,e_sum)\n",
        "    ori_energy=np.array(ori_energy); dom_angle=float(angles[int(np.argmax(ori_energy))])\n",
        "    anisotropy=float((ori_energy.max()-ori_energy.min())/(ori_energy.mean()+1e-6))\n",
        "    return angles,ori_energy,(combined-combined.min())/(combined.max()-combined.min()+1e-6),anisotropy,dom_angle\n",
        "\n",
        "def analyze_texture(img):\n",
        "    g=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "    hist,_=np.histogram(g,bins=256,range=(0,256)); hist=hist.astype(np.float32); hist/=hist.sum()+1e-6\n",
        "    lbp_entropy=-float(np.sum(hist*np.log2(hist+1e-12))); lbp_roughness=float(g.std())\n",
        "    angles,e_map,gabor_map,anisotropy,dom=gabor_energy(g)\n",
        "    return dict(lbp_entropy=lbp_entropy,lbp_roughness=lbp_roughness,gabor_angles=angles,\n",
        "                gabor_energy=e_map,gabor_map=gabor_map,gabor_anisotropy=anisotropy,\n",
        "                gabor_dom_angle=dom)\n",
        "\n",
        "def spectral_saliency(grayf):\n",
        "    fft=np.fft.fft2(grayf); loga=np.log(np.abs(fft)+1e-8)\n",
        "    spec=np.exp((loga-cv2.blur(loga,(3,3)))+1j*np.angle(fft))\n",
        "    sal=np.abs(np.fft.ifft2(spec))**2; sal=cv2.GaussianBlur(sal,(9,9),2)\n",
        "    sal=(sal-sal.min())/(sal.max()-sal.min()+1e-6)\n",
        "    return (sal*255).astype(np.uint8)\n",
        "\n",
        "def subject_from_saliency(sal):\n",
        "    H,W=sal.shape\n",
        "    _,th=cv2.threshold(sal,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    cnts,_=cv2.findContours(th,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if cnts: x,y,w,h=cv2.boundingRect(max(cnts,key=cv2.contourArea))\n",
        "    else: x,y,w,h=W//4,H//4,W//2,H//2\n",
        "    mask=np.zeros((H,W),np.uint8); cv2.rectangle(mask,(x,y),(x+w,y+h),255,-1)\n",
        "    return dict(mask=mask,bbox=(x,y,w,h))\n",
        "\n",
        "def analyze_saliency(img):\n",
        "    g=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY).astype(np.float32)\n",
        "    sal=spectral_saliency(g); sub=subject_from_saliency(sal)\n",
        "    Y,X=np.indices(sal.shape); w=sal.astype(np.float32)+1\n",
        "    cx,cy=int((X*w).sum()/w.sum()),int((Y*w).sum()/w.sum())\n",
        "    return dict(saliency_map=sal,focal=(cx,cy),subject_mask=sub[\"mask\"],subject_bbox=sub[\"bbox\"])\n",
        "\n",
        "def analyze_composition(img,focal_xy):\n",
        "    g=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "    H,W=g.shape; edges=cv2.Canny(g,100,200)\n",
        "    linesP=cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength=min(H,W)//10,maxLineGap=15)\n",
        "    lines=[tuple(map(int,l[0])) for l in linesP] if linesP is not None else []\n",
        "    fx,fy=focal_xy; golden=0.618\n",
        "    thirds_pts=[(W/3,H/3),(2*W/3,H/3),(W/3,2*H/3),(2*W/3,2*H/3)]\n",
        "    golden_pts=[(golden*W,golden*H),((1-golden)*W,golden*H),(golden*W,(1-golden)*H),((1-golden)*W,(1-golden)*H)]\n",
        "    diag=np.hypot(W,H)\n",
        "    thirds_delta=min(np.hypot(fx-x,fy-y) for (x,y) in thirds_pts)/(diag+1e-6)\n",
        "    golden_delta=min(np.hypot(fx-x,fy-y) for (x,y) in golden_pts)/(diag+1e-6)\n",
        "    g_f=g.astype(np.float32)/255.0\n",
        "    left=g_f[:,:W//2]; right=np.fliplr(g_f[:,W-W//2:])\n",
        "    mse=float(np.mean((left-right)**2)); symmetry=float(1.0-min(1.0,mse*4.0))\n",
        "    lw,rw=float(np.sum(edges[:,:W//2])),float(np.sum(edges[:,W//2:]))\n",
        "    balance=(rw-lw)/(lw+rw+1e-6)\n",
        "    return dict(lines=lines,edge_balance=balance,thirds_delta=thirds_delta,golden_delta=golden_delta,\n",
        "                symmetry=symmetry,vanishing_point=(W//2,H//2))\n",
        "\n",
        "def illumination(img):\n",
        "    L=cv2.cvtColor(img,cv2.COLOR_RGB2LAB)[:,:,0].astype(np.float32)\n",
        "    mu,sig=L.mean(),L.std()+1e-6; skew=float((((L-mu)/sig)**3).mean())\n",
        "    gx,gy=cv2.Sobel(L,cv2.CV_32F,1,0),cv2.Sobel(L,cv2.CV_32F,0,1)\n",
        "    hi=(L>np.percentile(L,90)).astype(np.uint8)\n",
        "    if hi.sum()>0:\n",
        "        gx,gy=(gx*hi).sum(),(gy*hi).sum()\n",
        "        ang=float((degrees(atan2(-gy,-gx))+360)%360)\n",
        "    else: ang=None\n",
        "    return dict(lightness_skew=skew,light_direction_deg=ang)\n",
        "# -----------------------------\n",
        "# Curatorial Summary Generator\n",
        "# -----------------------------\n",
        "def generate_curatorial_summary(M):\n",
        "    C, T, P, I = M[\"color\"], M[\"texture\"], M[\"composition\"], M[\"illumination\"]\n",
        "\n",
        "    tone = {\n",
        "        \"analogous\": \"a restrained, harmonious palette\",\n",
        "        \"complementary\": \"a lively chromatic counterpoint\",\n",
        "    }.get(C[\"harmony\"], \"a balanced and nuanced color range\")\n",
        "\n",
        "    if C[\"mean_deltaE\"] > 25:\n",
        "        contrast = \"strong contrast that energizes the composition\"\n",
        "    elif C[\"mean_deltaE\"] > 10:\n",
        "        contrast = \"moderate contrast that keeps the eye moving\"\n",
        "    else:\n",
        "        contrast = \"gentle tonal transitions that calm the surface\"\n",
        "\n",
        "    texture_phrase = (\n",
        "        f\"Texture reveals directional force (anisotropy {T['gabor_anisotropy']:.2f}) \"\n",
        "        f\"with a dominant orientation near {T['gabor_dom_angle']:.0f}¬∞.\"\n",
        "        if T[\"gabor_anisotropy\"] > 0.5\n",
        "        else \"Texture remains even and diffused, emphasizing balance over motion.\"\n",
        "    )\n",
        "\n",
        "    comp_phrase = (\n",
        "        f\"The focal point aligns with golden proportion (Œî={P['golden_delta']:.3f}).\"\n",
        "        if P[\"golden_delta\"] < 0.12\n",
        "        else f\"The composition loosely follows rule-of-thirds (Œî={P['thirds_delta']:.3f}).\"\n",
        "        if P[\"thirds_delta\"] < 0.12\n",
        "        else \"The composition resists classical proportion, encouraging open visual flow.\"\n",
        "    )\n",
        "\n",
        "    light_phrase = (\n",
        "        f\"Light enters from around {int(I['light_direction_deg'])}¬∞, shaping perception.\"\n",
        "        if I[\"light_direction_deg\"] is not None\n",
        "        else \"Light diffuses evenly, creating tonal unity.\"\n",
        "    )\n",
        "\n",
        "    if I[\"lightness_skew\"] > 0.5:\n",
        "        mood = \"luminous and expansive\"\n",
        "    elif I[\"lightness_skew\"] < -0.5:\n",
        "        mood = \"dark-hued and contemplative\"\n",
        "    else:\n",
        "        mood = \"balanced and calm\"\n",
        "\n",
        "    micro = textwrap.fill(\n",
        "        \" \".join([\n",
        "            f\"Color: {C['harmony']} harmony, mean ŒîE={C['mean_deltaE']:.1f}, max ŒîE={C['max_deltaE']:.1f}, \"\n",
        "            f\"entropy={C['palette_entropy']:.2f}, spatial cohesion={C['spatial_cohesion']:.2f}.\",\n",
        "            f\"Texture: entropy={T['lbp_entropy']:.2f}, anisotropy={T['gabor_anisotropy']:.2f}, \"\n",
        "            f\"dom. angle={T['gabor_dom_angle']:.0f}¬∞.\",\n",
        "            f\"Composition: thirdsŒî={P['thirds_delta']:.3f}, goldenŒî={P['golden_delta']:.3f}, \"\n",
        "            f\"symmetry={P['symmetry']:.2f}, balance={P['edge_balance']:.2f}.\",\n",
        "            f\"Light: skew={I['lightness_skew']:.2f}, direction={I['light_direction_deg']}.\"\n",
        "        ]),\n",
        "        width=90\n",
        "    )\n",
        "\n",
        "    curatorial = textwrap.fill(\n",
        "        \" \".join([\n",
        "            f\"The work presents {tone} with {contrast}.\",\n",
        "            texture_phrase, comp_phrase, light_phrase,\n",
        "            f\"The overall mood feels {mood}.\",\n",
        "            \"Together, these qualities invite a slow, attentive gaze where gesture, color, and balance cohere.\"\n",
        "        ]),\n",
        "        width=90\n",
        "    )\n",
        "\n",
        "    return micro, curatorial\n",
        "\n",
        "# -----------------------------\n",
        "# Visualization / Composite\n",
        "# -----------------------------\n",
        "def make_hue_bar(hist,width=420,height=50):\n",
        "    bar=np.zeros((height,width,3),np.uint8)\n",
        "    for x in range(width):\n",
        "        h=int((x/width)*179)\n",
        "        rgb=cv2.cvtColor(np.uint8([[[h,200,220]]]),cv2.COLOR_HSV2RGB)[0,0]\n",
        "        bar[:,x]=rgb\n",
        "    bins=len(hist); bin_w=max(1,width//bins)\n",
        "    norm=hist/(hist.max()+1e-6)\n",
        "    for i,v in enumerate(norm):\n",
        "        x1=i*bin_w; x2=min(width-1,(i+1)*bin_w-1); h_px=int(v*(height-10))\n",
        "        cv2.rectangle(bar,(x1,height-1),(x2,height-1-h_px),(0,0,0),-1)\n",
        "    return bar\n",
        "\n",
        "def make_orientation_bar(angles,energies,width=420,height=50):\n",
        "    bar=np.full((height,width,3),240,np.uint8)\n",
        "    if len(energies)==0: return bar\n",
        "    e=np.array(energies,dtype=np.float32); e=(e-e.min())/(e.max()-e.min()+1e-6)\n",
        "    for a,v in zip(angles,e):\n",
        "        x=int((a/180.0)*width); h_px=int(v*(height-10))\n",
        "        cv2.rectangle(bar,(x-2,height-1),(x+2,height-1-h_px),(60,60,60),-1)\n",
        "    cv2.putText(bar,\"0¬∞\",(5,18),0,0.5,(0,0,0),1)\n",
        "    cv2.putText(bar,\"90¬∞\",(width//2-15,18),0,0.5,(0,0,0),1)\n",
        "    cv2.putText(bar,\"180¬∞\",(width-50,18),0,0.5,(0,0,0),1)\n",
        "    return bar\n",
        "\n",
        "# -----------------------------\n",
        "# Main Pipeline\n",
        "# -----------------------------\n",
        "def analyze_artwork_high_fidelity(path):\n",
        "    start=time.time()\n",
        "    img=load_rgb(path)\n",
        "    color=analyze_color_deep(img)\n",
        "    texture=analyze_texture(img)\n",
        "    sal=analyze_saliency(img)\n",
        "    comp=analyze_composition(img,sal[\"focal\"])\n",
        "    illum=illumination(img)\n",
        "    M=dict(color=color,texture=texture,saliency=sal,composition=comp,illumination=illum)\n",
        "\n",
        "    # --- Build composite ---\n",
        "    base=img.astype(np.float32)/255.0; H,W=base.shape[:2]\n",
        "    comp_rgb=base.copy()\n",
        "    legend_h=160; legend=np.zeros((legend_h,W,3),np.uint8)\n",
        "    hue_bar=make_hue_bar(color[\"hue_hist\"],width=min(500,max(360,W//2)),height=50)\n",
        "    ori_bar=make_orientation_bar(texture[\"gabor_angles\"],texture[\"gabor_energy\"],\n",
        "                                 width=min(500,max(360,W//2)),height=50)\n",
        "    hb_h,hb_w=hue_bar.shape[:2]; ob_h,ob_w=ori_bar.shape[:2]\n",
        "    x0=max(0,W-max(hb_w,ob_w)-20)\n",
        "    hue_bar_resized=hue_bar[:,:min(hb_w,W-x0)]\n",
        "    ori_bar_resized=ori_bar[:,:min(ob_w,W-x0)]\n",
        "    # safe placement\n",
        "    y1,y2=10,10+hb_h; x1,x2=x0,x0+hue_bar_resized.shape[1]\n",
        "    if y2<=legend.shape[0] and x2<=legend.shape[1]:\n",
        "        legend[y1:y2, x1:x2] = hue_bar_resized\n",
        "    y1b, y2b = 10 + hb_h + 5, 10 + hb_h + 5 + ob_h\n",
        "    x1b, x2b = x0, x0 + ori_bar_resized.shape[1]\n",
        "    if y2b <= legend.shape[0] and x2b <= legend.shape[1]:\n",
        "        legend[y1b:y2b, x1b:x2b] = ori_bar_resized\n",
        "\n",
        "    final = np.vstack([to_uint8(safe_gamma(comp_rgb)), legend])\n",
        "    final = final.astype(np.uint8)\n",
        "\n",
        "    # --- Save Outputs ---\n",
        "    out_dir = os.path.splitext(path)[0] + \"_analysis\"\n",
        "    ensure_dir(out_dir)\n",
        "    out_png = os.path.join(out_dir, \"overlay_final_composite.png\")\n",
        "    cv2.imwrite(out_png, final)\n",
        "\n",
        "    # Curatorial Text\n",
        "    micro, narrative = generate_curatorial_summary(M)\n",
        "    out_txt = os.path.join(out_dir, \"curatorial_summary.txt\")\n",
        "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"--- MICRO SUMMARY ---\\n\")\n",
        "        f.write(micro + \"\\n\\n--- CURATORIAL SUMMARY ---\\n\")\n",
        "        f.write(narrative + \"\\n\")\n",
        "\n",
        "    # Metrics JSON (safe serialization for NumPy types)\n",
        "    def make_json_safe(obj):\n",
        "        if isinstance(obj, dict):\n",
        "            return {k: make_json_safe(v) for k, v in obj.items()}\n",
        "        elif isinstance(obj, (list, tuple)):\n",
        "            return [make_json_safe(x) for x in obj]\n",
        "        elif isinstance(obj, (np.generic, np.number)):\n",
        "            return obj.item()\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        else:\n",
        "            return obj\n",
        "\n",
        "    metrics_py = make_json_safe(M)\n",
        "    out_json = os.path.join(out_dir, \"metrics.json\")\n",
        "    with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metrics_py, f, indent=2)\n",
        "\n",
        "    print(f\"‚úÖ Analysis complete for: {os.path.basename(path)}\")\n",
        "    print(f\"üìÅ Results saved to: {out_dir}\")\n",
        "    print(f\"‚è±Ô∏è  Elapsed: {time.time() - start:.2f}s\")\n",
        "\n",
        "# -----------------------------\n",
        "# Run\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    IMAGE_PATH = \"/Users/alievanayasso/Documents/SlowMA/VG_-_skeleton.jpg\"\n",
        "    analyze_artwork_high_fidelity(IMAGE_PATH)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
