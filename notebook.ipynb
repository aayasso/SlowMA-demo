{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🖼️ Loading image: /Users/alievanayasso/Documents/SlowMA/Raymond-Simboli-.jpg\n",
            "   • Image size: 1140×797\n",
            "   • Rescaled for fidelity: 1512×1057\n",
            "🎨 Running color analysis… ✓\n",
            "🪶 Running texture analysis… ✓\n",
            "🔥 Running saliency analysis… ✓\n",
            "📐 Running composition analysis… ✓\n",
            "💡 Running illumination analysis… ✓\n",
            "🌐 Building ROI interest map… ✓\n",
            "🔍 Extracting regions of interest… 3 regions ✓\n",
            "🖋️ Writing curatorial summary… ✓\n",
            "💡 Rendering combined ROI overlay… ✓\n",
            "💡 Rendering individual ROI overlays… ✓\n",
            "💾 Writing metrics and summaries… ✓\n",
            "📁 All ROI outputs saved to: /Users/alievanayasso/Documents/SlowMA/Raymond-Simboli-_analysis\n",
            "\n",
            "✅ Complete! Total runtime: 3.99s\n",
            "📁 Outputs saved to: /Users/alievanayasso/Documents/SlowMA/Raymond-Simboli-_analysis\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Artwork Analyzer v19 — Dynamic ROI-Only Pipeline (Stable)\n",
        "# ==========================================================\n",
        "# • Fully local (OpenCV + NumPy + Pillow)\n",
        "# • Detects 2–5 adaptive Regions of Interest (ROIs)\n",
        "# • Each ROI overlay includes its own bespoke paragraph\n",
        "# • Combined ROI overlay includes all summaries\n",
        "# • Outputs: ROI images + combined overlay + summary.txt + metrics.json\n",
        "# ==========================================================\n",
        "\n",
        "import os, json, time, math, textwrap\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from math import atan2, degrees\n",
        "from pathlib import Path\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Utility Functions\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "def ensure_dir(p):\n",
        "    \"\"\"Create directory (and parents) reliably.\"\"\"\n",
        "    Path(p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def load_rgb(path):\n",
        "    \"\"\"Load image as RGB numpy array.\"\"\"\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    return np.array(img)\n",
        "\n",
        "def to_uint8(img_f32):\n",
        "    \"\"\"Convert float [0, 1] → uint8 safely.\"\"\"\n",
        "    return np.clip(img_f32 * 255, 0, 255).astype(np.uint8)\n",
        "\n",
        "def safe_gamma(img_u8):\n",
        "    \"\"\"Soft gamma correction for display readability.\"\"\"\n",
        "    img = img_u8.astype(np.float32) / 255.0\n",
        "    mean_bright = float(img.mean())\n",
        "    if mean_bright < 0.25:\n",
        "        img = np.power(img, 0.75)\n",
        "    elif mean_bright > 0.8:\n",
        "        img = np.power(img, 1.1)\n",
        "    return to_uint8(np.clip(img, 0, 1))\n",
        "\n",
        "def resize_for_fidelity(img, target_pixels=1_600_000):\n",
        "    \"\"\"Upscale small artworks to improve analysis fidelity.\"\"\"\n",
        "    H, W = img.shape[:2]\n",
        "    cur = H * W\n",
        "    if cur >= target_pixels:\n",
        "        return img, 1.0\n",
        "    scale = math.sqrt(target_pixels / cur)\n",
        "    newW, newH = int(W * scale), int(H * scale)\n",
        "    resized = cv2.resize(img, (newW, newH), interpolation=cv2.INTER_CUBIC)\n",
        "    return resized, scale\n",
        "\n",
        "def json_safe(obj):\n",
        "    \"\"\"Convert numpy objects into JSON-serializable types.\"\"\"\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: json_safe(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, (list, tuple)):\n",
        "        return [json_safe(x) for x in obj]\n",
        "    elif isinstance(obj, (np.generic, np.number)):\n",
        "        return obj.item()\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    else:\n",
        "        return obj\n",
        "# ==========================================================\n",
        "# Color & Texture Analysis (local only)\n",
        "# ==========================================================\n",
        "\n",
        "def ciede2000(Lab1, Lab2):\n",
        "    \"\"\"CIEDE2000 color difference between two LAB triplets.\"\"\"\n",
        "    L1,a1,b1 = Lab1; L2,a2,b2 = Lab2\n",
        "    C1 = np.sqrt(a1*a1 + b1*b1); C2 = np.sqrt(a2*a2 + b2*b2)\n",
        "    avg_C = (C1 + C2) / 2.0\n",
        "    G = 0.5 * (1 - np.sqrt((avg_C**7) / ((avg_C**7) + 25**7)))\n",
        "    a1p, a2p = (1 + G)*a1, (1 + G)*a2\n",
        "    C1p, C2p = np.sqrt(a1p*a1p + b1*b1), np.sqrt(a2p*a2p + b2*b2)\n",
        "    h1p = (np.degrees(np.arctan2(b1,a1p)) + 360) % 360\n",
        "    h2p = (np.degrees(np.arctan2(b2,a2p)) + 360) % 360\n",
        "    dLp, dCp = L2 - L1, C2p - C1p\n",
        "    dhp = h2p - h1p\n",
        "    if C1p*C2p == 0: dhp = 0\n",
        "    elif dhp > 180: dhp -= 360\n",
        "    elif dhp < -180: dhp += 360\n",
        "    dHp = 2*np.sqrt(C1p*C2p) * np.sin(np.radians(dhp)/2)\n",
        "    avg_Lp = (L1 + L2)/2.0\n",
        "    avg_Cp = (C1p + C2p)/2.0\n",
        "    avg_hp = (h1p + h2p)/2.0 if abs(h1p - h2p) <= 180 else (h1p + h2p + 360)/2.0\n",
        "    T = (1 - 0.17*np.cos(np.radians(avg_hp - 30))\n",
        "         + 0.24*np.cos(np.radians(2*avg_hp))\n",
        "         + 0.32*np.cos(np.radians(3*avg_hp + 6))\n",
        "         - 0.20*np.cos(np.radians(4*avg_hp - 63)))\n",
        "    d_ro = 30*np.exp(-((avg_hp - 275)/25)**2)\n",
        "    Rc = 2*np.sqrt((avg_Cp**7)/((avg_Cp**7) + 25**7))\n",
        "    Sl = 1 + (0.015*(avg_Lp - 50)**2)/np.sqrt(20 + (avg_Lp - 50)**2)\n",
        "    Sc, Sh = 1 + 0.045*avg_Cp, 1 + 0.015*avg_Cp*T\n",
        "    Rt = -np.sin(np.radians(2*d_ro))*Rc\n",
        "    return float(np.sqrt((dLp/Sl)**2 + (dCp/Sc)**2 + (dHp/Sh)**2 + Rt*(dCp/Sc)*(dHp/Sh)))\n",
        "\n",
        "def color_analysis(img, k=8):\n",
        "    \"\"\"Extract main palette, color diversity, and harmony.\"\"\"\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "    H, W = lab.shape[:2]\n",
        "    Z = lab.reshape(-1,3).astype(np.float32)\n",
        "    crit = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 60, 0.2)\n",
        "    _, labels, centers = cv2.kmeans(Z, k, None, crit, 6, cv2.KMEANS_PP_CENTERS)\n",
        "    centers = centers.astype(np.float32)\n",
        "    counts = np.bincount(labels.flatten(), minlength=k).astype(np.float32)\n",
        "    frac = counts / (H*W + 1e-6)\n",
        "\n",
        "    a,b = centers[:,1]-128, centers[:,2]-128\n",
        "    hues = (np.degrees(np.arctan2(b,a)) + 360) % 360\n",
        "    warm_ratio = float(((hues<90)|(hues>330)).sum()/len(hues))\n",
        "    cool_ratio = float(((hues>180)&(hues<300)).sum()/len(hues))\n",
        "    if np.ptp(hues) < 30:\n",
        "        harmony = \"analogous\"\n",
        "    elif any(abs(hues[i]-hues[j])%360>150 for i in range(len(hues)) for j in range(i+1,len(hues))):\n",
        "        harmony = \"complementary\"\n",
        "    else:\n",
        "        harmony = \"mixed\"\n",
        "\n",
        "    dEs = [ciede2000(centers[i], centers[j]) for i in range(len(centers)) for j in range(i+1,len(centers))]\n",
        "    mean_dE = float(np.mean(dEs))\n",
        "    entropy = -float(np.sum(frac[frac>0]*np.log2(frac[frac>0])))\n",
        "\n",
        "    return dict(\n",
        "        palette_lab=centers.tolist(),\n",
        "        mean_deltaE=mean_dE,\n",
        "        warm_ratio=warm_ratio,\n",
        "        cool_ratio=cool_ratio,\n",
        "        harmony=harmony,\n",
        "        entropy=entropy\n",
        "    )\n",
        "\n",
        "def texture_analysis(gray):\n",
        "    \"\"\"Basic surface texture measure (entropy + anisotropy).\"\"\"\n",
        "    gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0)\n",
        "    gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1)\n",
        "    mag = np.sqrt(gx*gx + gy*gy)\n",
        "    ang = (np.degrees(np.arctan2(gy, gx)) + 180) % 180\n",
        "    hist, _ = np.histogram(ang, bins=18, range=(0,180))\n",
        "    anisotropy = float((hist.max() - hist.min()) / (hist.mean() + 1e-6))\n",
        "    mag_norm = (mag - mag.min()) / (mag.max() - mag.min() + 1e-6)\n",
        "    return dict(\n",
        "        texture_map=mag_norm,\n",
        "        texture_anisotropy=anisotropy,\n",
        "        texture_mean=float(mag_norm.mean()),\n",
        "        texture_std=float(mag_norm.std())\n",
        "    )\n",
        "# ==========================================================\n",
        "# Saliency & Composition Analysis\n",
        "# ==========================================================\n",
        "\n",
        "def spectral_saliency(gray):\n",
        "    \"\"\"Compute spectral residual saliency map (frequency domain).\"\"\"\n",
        "    grayf = gray.astype(np.float32)\n",
        "    fft = np.fft.fft2(grayf)\n",
        "    log_amp = np.log(np.abs(fft) + 1e-8)\n",
        "    phase = np.angle(fft)\n",
        "    spectral_residual = log_amp - cv2.blur(log_amp, (3,3))\n",
        "    saliency = np.abs(np.fft.ifft2(np.exp(spectral_residual + 1j*phase)))**2\n",
        "    saliency = cv2.GaussianBlur(saliency, (7,7), 2.0)\n",
        "    saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min() + 1e-6)\n",
        "    return saliency\n",
        "\n",
        "def saliency_analysis(img):\n",
        "    \"\"\"Find areas that naturally draw attention.\"\"\"\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    sal = spectral_saliency(gray)\n",
        "    m = cv2.threshold((sal*255).astype(np.uint8), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "    cnts,_ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if cnts:\n",
        "        x,y,w,h = cv2.boundingRect(max(cnts, key=cv2.contourArea))\n",
        "    else:\n",
        "        H,W = gray.shape\n",
        "        x,y,w,h = W//4,H//4,W//2,H//2\n",
        "    Y,X = np.indices(sal.shape)\n",
        "    wgt = sal + 1e-6\n",
        "    cx, cy = int((X*wgt).sum()/wgt.sum()), int((Y*wgt).sum()/wgt.sum())\n",
        "    return dict(\n",
        "        saliency_map=sal,\n",
        "        focal=(cx,cy),\n",
        "        subject_bbox=(x,y,w,h),\n",
        "        subject_mask=m\n",
        "    )\n",
        "\n",
        "def composition_analysis(img, focal):\n",
        "    \"\"\"Detect structure using edges and Hough lines.\"\"\"\n",
        "    g = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    edges = cv2.Canny(g, 80, 180)\n",
        "    linesP = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=60, maxLineGap=12)\n",
        "    lines = []\n",
        "    if linesP is not None:\n",
        "        for l in linesP[:200]:\n",
        "            x1,y1,x2,y2 = map(int, l[0])\n",
        "            lines.append((x1,y1,x2,y2))\n",
        "\n",
        "    H, W = g.shape\n",
        "    mid = W // 2\n",
        "    left = g[:, :mid].astype(np.float32)\n",
        "    right = np.fliplr(g[:, mid:].astype(np.float32))\n",
        "    min_w = min(left.shape[1], right.shape[1])\n",
        "    if min_w > 0:\n",
        "        left = left[:, :min_w]\n",
        "        right = right[:, :min_w]\n",
        "        mse = float(np.mean((left - right) ** 2))\n",
        "    else:\n",
        "        mse = 0.0\n",
        "\n",
        "    symmetry = 1.0 - min(1.0, mse * 3.0)\n",
        "    lw = float(np.sum(edges[:, :mid]))\n",
        "    rw = float(np.sum(edges[:, mid:]))\n",
        "    balance = (rw - lw) / (rw + lw + 1e-6)\n",
        "\n",
        "    fx, fy = focal\n",
        "    thirds_pts = [(W/3, H/3), (2*W/3, H/3), (W/3, 2*H/3), (2*W/3, 2*H/3)]\n",
        "    diag = np.hypot(W, H)\n",
        "    thirds_delta = min(np.hypot(fx - x, fy - y) for x, y in thirds_pts) / (diag + 1e-6)\n",
        "\n",
        "    return dict(\n",
        "        lines=lines,\n",
        "        symmetry=symmetry,\n",
        "        balance=balance,\n",
        "        thirds_delta=thirds_delta\n",
        "    )\n",
        "# ==========================================================\n",
        "# Illumination & Light Direction Analysis\n",
        "# ==========================================================\n",
        "\n",
        "def illumination_analysis(img):\n",
        "    \"\"\"Analyze light direction and tonal skew in LAB space.\"\"\"\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "    L = lab[:,:,0].astype(np.float32)\n",
        "    mu, sigma = L.mean(), L.std() + 1e-6\n",
        "    skew = float((((L - mu) / sigma) ** 3).mean())\n",
        "\n",
        "    gx = cv2.Sobel(L, cv2.CV_32F, 1, 0)\n",
        "    gy = cv2.Sobel(L, cv2.CV_32F, 0, 1)\n",
        "    hi_mask = (L > np.percentile(L, 90)).astype(np.uint8)\n",
        "    if hi_mask.sum() > 0:\n",
        "        gx_sum = float((gx * hi_mask).sum())\n",
        "        gy_sum = float((gy * hi_mask).sum())\n",
        "        ang = float((degrees(atan2(-gy_sum, -gx_sum)) + 360) % 360)\n",
        "    else:\n",
        "        ang = None\n",
        "\n",
        "    return dict(\n",
        "        light_skew=skew,\n",
        "        light_direction_deg=ang\n",
        "    )\n",
        "\n",
        "def light_description(I):\n",
        "    \"\"\"Create friendly narrative description of illumination.\"\"\"\n",
        "    skew = I.get(\"light_skew\", 0)\n",
        "    ang = I.get(\"light_direction_deg\", None)\n",
        "\n",
        "    if ang is None:\n",
        "        direction_phrase = \"diffused evenly across the surface\"\n",
        "    elif 45 <= ang <= 135:\n",
        "        direction_phrase = \"entering softly from the top\"\n",
        "    elif 135 < ang <= 225:\n",
        "        direction_phrase = \"settling in from the left\"\n",
        "    elif 225 < ang <= 315:\n",
        "        direction_phrase = \"flowing across from the bottom\"\n",
        "    else:\n",
        "        direction_phrase = \"illuminating gently from the right\"\n",
        "\n",
        "    if skew > 0.6:\n",
        "        tone_phrase = \"bright and airy\"\n",
        "    elif skew < -0.6:\n",
        "        tone_phrase = \"dim and contemplative\"\n",
        "    else:\n",
        "        tone_phrase = \"balanced in tone\"\n",
        "\n",
        "    return f\"The overall lighting feels {tone_phrase}, {direction_phrase}.\"\n",
        "# ==========================================================\n",
        "# ROI Interest Map Construction (Dynamic Fusion)\n",
        "# ==========================================================\n",
        "\n",
        "def _norm01(x):\n",
        "    x = np.asarray(x, np.float32)\n",
        "    mn, mx = x.min(), x.max()\n",
        "    if mx - mn < 1e-6:\n",
        "        return np.zeros_like(x, np.float32)\n",
        "    return (x - mn) / (mx - mn)\n",
        "\n",
        "def _gaussian_bump(H, W, cx, cy, sigma_frac=0.25):\n",
        "    \"\"\"Return a soft Gaussian map centered at (cx,cy).\"\"\"\n",
        "    yy, xx = np.indices((H, W))\n",
        "    d2 = (xx - cx)**2 + (yy - cy)**2\n",
        "    diag = np.hypot(H, W)\n",
        "    sigma = sigma_frac * diag\n",
        "    g = np.exp(-d2 / (2.0 * sigma**2 + 1e-6))\n",
        "    return _norm01(g)\n",
        "# ==========================================================\n",
        "# Text Wrapping Helper\n",
        "# ==========================================================\n",
        "import textwrap\n",
        "\n",
        "def wrap_text_lines(text, width_chars=48):\n",
        "    \"\"\"\n",
        "    Cleanly wrap text to multiple lines for OpenCV rendering.\n",
        "    Keeps summaries readable and avoids overflow.\n",
        "    \"\"\"\n",
        "    text = text.strip().replace(\"\\n\", \" \")\n",
        "    lines = textwrap.wrap(text, width=width_chars)\n",
        "    return [ln.strip() for ln in lines if ln.strip()]\n",
        "\n",
        "\n",
        "def _line_density_map(H, W, lines, blur=2.0):\n",
        "    \"\"\"Rasterize all composition lines into a soft density map.\"\"\"\n",
        "    m = np.zeros((H, W), np.uint8)\n",
        "    if lines:\n",
        "        for (x1,y1,x2,y2) in lines:\n",
        "            cv2.line(m, (x1,y1), (x2,y2), 255, 1, cv2.LINE_AA)\n",
        "    m = cv2.GaussianBlur(m, (0,0), blur)\n",
        "    return _norm01(m)\n",
        "\n",
        "def roi_interest_map(C, T, S, P, I, shape):\n",
        "    \"\"\"\n",
        "    Combine all analytic maps into a unified interest heatmap.\n",
        "    Dynamically weights signals depending on image complexity.\n",
        "    \"\"\"\n",
        "    H, W = shape\n",
        "    sal = _norm01(S.get(\"saliency_map\", np.zeros((H, W), np.float32)))\n",
        "    tex = _norm01(T.get(\"texture_map\", np.zeros((H, W), np.float32)))\n",
        "    line_density = _line_density_map(H, W, P.get(\"lines\", []))\n",
        "    contrast_proxy = np.zeros_like(sal)\n",
        "    focal = S.get(\"focal\", (W//2, H//2))\n",
        "    prox_focal = _gaussian_bump(H, W, *focal, sigma_frac=0.25)\n",
        "    prox_light = _gaussian_bump(H, W, W/2, H/2, sigma_frac=0.3) if I.get(\"light_direction_deg\") else np.zeros_like(sal)\n",
        "\n",
        "    # Adaptive weighting with robust defaults\n",
        "    tex_std = float(T.get(\"texture_std\", 0.1))\n",
        "    mean_dE = float(C.get(\"mean_deltaE\", 10.0))\n",
        "    line_complex = np.tanh(len(P.get(\"lines\", [])) / 150.0)\n",
        "    tex_complex = np.tanh(tex_std * 4.0)\n",
        "    contrast_wt = np.tanh(mean_dE / 25.0)\n",
        "\n",
        "    w_sal = 0.4\n",
        "    w_tex = 0.25 * (1 + 0.2*tex_complex)\n",
        "    w_line = 0.15 * (1 + 0.2*line_complex)\n",
        "    w_contrast = 0.15 * (1 + 0.2*contrast_wt)\n",
        "    w_light = 0.05\n",
        "\n",
        "    w_sum = w_sal + w_tex + w_line + w_contrast + w_light\n",
        "    w_sal /= w_sum; w_tex /= w_sum; w_line /= w_sum; w_contrast /= w_sum; w_light /= w_sum\n",
        "\n",
        "    fused = (w_sal * sal +\n",
        "             w_tex * tex +\n",
        "             w_line * line_density +\n",
        "             w_contrast * contrast_proxy +\n",
        "             w_light * prox_light +\n",
        "             0.1 * prox_focal)\n",
        "\n",
        "    fused = cv2.GaussianBlur(fused, (0,0), 1.0)\n",
        "    return _norm01(fused)\n",
        "# ==========================================================\n",
        "# ROI Detection (Peaks + Separation) & Per-Region Factors\n",
        "# ==========================================================\n",
        "\n",
        "def _prepare_roi_inputs(C, T, S, P, I, shape):\n",
        "    \"\"\"Normalize and adapt analysis results for ROI fusion.\"\"\"\n",
        "    H, W = shape\n",
        "\n",
        "    # Texture map\n",
        "    tmap = T.get(\"texture_map\", np.zeros((H, W), np.float32))\n",
        "    if tmap.shape[:2] != (H, W):\n",
        "        tmap = cv2.resize(tmap, (W, H), interpolation=cv2.INTER_CUBIC)\n",
        "    T2 = dict(texture_map=_norm01(tmap), texture_std=T.get(\"texture_std\", 0.1))\n",
        "\n",
        "    # Contrast proxy\n",
        "    cmap = C.get(\"contrast_map\", np.zeros((H, W), np.float32))\n",
        "    if cmap.shape[:2] != (H, W):\n",
        "        cmap = cv2.resize(cmap, (W, H), interpolation=cv2.INTER_CUBIC)\n",
        "    C2 = dict(mean_deltaE=float(C.get(\"mean_deltaE\", 10.0)),\n",
        "              contrast_map=_norm01(cmap))\n",
        "\n",
        "    # Saliency\n",
        "    smap = S.get(\"saliency_map\", np.zeros((H, W), np.float32))\n",
        "    if smap.shape[:2] != (H, W):\n",
        "        smap = cv2.resize(smap, (W, H), interpolation=cv2.INTER_CUBIC)\n",
        "    S2 = dict(saliency_map=_norm01(smap),\n",
        "              focal=S.get(\"focal\", (W//2, H//2)))\n",
        "\n",
        "    # Composition\n",
        "    P2 = dict(lines=P.get(\"lines\", []),\n",
        "              vanishing_point=P.get(\"vanishing_point\", (W/2, H/2)))\n",
        "\n",
        "    # Illumination\n",
        "    I2 = dict(light_direction_deg=I.get(\"light_direction_deg\", None))\n",
        "\n",
        "    return C2, T2, S2, P2, I2\n",
        "\n",
        "\n",
        "def _roi_component_maps(C2, T2, S2, P2, I2, shape):\n",
        "    \"\"\"Recreate component maps used in interest fusion.\"\"\"\n",
        "    H, W = shape\n",
        "    sal = _norm01(S2[\"saliency_map\"])\n",
        "    tex = _norm01(T2[\"texture_map\"])\n",
        "    con = _norm01(C2[\"contrast_map\"])\n",
        "\n",
        "    fx, fy = S2[\"focal\"]\n",
        "    prox_focal = _gaussian_bump(H, W, fx, fy, sigma_frac=0.23)\n",
        "    vx, vy = P2.get(\"vanishing_point\", (W/2, H/2))\n",
        "    prox_vp = _gaussian_bump(H, W, vx, vy, sigma_frac=0.28)\n",
        "    line_density = _line_density_map(H, W, P2.get(\"lines\", []))\n",
        "\n",
        "    return dict(sal=sal, tex=tex, con=con,\n",
        "                prox_focal=prox_focal, prox_vp=prox_vp, line=line_density)\n",
        "\n",
        "\n",
        "def _find_peak_centers(interest, min_dist):\n",
        "    \"\"\"Find peak centers in the interest map with distance constraint.\"\"\"\n",
        "    H, W = interest.shape\n",
        "    blur = cv2.GaussianBlur(interest, (0, 0), 1.2)\n",
        "    maxf = cv2.dilate(blur, np.ones((5,5), np.uint8))\n",
        "    peaks = (blur >= maxf - 1e-6).astype(np.uint8)\n",
        "    thr = np.percentile(blur, 92)\n",
        "    peaks = (peaks & (blur >= thr)).astype(np.uint8)\n",
        "\n",
        "    ys, xs = np.where(peaks > 0)\n",
        "    if len(xs) == 0:\n",
        "        return [(W//2, H//2)]\n",
        "\n",
        "    pts = sorted(list(zip(xs, ys)), key=lambda p: interest[p[1], p[0]], reverse=True)\n",
        "    selected = []\n",
        "    for (x, y) in pts:\n",
        "        if all(np.hypot(x - sx, y - sy) >= min_dist for (sx, sy) in selected):\n",
        "            selected.append((x, y))\n",
        "    return selected\n",
        "\n",
        "\n",
        "def extract_regions_of_interest(interest_map, component_maps, n_min=2, n_max=5):\n",
        "    \"\"\"Extract ROIs and compute per-region factor scores.\"\"\"\n",
        "    H, W = interest_map.shape\n",
        "    im = _norm01(interest_map)\n",
        "\n",
        "    spread = float(im.std())\n",
        "    k_est = 2 + int(np.clip(spread * 8.0, 0, 3))  # 2–5 adaptive\n",
        "    k = int(np.clip(k_est, n_min, n_max))\n",
        "\n",
        "    min_dist = int(min(H, W) * 0.22)\n",
        "    centers = _find_peak_centers(im, min_dist)\n",
        "    if len(centers) < k:\n",
        "        k = max(n_min, min(len(centers), n_max))\n",
        "    centers = centers[:k]\n",
        "\n",
        "    base_r = int(min(H, W) * 0.14)\n",
        "    rois = []\n",
        "    for (cx, cy) in centers:\n",
        "        r = base_r\n",
        "        x1, y1 = max(0, cx - r), max(0, cy - r)\n",
        "        x2, y2 = min(W, cx + r), min(H, cy + r)\n",
        "        patch = im[y1:y2, x1:x2]\n",
        "        score = float(patch.mean()) if patch.size else 0.0\n",
        "\n",
        "        factors = {}\n",
        "        for key, m in component_maps.items():\n",
        "            roi_m = m[y1:y2, x1:x2]\n",
        "            factors[key] = float(roi_m.mean()) if roi_m.size else 0.0\n",
        "\n",
        "        rois.append(dict(center=(cx, cy),\n",
        "                         bbox=(x1, y1, x2 - x1, y2 - y1),\n",
        "                         score=score,\n",
        "                         factors=factors))\n",
        "\n",
        "    rois.sort(key=lambda r: r[\"score\"], reverse=True)\n",
        "    return rois\n",
        "# ==========================================================\n",
        "# ROI Overlay Rendering (Shaded Regions + Auto-Text Labels)\n",
        "# ==========================================================\n",
        "\n",
        "ROI_COLORS = [\n",
        "    (255, 80, 80),\n",
        "    (255, 200, 50),\n",
        "    (80, 255, 120),\n",
        "    (80, 200, 255),\n",
        "    (255, 120, 220),\n",
        "]\n",
        "\n",
        "def _measure_text(img, text, font=cv2.FONT_HERSHEY_SIMPLEX, scale=0.6, thickness=1):\n",
        "    (w, h), _ = cv2.getTextSize(text, font, scale, thickness)\n",
        "    return w, h\n",
        "\n",
        "def _draw_label_box(img, x, y, w, h, alpha=0.82):\n",
        "    \"\"\"Draw semi-transparent black box for text.\"\"\"\n",
        "    H, W = img.shape[:2]\n",
        "    x2, y2 = min(W, x + w), min(H, y + h)\n",
        "    roi = img[y:y2, x:x2].astype(np.float32)\n",
        "    overlay = np.zeros_like(roi)\n",
        "    blended = (1 - alpha) * roi + alpha * overlay\n",
        "    img[y:y2, x:x2] = np.clip(blended, 0, 255).astype(np.uint8)\n",
        "    cv2.rectangle(img, (x, y), (x2, y2), (255, 255, 255), 1, cv2.LINE_AA)\n",
        "\n",
        "def _put_label_lines(img, x, y, lines, leading=20, color=(255, 255, 255)):\n",
        "    \"\"\"Render wrapped text lines inside label box.\"\"\"\n",
        "    f = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    for i, line in enumerate(lines):\n",
        "        cv2.putText(img, line, (x + 8, y + 18 + i * leading), f, 0.55, color, 1, cv2.LINE_AA)\n",
        "\n",
        "def _choose_label_rect(img_shape, bbox, used, text_lines, pad=6):\n",
        "    \"\"\"Select label placement to avoid overlaps.\"\"\"\n",
        "    H, W = img_shape[:2]\n",
        "    f = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    line_w = [cv2.getTextSize(t, f, 0.55, 1)[0][0] for t in text_lines]\n",
        "    box_w = max(140, min(W - 12, max(line_w) + 16))\n",
        "    box_h = 12 + 20 * len(text_lines)\n",
        "\n",
        "    x, y, w, h = bbox\n",
        "    cx, cy = x + w // 2, y + h // 2\n",
        "    candidates = [\n",
        "        (x, max(6, y - box_h - 8)),                # above\n",
        "        (x, min(H - box_h - 6, y + h + 8)),        # below\n",
        "        (min(W - box_w - 6, x + w + 8), max(6, y)),# right\n",
        "        (max(6, x - box_w - 8), max(6, y)),        # left\n",
        "        (min(W - box_w - 6, x + 6), min(H - box_h - 6, y + 6)),  # inside\n",
        "    ]\n",
        "\n",
        "    def overlaps(a, b):\n",
        "        ax1, ay1, ax2, ay2 = a[0], a[1], a[0] + box_w, a[1] + box_h\n",
        "        bx1, by1, bx2, by2 = b\n",
        "        return not (ax2 < bx1 or bx2 < ax1 or ay2 < by1 or by2 < ay1)\n",
        "\n",
        "    for (lx, ly) in candidates:\n",
        "        lx = int(np.clip(lx, 6, W - box_w - 6))\n",
        "        ly = int(np.clip(ly, 6, H - box_h - 6))\n",
        "        rect = (lx, ly, lx + box_w, ly + box_h)\n",
        "        if not any(overlaps((lx, ly), u) for u in used):\n",
        "            used.append(rect)\n",
        "            return lx, ly, box_w, box_h\n",
        "\n",
        "    lx, ly = 8, min(H - box_h - 8, 8 + len(used) * (box_h + 8))\n",
        "    rect = (lx, ly, lx + box_w, ly + box_h)\n",
        "    used.append(rect)\n",
        "    return lx, ly, box_w, box_h\n",
        "\n",
        "def _summarize_roi_naturally(i, roi, C, T, S, P, I):\n",
        "    \"\"\"Generate short descriptive text for each ROI.\"\"\"\n",
        "    f = roi[\"factors\"]\n",
        "    keys = [\"sal\", \"tex\", \"con\", \"line\", \"prox_focal\", \"prox_vp\"]\n",
        "    ranked = sorted(keys, key=lambda k: f.get(k, 0.0), reverse=True)\n",
        "    top = ranked[:2]\n",
        "\n",
        "    tone_color = (\n",
        "        \"quiet transitions\" if C[\"mean_deltaE\"] < 10 else\n",
        "        \"measured contrast\" if C[\"mean_deltaE\"] < 20 else\n",
        "        \"confident contrast\"\n",
        "    )\n",
        "\n",
        "    tex_snip = (\n",
        "        \"a calm surface\" if T.get(\"texture_std\", 0.1) < 0.25 else\n",
        "        \"a sense of tactile movement\"\n",
        "    )\n",
        "\n",
        "    light_snip = (\n",
        "        f\"subtly shaped by light from ~{int(I['light_direction_deg'])}°\"\n",
        "        if I.get(\"light_direction_deg\") is not None else\n",
        "        \"bathed in diffuse light\"\n",
        "    )\n",
        "\n",
        "    H, W = S[\"saliency_map\"].shape\n",
        "    x, y, w, h = roi[\"bbox\"]\n",
        "    cx, cy = x + w / 2, y + h / 2\n",
        "    vertical = \"upper\" if cy < H / 2 else \"lower\"\n",
        "    horizontal = \"left\" if cx < W / 2 else \"right\"\n",
        "    zone = f\"{vertical}-{horizontal}\"\n",
        "\n",
        "    lead = {\n",
        "        \"sal\": \"Naturally eye-catching,\",\n",
        "        \"tex\": \"Texturally rich,\",\n",
        "        \"con\": \"Colorfully assertive,\",\n",
        "        \"line\": \"Structurally charged,\",\n",
        "        \"prox_focal\": \"Close to the focal center,\",\n",
        "        \"prox_vp\": \"Aligned with perspective,\",\n",
        "    }.get(top[0], \"Visually distinct,\")\n",
        "\n",
        "    second = {\n",
        "        \"sal\": \"it draws attention instantly.\",\n",
        "        \"tex\": \"the surface carries movement.\",\n",
        "        \"con\": f\"tones meet with {tone_color}.\",\n",
        "        \"line\": \"linework guides the gaze.\",\n",
        "        \"prox_focal\": \"it reinforces the main subject.\",\n",
        "        \"prox_vp\": \"the geometry feels ordered.\",\n",
        "    }.get(top[1] if len(top) > 1 else top[0], \"the details hold attention.\")\n",
        "\n",
        "    endings = [\n",
        "        \"the area rewards a slower look.\",\n",
        "        f\"Here there's {tex_snip}.\",\n",
        "        f\"It feels {light_snip}.\",\n",
        "        \"it feels resolved yet alive.\",\n",
        "    ]\n",
        "    tail = endings[i % len(endings)]\n",
        "\n",
        "    return f\"{lead} this {zone} region balances where {second} {tail}\"\n",
        "# ==========================================================\n",
        "# ROI Overlay Rendering (Shaded Regions + Auto-Text Labels)\n",
        "# ==========================================================\n",
        "\n",
        "ROI_COLORS = [\n",
        "    (255, 80, 80),\n",
        "    (255, 200, 50),\n",
        "    (80, 255, 120),\n",
        "    (80, 200, 255),\n",
        "    (255, 120, 220),\n",
        "]\n",
        "\n",
        "def _measure_text(img, text, font=cv2.FONT_HERSHEY_SIMPLEX, scale=0.6, thickness=1):\n",
        "    (w, h), _ = cv2.getTextSize(text, font, scale, thickness)\n",
        "    return w, h\n",
        "\n",
        "def _draw_label_box(img, x, y, w, h, alpha=0.82):\n",
        "    \"\"\"Draw semi-transparent black box for text.\"\"\"\n",
        "    H, W = img.shape[:2]\n",
        "    x2, y2 = min(W, x + w), min(H, y + h)\n",
        "    roi = img[y:y2, x:x2].astype(np.float32)\n",
        "    overlay = np.zeros_like(roi)\n",
        "    blended = (1 - alpha) * roi + alpha * overlay\n",
        "    img[y:y2, x:x2] = np.clip(blended, 0, 255).astype(np.uint8)\n",
        "    cv2.rectangle(img, (x, y), (x2, y2), (255, 255, 255), 1, cv2.LINE_AA)\n",
        "\n",
        "def _put_label_lines(img, x, y, lines, leading=20, color=(255, 255, 255)):\n",
        "    \"\"\"Render wrapped text lines inside label box.\"\"\"\n",
        "    f = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    for i, line in enumerate(lines):\n",
        "        cv2.putText(img, line, (x + 8, y + 18 + i * leading), f, 0.55, color, 1, cv2.LINE_AA)\n",
        "\n",
        "def _choose_label_rect(img_shape, bbox, used, text_lines, pad=6):\n",
        "    \"\"\"Select label placement to avoid overlaps.\"\"\"\n",
        "    H, W = img_shape[:2]\n",
        "    f = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    line_w = [cv2.getTextSize(t, f, 0.55, 1)[0][0] for t in text_lines]\n",
        "    box_w = max(140, min(W - 12, max(line_w) + 16))\n",
        "    box_h = 12 + 20 * len(text_lines)\n",
        "\n",
        "    x, y, w, h = bbox\n",
        "    cx, cy = x + w // 2, y + h // 2\n",
        "    candidates = [\n",
        "        (x, max(6, y - box_h - 8)),                # above\n",
        "        (x, min(H - box_h - 6, y + h + 8)),        # below\n",
        "        (min(W - box_w - 6, x + w + 8), max(6, y)),# right\n",
        "        (max(6, x - box_w - 8), max(6, y)),        # left\n",
        "        (min(W - box_w - 6, x + 6), min(H - box_h - 6, y + 6)),  # inside\n",
        "    ]\n",
        "\n",
        "    def overlaps(a, b):\n",
        "        ax1, ay1, ax2, ay2 = a[0], a[1], a[0] + box_w, a[1] + box_h\n",
        "        bx1, by1, bx2, by2 = b\n",
        "        return not (ax2 < bx1 or bx2 < ax1 or ay2 < by1 or by2 < ay1)\n",
        "\n",
        "    for (lx, ly) in candidates:\n",
        "        lx = int(np.clip(lx, 6, W - box_w - 6))\n",
        "        ly = int(np.clip(ly, 6, H - box_h - 6))\n",
        "        rect = (lx, ly, lx + box_w, ly + box_h)\n",
        "        if not any(overlaps((lx, ly), u) for u in used):\n",
        "            used.append(rect)\n",
        "            return lx, ly, box_w, box_h\n",
        "\n",
        "    lx, ly = 8, min(H - box_h - 8, 8 + len(used) * (box_h + 8))\n",
        "    rect = (lx, ly, lx + box_w, ly + box_h)\n",
        "    used.append(rect)\n",
        "    return lx, ly, box_w, box_h\n",
        "\n",
        "def _summarize_roi_naturally(i, roi, C, T, S, P, I):\n",
        "    \"\"\"Generate short descriptive text for each ROI.\"\"\"\n",
        "    f = roi[\"factors\"]\n",
        "    keys = [\"sal\", \"tex\", \"con\", \"line\", \"prox_focal\", \"prox_vp\"]\n",
        "    ranked = sorted(keys, key=lambda k: f.get(k, 0.0), reverse=True)\n",
        "    top = ranked[:2]\n",
        "\n",
        "    tone_color = (\n",
        "        \"quiet transitions\" if C[\"mean_deltaE\"] < 10 else\n",
        "        \"measured contrast\" if C[\"mean_deltaE\"] < 20 else\n",
        "        \"confident contrast\"\n",
        "    )\n",
        "\n",
        "    tex_snip = (\n",
        "        \"a calm surface\" if T.get(\"texture_std\", 0.1) < 0.25 else\n",
        "        \"a sense of tactile movement\"\n",
        "    )\n",
        "\n",
        "    light_snip = (\n",
        "        f\"subtly shaped by light from ~{int(I['light_direction_deg'])}°\"\n",
        "        if I.get(\"light_direction_deg\") is not None else\n",
        "        \"bathed in diffuse light\"\n",
        "    )\n",
        "\n",
        "    H, W = S[\"saliency_map\"].shape\n",
        "    x, y, w, h = roi[\"bbox\"]\n",
        "    cx, cy = x + w / 2, y + h / 2\n",
        "    vertical = \"upper\" if cy < H / 2 else \"lower\"\n",
        "    horizontal = \"left\" if cx < W / 2 else \"right\"\n",
        "    zone = f\"{vertical}-{horizontal}\"\n",
        "\n",
        "    lead = {\n",
        "        \"sal\": \"Naturally eye-catching,\",\n",
        "        \"tex\": \"Texturally rich,\",\n",
        "        \"con\": \"Colorfully assertive,\",\n",
        "        \"line\": \"Structurally charged,\",\n",
        "        \"prox_focal\": \"Close to the focal center,\",\n",
        "        \"prox_vp\": \"Aligned with perspective,\",\n",
        "    }.get(top[0], \"Visually distinct,\")\n",
        "\n",
        "    second = {\n",
        "        \"sal\": \"it draws attention instantly.\",\n",
        "        \"tex\": \"the surface carries movement.\",\n",
        "        \"con\": f\"tones meet with {tone_color}.\",\n",
        "        \"line\": \"linework guides the gaze.\",\n",
        "        \"prox_focal\": \"it reinforces the main subject.\",\n",
        "        \"prox_vp\": \"the geometry feels ordered.\",\n",
        "    }.get(top[1] if len(top) > 1 else top[0], \"the details hold attention.\")\n",
        "\n",
        "    endings = [\n",
        "        \"the area rewards a slower look.\",\n",
        "        f\"Here there's {tex_snip}.\",\n",
        "        f\"It feels {light_snip}.\",\n",
        "        \"it feels resolved yet alive.\",\n",
        "    ]\n",
        "    tail = endings[i % len(endings)]\n",
        "\n",
        "    return f\"{lead} this {zone} region balances where {second} {tail}\"\n",
        "# ==========================================================\n",
        "# Drawing: Combined ROI Overlay + Individual ROI Overlays\n",
        "# ==========================================================\n",
        "\n",
        "def draw_roi_overlays_with_text(img_rgb, rois, C, T, S, P, I):\n",
        "    \"\"\"\n",
        "    Draw all ROIs with colored shading and auto-placed text summaries.\n",
        "    Returns:\n",
        "        combined_img_rgb (uint8 RGB),\n",
        "        texts (list[str]) per-ROI natural summaries in draw order.\n",
        "    \"\"\"\n",
        "    out = img_rgb.copy().astype(np.float32)\n",
        "    H, W = out.shape[:2]\n",
        "    alpha = 0.35\n",
        "    used_label_rects = []\n",
        "    texts = []\n",
        "\n",
        "    for i, roi in enumerate(rois):\n",
        "        # shaded region\n",
        "        color = ROI_COLORS[i % len(ROI_COLORS)]\n",
        "        x, y, w, h = roi[\"bbox\"]\n",
        "        mask = np.zeros((H, W), np.uint8)\n",
        "        cv2.rectangle(mask, (x, y), (x + w, y + h), 255, -1)\n",
        "\n",
        "        tint = np.full_like(out, color, np.uint8)\n",
        "        out = np.where(mask[:, :, None] > 0,\n",
        "                       (1 - alpha) * out + alpha * tint.astype(np.float32),\n",
        "                       out)\n",
        "\n",
        "        # ROI title + summary\n",
        "        title = f\"ROI {i + 1}\"\n",
        "        summary = _summarize_roi_naturally(i, roi, C, T, S, P, I)\n",
        "        lines = [title] + wrap_text_lines(summary, width_chars=46)\n",
        "        texts.append(summary)\n",
        "\n",
        "        # choose label rect & draw\n",
        "        lx, ly, bw, bh = _choose_label_rect(out.shape, roi[\"bbox\"], used_label_rects, lines)\n",
        "        _draw_label_box(out, lx, ly, bw, bh, alpha=0.7)\n",
        "\n",
        "        # title: accent color with thin black overlap for legibility\n",
        "        cv2.putText(out, title, (lx + 8, ly + 18),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.65, color, 2, cv2.LINE_AA)\n",
        "        cv2.putText(out, title, (lx + 8, ly + 18),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "        # body lines\n",
        "        if len(lines) > 1:\n",
        "            _put_label_lines(out, lx, ly + 6 + 18, lines[1:], leading=20, color=(240, 240, 240))\n",
        "\n",
        "    return np.clip(out, 0, 255).astype(np.uint8), texts\n",
        "\n",
        "\n",
        "def draw_single_roi_with_text(img_rgb, roi, idx, C, T, S, P, I):\n",
        "    \"\"\"\n",
        "    Render a single ROI overlay + on-image summary (for per-ROI files).\n",
        "    Returns:\n",
        "        single_img_rgb (uint8 RGB),\n",
        "        summary (str) the natural-language text for this ROI.\n",
        "    \"\"\"\n",
        "    out = img_rgb.copy().astype(np.float32)\n",
        "    H, W = out.shape[:2]\n",
        "    alpha = 0.35\n",
        "    color = ROI_COLORS[idx % len(ROI_COLORS)]\n",
        "    x, y, w, h = roi[\"bbox\"]\n",
        "\n",
        "    # shaded region\n",
        "    mask = np.zeros((H, W), np.uint8)\n",
        "    cv2.rectangle(mask, (x, y), (x + w, y + h), 255, -1)\n",
        "    tint = np.full_like(out, color, np.uint8)\n",
        "    out = np.where(mask[:, :, None] > 0,\n",
        "                   (1 - alpha) * out + alpha * tint.astype(np.float32),\n",
        "                   out)\n",
        "\n",
        "    # summary\n",
        "    title = f\"ROI {idx + 1}\"\n",
        "    summary = _summarize_roi_naturally(idx, roi, C, T, S, P, I)\n",
        "    lines = [title] + wrap_text_lines(summary, width_chars=46)\n",
        "\n",
        "    # pick label location (no previous labels for single)\n",
        "    used = []\n",
        "    lx, ly, bw, bh = _choose_label_rect(out.shape, roi[\"bbox\"], used, lines)\n",
        "    _draw_label_box(out, lx, ly, bw, bh, alpha=0.7)\n",
        "\n",
        "    cv2.putText(out, title, (lx + 8, ly + 18),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.65, color, 2, cv2.LINE_AA)\n",
        "    cv2.putText(out, title, (lx + 8, ly + 18),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "    if len(lines) > 1:\n",
        "        _put_label_lines(out, lx, ly + 6 + 18, lines[1:], leading=20, color=(240, 240, 240))\n",
        "\n",
        "    return np.clip(out, 0, 255).astype(np.uint8), summary\n",
        "# ==========================================================\n",
        "# Output Generation & Saving (ROIs + Summary + Metrics)\n",
        "# ==========================================================\n",
        "\n",
        "def save_roi_outputs(img, rois, C, T, S, P, I, paragraph, out_dir):\n",
        "    \"\"\"\n",
        "    Save:\n",
        "      • Combined ROI overlay (roi_combined.png)\n",
        "      • Individual ROI overlays (roi_1.png, roi_2.png, etc.)\n",
        "      • metrics.json (structured results)\n",
        "      • curatorial_summary.txt (light + tonal mood summary)\n",
        "    \"\"\"\n",
        "    ensure_dir(out_dir)\n",
        "\n",
        "    print(\"💡 Rendering combined ROI overlay…\", end=\" \")\n",
        "    combined_img, roi_texts = draw_roi_overlays_with_text(img, rois, C, T, S, P, I)\n",
        "    cv2.imwrite(os.path.join(out_dir, \"roi_combined.png\"),\n",
        "                cv2.cvtColor(combined_img, cv2.COLOR_RGB2BGR))\n",
        "    print(\"✓\")\n",
        "\n",
        "    print(\"💡 Rendering individual ROI overlays…\", end=\" \")\n",
        "    for i, roi in enumerate(rois):\n",
        "        single_img, text = draw_single_roi_with_text(img, roi, i, C, T, S, P, I)\n",
        "        cv2.imwrite(os.path.join(out_dir, f\"roi_{i + 1}.png\"),\n",
        "                    cv2.cvtColor(single_img, cv2.COLOR_RGB2BGR))\n",
        "    print(\"✓\")\n",
        "\n",
        "    print(\"💾 Writing metrics and summaries…\", end=\" \")\n",
        "    metrics = dict(\n",
        "        color=json_safe(C),\n",
        "        texture=json_safe(T),\n",
        "        saliency=json_safe(S),\n",
        "        composition=json_safe(P),\n",
        "        illumination=json_safe(I),\n",
        "        rois=json_safe(rois)\n",
        "    )\n",
        "    with open(os.path.join(out_dir, \"metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metrics, f, indent=2)\n",
        "\n",
        "    with open(os.path.join(out_dir, \"curatorial_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(paragraph + \"\\n\")\n",
        "\n",
        "    print(\"✓\")\n",
        "    print(f\"📁 All ROI outputs saved to: {out_dir}\")\n",
        "# ==========================================================\n",
        "# Main Function — ROI-Only Analysis + Curatorial Summary\n",
        "# ==========================================================\n",
        "\n",
        "def analyze_artwork_v17(path, verbose=True, thorough=True):\n",
        "    \"\"\"\n",
        "    Main entry point:\n",
        "      • Runs all analyses (color, texture, saliency, composition, light)\n",
        "      • Dynamically detects 2–5 Regions of Interest (ROIs)\n",
        "      • Writes per-ROI summaries + combined summary\n",
        "      • Saves only relevant outputs (ROI overlays + metrics + text)\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    print(f\"🖼️ Loading image: {path}\")\n",
        "    img = load_rgb(path)\n",
        "    H0, W0 = img.shape[:2]\n",
        "    print(f\"   • Image size: {W0}×{H0}\")\n",
        "\n",
        "    # --- Optional upscaling for fidelity ---\n",
        "    if thorough:\n",
        "        img, _ = resize_for_fidelity(img, target_pixels=1_600_000)\n",
        "        H, W = img.shape[:2]\n",
        "        if (H, W) != (H0, W0):\n",
        "            print(f\"   • Rescaled for fidelity: {W}×{H}\")\n",
        "    else:\n",
        "        H, W = H0, W0\n",
        "\n",
        "    # --- Output directory ---\n",
        "    out_dir = os.path.splitext(path)[0] + \"_analysis\"\n",
        "    ensure_dir(out_dir)\n",
        "\n",
        "    # --- Analyses ---\n",
        "    print(\"🎨 Running color analysis…\", end=\" \"); C = color_analysis(img); print(\"✓\")\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    print(\"🪶 Running texture analysis…\", end=\" \"); T = texture_analysis(gray); print(\"✓\")\n",
        "    print(\"🔥 Running saliency analysis…\", end=\" \"); S = saliency_analysis(img); print(\"✓\")\n",
        "    print(\"📐 Running composition analysis…\", end=\" \"); P = composition_analysis(img, S['focal']); print(\"✓\")\n",
        "    print(\"💡 Running illumination analysis…\", end=\" \"); I = illumination_analysis(img); print(\"✓\")\n",
        "\n",
        "    # --- ROI Processing ---\n",
        "    print(\"🌐 Building ROI interest map…\", end=\" \")\n",
        "    C2, T2, S2, P2, I2 = _prepare_roi_inputs(C, T, S, P, I, shape=img.shape[:2])\n",
        "    interest = roi_interest_map(C2, T2, S2, P2, I2, shape=img.shape[:2])\n",
        "    component_maps = _roi_component_maps(C2, T2, S2, P2, I2, shape=img.shape[:2])\n",
        "    print(\"✓\")\n",
        "\n",
        "    print(\"🔍 Extracting regions of interest…\", end=\" \")\n",
        "    rois = extract_regions_of_interest(interest, component_maps)\n",
        "    print(f\"{len(rois)} regions ✓\")\n",
        "\n",
        "    # --- Curatorial Summary ---\n",
        "    print(\"🖋️ Writing curatorial summary…\", end=\" \")\n",
        "    paragraph = light_description(I)\n",
        "    print(\"✓\")\n",
        "\n",
        "    # --- Save Outputs ---\n",
        "    save_roi_outputs(img, rois, C, T, S, P, I, paragraph, out_dir)\n",
        "\n",
        "    elapsed = time.time() - start\n",
        "    print(f\"\\n✅ Complete! Total runtime: {elapsed:.2f}s\")\n",
        "    print(f\"📁 Outputs saved to: {out_dir}\")\n",
        "# ==========================================================\n",
        "# Gamma Correction + Finalization Helpers\n",
        "# ==========================================================\n",
        "\n",
        "def safe_gamma_apply_and_save(img_rgb, path):\n",
        "    \"\"\"Apply gentle gamma correction before saving (for viewing clarity).\"\"\"\n",
        "    corrected = safe_gamma(img_rgb)\n",
        "    cv2.imwrite(path, cv2.cvtColor(corrected, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "def finalize_roi_outputs(img, rois, C, T, S, P, I, paragraph, out_dir):\n",
        "    \"\"\"\n",
        "    Post-process and save all ROI outputs with consistent gamma correction:\n",
        "      • Combined overlay\n",
        "      • Individual ROI overlays\n",
        "      • metrics.json\n",
        "      • curatorial_summary.txt\n",
        "    \"\"\"\n",
        "    ensure_dir(out_dir)\n",
        "    print(\"✨ Finalizing and saving ROI outputs…\", end=\" \")\n",
        "\n",
        "    combined_img, _ = draw_roi_overlays_with_text(img, rois, C, T, S, P, I)\n",
        "    safe_gamma_apply_and_save(combined_img, os.path.join(out_dir, \"roi_combined.png\"))\n",
        "\n",
        "    for i, roi in enumerate(rois):\n",
        "        single_img, _ = draw_single_roi_with_text(img, roi, i, C, T, S, P, I)\n",
        "        safe_gamma_apply_and_save(single_img, os.path.join(out_dir, f\"roi_{i+1}.png\"))\n",
        "\n",
        "    metrics = dict(\n",
        "        color=json_safe(C),\n",
        "        texture=json_safe(T),\n",
        "        saliency=json_safe(S),\n",
        "        composition=json_safe(P),\n",
        "        illumination=json_safe(I),\n",
        "        rois=json_safe(rois)\n",
        "    )\n",
        "\n",
        "    with open(os.path.join(out_dir, \"metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metrics, f, indent=2)\n",
        "    with open(os.path.join(out_dir, \"curatorial_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(paragraph + \"\\n\")\n",
        "\n",
        "    print(\"✓\")\n",
        "    print(f\"📁 Finalized ROI outputs saved in: {out_dir}\")\n",
        "# ==========================================================\n",
        "# Entry Point — Run Analyzer\n",
        "# ==========================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 🔧 Change this to the artwork you want to analyze:\n",
        "    IMAGE_PATH = \"/Users/alievanayasso/Documents/SlowMA/Raymond-Simboli-.jpg\"\n",
        "\n",
        "    try:\n",
        "        analyze_artwork_v17(IMAGE_PATH, verbose=True, thorough=True)\n",
        "    except Exception as e:\n",
        "        print(\"\\n❌ Error during analysis:\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        print(\"\\n💡 Tip: Check that your image path is correct and all dependencies are installed.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
