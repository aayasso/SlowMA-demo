{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================================\n",
        "# High-Fidelity Artwork Analyzer v13 (Visual+Functional)\n",
        "# ==========================================================\n",
        "# 100% LOCAL (OpenCV, NumPy, Pillow). No internet, no extras.\n",
        "#\n",
        "# What you get (per image):\n",
        "#   /<image>_analysis/\n",
        "#     ├─ overlay_final_composite.png  (single image with clear overlays + legend)\n",
        "#     ├─ curatorial_summary.txt       (micro + narrative, informed + encouraging)\n",
        "#     └─ metrics.json                 (all numeric metrics for inspection)\n",
        "#\n",
        "# Overlays (color-coded):\n",
        "#   • Focal point (🔴 red rings)\n",
        "#   • Subject region (🟣 magenta contour + soft glow)\n",
        "#   • Saliency field (soft red haze)\n",
        "#   • Texture energy (🟠 warm amber haze from Gabor)\n",
        "#   • Local color-contrast ΔE proxy (🟣 magenta haze)\n",
        "#   • Composition lines (cyan/green/yellow by angle)\n",
        "#   • Rule-of-thirds & Golden ratio nodes (white / yellow)\n",
        "#   • Light direction arrow (teal) & Vanishing point (yellow dot)\n",
        "#   • Hue-bar + Orientation-bar + textual legend strip\n",
        "# ==========================================================\n",
        "\n",
        "import os, json, time, textwrap\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from math import atan2, degrees\n",
        "\n",
        "# -----------------------------\n",
        "# Utils\n",
        "# -----------------------------\n",
        "def load_rgb(path):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    return np.array(img)\n",
        "\n",
        "def ensure_dir(p): os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def to_uint8(img_f32):\n",
        "    return np.clip(img_f32*255.0, 0, 255).astype(np.uint8)\n",
        "\n",
        "def safe_gamma(img_f32):\n",
        "    # Keep image visually balanced across light/dark paintings\n",
        "    m = float(img_f32.mean())\n",
        "    if m < 0.20:  # too dark → brighten\n",
        "        img_f32 = np.power(img_f32, 0.6)\n",
        "    elif m > 0.85:  # too bright → compress\n",
        "        img_f32 = np.power(img_f32, 1.2)\n",
        "    return np.clip(img_f32, 0, 1)\n",
        "\n",
        "# -----------------------------\n",
        "# ΔE2000 (perceptual contrast)\n",
        "# -----------------------------\n",
        "def ciede2000(Lab1, Lab2):\n",
        "    L1, a1, b1 = Lab1\n",
        "    L2, a2, b2 = Lab2\n",
        "    avg_L = (L1 + L2) / 2.0\n",
        "    C1 = np.sqrt(a1*a1 + b1*b1)\n",
        "    C2 = np.sqrt(a2*a2 + b2*b2)\n",
        "    avg_C = (C1 + C2) / 2.0\n",
        "    G = 0.5 * (1 - np.sqrt((avg_C**7) / (avg_C**7 + 25**7)))\n",
        "    a1p = (1+G)*a1; a2p = (1+G)*a2\n",
        "    C1p = np.sqrt(a1p*a1p + b1*b1); C2p = np.sqrt(a2p*a2p + b2*b2)\n",
        "    avg_Cp = (C1p + C2p) / 2.0\n",
        "    h1p = np.degrees(np.arctan2(b1, a1p)) % 360\n",
        "    h2p = np.degrees(np.arctan2(b2, a2p)) % 360\n",
        "    dLp = L2 - L1; dCp = C2p - C1p\n",
        "    dhp = h2p - h1p\n",
        "    if C1p*C2p == 0:\n",
        "        dhp = 0\n",
        "    else:\n",
        "        if dhp > 180: dhp -= 360\n",
        "        elif dhp < -180: dhp += 360\n",
        "    dHp = 2*np.sqrt(C1p*C2p)*np.sin(np.radians(dhp)/2.0)\n",
        "    avg_Lp = (L1 + L2)/2.0\n",
        "    if C1p*C2p == 0:\n",
        "        avg_hp = h1p + h2p\n",
        "    else:\n",
        "        if abs(h1p - h2p) > 180:\n",
        "            avg_hp = (h1p + h2p + 360)/2.0 if (h1p + h2p) < 360 else (h1p + h2p - 360)/2.0\n",
        "        else:\n",
        "            avg_hp = (h1p + h2p)/2.0\n",
        "    T = (1\n",
        "         - 0.17*np.cos(np.radians(avg_hp - 30))\n",
        "         + 0.24*np.cos(np.radians(2*avg_hp))\n",
        "         + 0.32*np.cos(np.radians(3*avg_hp + 6))\n",
        "         - 0.20*np.cos(np.radians(4*avg_hp - 63)))\n",
        "    d_ro = 30*np.exp(-((avg_hp - 275)/25)**2)\n",
        "    Rc = 2*np.sqrt((avg_Cp**7)/(avg_Cp**7 + 25**7))\n",
        "    Sl = 1 + 0.015*(avg_Lp - 50)**2 / np.sqrt(20 + (avg_Lp - 50)**2)\n",
        "    Sc = 1 + 0.045*avg_Cp\n",
        "    Sh = 1 + 0.015*avg_Cp*T\n",
        "    Rt = -np.sin(np.radians(2*d_ro))*Rc\n",
        "    dE = np.sqrt((dLp/Sl)**2 + (dCp/Sc)**2 + (dHp/Sh)**2 + Rt*(dCp/Sc)*(dHp/Sh))\n",
        "    return float(dE)\n",
        "\n",
        "# -----------------------------\n",
        "# Color (deep)\n",
        "# -----------------------------\n",
        "def circular_histogram_hue(h_degrees, bins=36):\n",
        "    hist, edges = np.histogram(h_degrees, bins=bins, range=(0,360))\n",
        "    hist = hist.astype(np.float32); hist /= (hist.sum() + 1e-6)\n",
        "    centers = (edges[:-1] + edges[1:]) / 2.0\n",
        "    return hist, centers\n",
        "\n",
        "def analyze_color_deep(img, k=6):\n",
        "    H, W = img.shape[:2]\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "    Z = lab.reshape(-1,3).astype(np.float32)\n",
        "    crit = (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 60, 0.3)\n",
        "    _r, labels, centers = cv2.kmeans(Z, k, None, crit, 10, cv2.KMEANS_PP_CENTERS)\n",
        "    labels2 = labels.reshape(H, W)\n",
        "    centers = centers.astype(np.float32)\n",
        "\n",
        "    rgb_centers = cv2.cvtColor(centers.reshape(-1,1,3).astype(np.uint8),\n",
        "                               cv2.COLOR_Lab2RGB).reshape(-1,3)\n",
        "    palette = [tuple(map(int, c)) for c in rgb_centers]\n",
        "\n",
        "    counts = np.bincount(labels.flatten(), minlength=k).astype(np.float32)\n",
        "    masks = [(labels2 == i).astype(np.uint8)*255 for i in range(k)]\n",
        "    cluster_area_frac = counts / (H*W + 1e-6)\n",
        "    spatial_cohesion = float(cluster_area_frac.max())\n",
        "    p = cluster_area_frac[cluster_area_frac > 0]\n",
        "    palette_entropy = -float(np.sum(p * np.log2(p)))\n",
        "\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    Hh, Sh, Vh = hsv[:,:,0].astype(np.float32), hsv[:,:,1].astype(np.float32), hsv[:,:,2].astype(np.float32)\n",
        "    hue_deg = (Hh * 2.0) % 360.0\n",
        "    hue_hist, hue_centers = circular_histogram_hue(hue_deg, bins=36)\n",
        "    sat_mean, sat_std = float(Sh.mean()), float(Sh.std())\n",
        "    val_mean, val_std = float(Vh.mean()), float(Vh.std())\n",
        "\n",
        "    a, b = centers[:,1]-128, centers[:,2]-128\n",
        "    hues_c = (np.degrees(np.arctan2(b, a)) + 360) % 360\n",
        "    warm_ratio = float(((hues_c < 90) | (hues_c > 330)).sum()/len(hues_c))\n",
        "    cool_ratio = float(((hues_c > 180) & (hues_c < 300)).sum()/len(hues_c))\n",
        "    harmony = \"mixed\"\n",
        "    if np.ptp(hues_c) < 35: harmony = \"analogous\"\n",
        "    elif any(abs(hues_c[i]-hues_c[j])%360 > 150 for i in range(len(hues_c)) for j in range(i+1,len(hues_c))):\n",
        "        harmony = \"complementary\"\n",
        "\n",
        "    dEs = []\n",
        "    for i in range(len(centers)):\n",
        "        for j in range(i+1, len(centers)):\n",
        "            dEs.append(ciede2000(centers[i], centers[j]))\n",
        "    mean_dE = float(np.mean(dEs)) if dEs else 0.0\n",
        "    max_dE = float(np.max(dEs)) if dEs else 0.0\n",
        "\n",
        "    # ΔE proxy field: gradient magnitude in Lab (multi-channel)\n",
        "    labf = lab.astype(np.float32)\n",
        "    gxL = cv2.Sobel(labf[:,:,0], cv2.CV_32F, 1, 0); gyL = cv2.Sobel(labf[:,:,0], cv2.CV_32F, 0, 1)\n",
        "    gxa = cv2.Sobel(labf[:,:,1], cv2.CV_32F, 1, 0); gya = cv2.Sobel(labf[:,:,1], cv2.CV_32F, 0, 1)\n",
        "    gxb = cv2.Sobel(labf[:,:,2], cv2.CV_32F, 1, 0); gyb = cv2.Sobel(labf[:,:,2], cv2.CV_32F, 0, 1)\n",
        "    grad_mag = np.sqrt((gxL**2 + gyL**2) + (gxa**2 + gya**2) + (gxb**2 + gyb**2))\n",
        "    contrast_map = cv2.GaussianBlur(grad_mag, (0,0), 1.2)\n",
        "    contrast_map = (contrast_map - contrast_map.min())/(contrast_map.max()-contrast_map.min()+1e-6)\n",
        "\n",
        "    return dict(\n",
        "        palette_rgb=palette, masks=masks,\n",
        "        color_variability=float(np.std(centers,0).mean()),\n",
        "        warm_ratio=warm_ratio, cool_ratio=cool_ratio, harmony=harmony,\n",
        "        hue_hist=hue_hist, hue_centers=hue_centers,\n",
        "        sat_mean=sat_mean, sat_std=sat_std, val_mean=val_mean, val_std=val_std,\n",
        "        palette_entropy=palette_entropy, spatial_cohesion=spatial_cohesion,\n",
        "        mean_deltaE=mean_dE, max_deltaE=max_dE, contrast_map=contrast_map\n",
        "    )\n",
        "\n",
        "# -----------------------------\n",
        "# Texture (LBP + Gabor)\n",
        "# -----------------------------\n",
        "def lbp_basic(gray):\n",
        "    H,W = gray.shape\n",
        "    out = np.zeros((H-2, W-2), dtype=np.uint8)\n",
        "    c = gray[1:-1,1:-1]\n",
        "    code = np.zeros_like(c, dtype=np.uint8)\n",
        "    shifts = [(-1,-1,7),(-1,0,6),(-1,1,5),(0,1,4),(1,1,3),(1,0,2),(1,-1,1),(0,-1,0)]\n",
        "    for dy,dx,bit in shifts:\n",
        "        nb = gray[1+dy:H-1+dy, 1+dx:W-1+dx]\n",
        "        code |= ((nb >= c).astype(np.uint8) << bit)\n",
        "    return code\n",
        "\n",
        "def gabor_energy(gray, orientations=6, scales=(3,5,7)):\n",
        "    H,W = gray.shape\n",
        "    energy_maps = []\n",
        "    angles = np.linspace(0, 180, orientations, endpoint=False)\n",
        "    combined = np.zeros((H,W), np.float32)\n",
        "    ori_energy = []\n",
        "    for theta in angles:\n",
        "        theta_rad = np.deg2rad(theta)\n",
        "        e_sum = np.zeros((H,W), np.float32)\n",
        "        for k in scales:\n",
        "            kernel = cv2.getGaborKernel((21,21), sigma=k, theta=theta_rad, lambd=10, gamma=0.5, psi=0)\n",
        "            resp = cv2.filter2D(gray, cv2.CV_32F, kernel)\n",
        "            e_sum += resp*resp\n",
        "        ori_energy.append(e_sum.mean())\n",
        "        combined = np.maximum(combined, e_sum)\n",
        "        energy_maps.append(e_sum)\n",
        "    ori_energy = np.array(ori_energy, dtype=np.float32)\n",
        "    dominant_idx = int(np.argmax(ori_energy))\n",
        "    dominant_angle = float(angles[dominant_idx])\n",
        "    anisotropy = float((ori_energy.max() - ori_energy.min()) / (ori_energy.mean()+1e-6))\n",
        "    comb_norm = (combined - combined.min())/(combined.max()-combined.min()+1e-6)\n",
        "    return angles, ori_energy, comb_norm, anisotropy, dominant_angle\n",
        "\n",
        "def analyze_texture_nuanced(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY).astype(np.uint8)\n",
        "    lbp = lbp_basic(gray)\n",
        "    hist, _ = np.histogram(lbp, bins=256, range=(0,256))\n",
        "    hist = hist.astype(np.float32); hist /= (hist.sum()+1e-6)\n",
        "    lbp_entropy = -float(np.sum(hist * np.log2(hist + 1e-12)))\n",
        "    lbp_roughness = float(lbp.std())\n",
        "    angles, ori_energy, energy_map, anisotropy, dom_angle = gabor_energy(gray, orientations=6, scales=(3,5,7))\n",
        "    return dict(\n",
        "        lbp_entropy=lbp_entropy,\n",
        "        lbp_roughness=lbp_roughness,\n",
        "        gabor_angles=angles, gabor_energy=ori_energy,\n",
        "        gabor_map=energy_map, gabor_anisotropy=anisotropy, gabor_dom_angle=dom_angle\n",
        "    )\n",
        "\n",
        "# -----------------------------\n",
        "# Saliency (frequency-based)\n",
        "# -----------------------------\n",
        "def spectral_saliency(grayf):\n",
        "    fft=np.fft.fft2(grayf)\n",
        "    loga=np.log(np.abs(fft)+1e-8)\n",
        "    spec=np.exp((loga-cv2.blur(loga,(3,3)))+1j*np.angle(fft))\n",
        "    sal=np.abs(np.fft.ifft2(spec))**2\n",
        "    sal=cv2.GaussianBlur(sal,(9,9),2)\n",
        "    sal=(sal-sal.min())/(sal.max()-sal.min()+1e-6)\n",
        "    return (sal*255).astype(np.uint8)\n",
        "\n",
        "def subject_from_saliency(sal):\n",
        "    H,W=sal.shape\n",
        "    _,th=cv2.threshold(sal,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    cnts,_=cv2.findContours(th,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if cnts:\n",
        "        x,y,w,h=cv2.boundingRect(max(cnts,key=cv2.contourArea))\n",
        "    else: x,y,w,h=W//4,H//4,W//2,H//2\n",
        "    mask=np.zeros((H,W),np.uint8); cv2.rectangle(mask,(x,y),(x+w,y+h),255,-1)\n",
        "    return dict(mask=mask,bbox=(x,y,w,h))\n",
        "\n",
        "def analyze_saliency(img):\n",
        "    g=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY).astype(np.float32)\n",
        "    sal=spectral_saliency(g)\n",
        "    sub=subject_from_saliency(sal)\n",
        "    Y,X=np.indices(sal.shape); w=sal.astype(np.float32)+1\n",
        "    cx,cy=int((X*w).sum()/w.sum()),int((Y*w).sum()/w.sum())\n",
        "    return dict(saliency_map=sal,focal=(cx,cy),\n",
        "                subject_mask=sub[\"mask\"],subject_bbox=sub[\"bbox\"])\n",
        "\n",
        "# -----------------------------\n",
        "# Composition (lines, thirds, golden, symmetry, balance)\n",
        "# -----------------------------\n",
        "def analyze_composition_nuanced(img, focal_xy):\n",
        "    g=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "    H,W=g.shape\n",
        "    edges=cv2.Canny(g,100,200)\n",
        "    linesP=cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength=min(H,W)//10,maxLineGap=15)\n",
        "    lines=[tuple(map(int,l[0])) for l in linesP] if linesP is not None else []\n",
        "    fx,fy=focal_xy\n",
        "    thirds_pts=[(W/3,H/3),(2*W/3,H/3),(W/3,2*H/3),(2*W/3,2*H/3)]\n",
        "    golden=0.618\n",
        "    golden_pts=[(golden*W,golden*H),((1-golden)*W,golden*H),\n",
        "                (golden*W,(1-golden)*H),((1-golden)*W,(1-golden)*H)]\n",
        "    diag=np.hypot(W,H)\n",
        "    thirds_delta=min(np.hypot(fx-x,fy-y) for (x,y) in thirds_pts)/(diag+1e-6)\n",
        "    golden_delta=min(np.hypot(fx-x,fy-y) for (x,y) in golden_pts)/(diag+1e-6)\n",
        "    g_f = g.astype(np.float32)/255.0\n",
        "    left = g_f[:, :W//2]\n",
        "    right = g_f[:, W - left.shape[1]:]\n",
        "    right_flipped = np.fliplr(right)\n",
        "    mse = float(np.mean((left - right_flipped)**2))\n",
        "    symmetry = float(1.0 - min(1.0, mse*4.0))\n",
        "    lw,rw=float(np.sum(edges[:,:W//2])),float(np.sum(edges[:,W//2:]))\n",
        "    balance=(rw-lw)/(lw+rw+1e-6)\n",
        "    return dict(\n",
        "        lines=lines, edge_balance=balance, thirds_delta=thirds_delta,\n",
        "        golden_delta=golden_delta, symmetry=symmetry, vanishing_point=(W//2,H//2)\n",
        "    )\n",
        "\n",
        "# -----------------------------\n",
        "# Illumination\n",
        "# -----------------------------\n",
        "def illumination(img):\n",
        "    L=cv2.cvtColor(img,cv2.COLOR_RGB2LAB)[:,:,0].astype(np.float32)\n",
        "    mu,sig=L.mean(),L.std()+1e-6\n",
        "    skew=float((((L-mu)/sig)**3).mean())\n",
        "    gx,gy=cv2.Sobel(L,cv2.CV_32F,1,0),cv2.Sobel(L,cv2.CV_32F,0,1)\n",
        "    hi=(L>np.percentile(L,90)).astype(np.uint8)\n",
        "    if hi.sum()>0:\n",
        "        gx,gy=(gx*hi).sum(),(gy*hi).sum()\n",
        "        ang=float((degrees(atan2(-gy,-gx))+360)%360)\n",
        "    else: ang=None\n",
        "    return dict(lightness_skew=skew,light_direction_deg=ang)\n",
        "\n",
        "# -----------------------------\n",
        "# Legend helpers\n",
        "# -----------------------------\n",
        "def make_hue_bar(hue_hist, width=420, height=50):\n",
        "    bar = np.zeros((height, width, 3), np.uint8)\n",
        "    for x in range(width):\n",
        "        h = int((x/width)*179)\n",
        "        col = np.uint8([[[h, 200, 220]]])\n",
        "        rgb = cv2.cvtColor(col, cv2.COLOR_HSV2RGB)[0,0]\n",
        "        bar[:, x] = rgb\n",
        "    bins = len(hue_hist); bin_w = max(1, width // bins)\n",
        "    hist = hue_hist/(hue_hist.max()+1e-6)\n",
        "    for i, v in enumerate(hist):\n",
        "        x1, x2 = i*bin_w, min(width-1, (i+1)*bin_w-1)\n",
        "        h_px = int(v*(height-10))\n",
        "        cv2.rectangle(bar, (x1, height-1), (x2, height-1-h_px), (0,0,0), -1)\n",
        "    return bar\n",
        "\n",
        "def make_orientation_bar(angles, energies, width=420, height=50):\n",
        "    bar = np.full((height, width, 3), 240, np.uint8)\n",
        "    if energies is None or len(energies)==0: return bar\n",
        "    e = np.array(energies, dtype=np.float32)\n",
        "    e = (e - e.min())/(e.max()-e.min()+1e-6)\n",
        "    for a, v in zip(angles, e):\n",
        "        x = int((a/180.0)*width)\n",
        "        h_px = int(v*(height-10))\n",
        "        cv2.rectangle(bar, (x-2, height-1), (x+2, height-1-h_px), (60,60,60), -1)\n",
        "    cv2.putText(bar, \"0°\", (5,18), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n",
        "    cv2.putText(bar, \"90°\", (width//2-15,18), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n",
        "    cv2.putText(bar, \"180°\", (width-50,18), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n",
        "    return bar\n",
        "\n",
        "# -----------------------------\n",
        "# Curatorial Text Generator\n",
        "# -----------------------------\n",
        "def generate_curatorial_summary(M):\n",
        "    C, T, P, I = (M[\"color\"], M[\"texture\"], M[\"composition\"], M[\"illumination\"])\n",
        "    if C[\"harmony\"] == \"analogous\":\n",
        "        color_tone = \"a restrained palette that breathes with quiet unity\"\n",
        "    elif C[\"harmony\"] == \"complementary\":\n",
        "        color_tone = \"a lively chromatic counterpoint that animates the surface\"\n",
        "    else:\n",
        "        color_tone = \"a flexible palette balancing contrast and cohesion\"\n",
        "    if C[\"mean_deltaE\"] > 25:\n",
        "        contrast_phrase = \"marked by pronounced contrast\"\n",
        "    elif C[\"mean_deltaE\"] > 10:\n",
        "        contrast_phrase = \"held in a moderate register of contrast\"\n",
        "    else:\n",
        "        contrast_phrase = \"gentle in chromatic transitions\"\n",
        "    texture_line = (\"Texture discloses a directional force (anisotropy \"\n",
        "                    f\"{T['gabor_anisotropy']:.2f}) with a prevailing angle near \"\n",
        "                    f\"{T['gabor_dom_angle']:.0f}°.\") if T[\"gabor_anisotropy\"]>0.5 else \\\n",
        "                   \"Texture remains even and diffused, emphasizing tonal balance.\"\n",
        "    comp_tone = (\"The focal point leans toward classical proportion (golden Δ=\"\n",
        "                 f\"{P['golden_delta']:.3f}).\") if P[\"golden_delta\"]<0.12 else \\\n",
        "                (\"The focal point aligns intuitively with rule-of-thirds (Δ=\"\n",
        "                 f\"{P['thirds_delta']:.3f}).\") if P[\"thirds_delta\"]<0.12 else \\\n",
        "                \"The composition resists convention, inviting open visual movement.\"\n",
        "    sym_phrase = (\"Axial calm arises from notable symmetry.\"\n",
        "                  if P[\"symmetry\"]>0.8 else\n",
        "                  \"Partial symmetry tempers dynamism.\"\n",
        "                  if P[\"symmetry\"]>0.5 else\n",
        "                  \"Asymmetry lends motion and immediacy.\")\n",
        "    balance_phrase = (\"Edge-weight remains stable.\"\n",
        "                      if abs(P[\"edge_balance\"])<0.1 else\n",
        "                      \"A deliberate imbalance animates the frame.\")\n",
        "    if I[\"light_direction_deg\"] is not None:\n",
        "        illum_phrase = f\"Light enters around {int(I['light_direction_deg'])}°, guiding attention.\"\n",
        "    else:\n",
        "        illum_phrase = \"Light diffuses evenly, reinforcing tonal unity.\"\n",
        "    if I[\"lightness_skew\"] > 0.5:\n",
        "        mood = \"luminous and open\"\n",
        "    elif I[\"lightness_skew\"] < -0.5:\n",
        "        mood = \"dark-hued and contemplative\"\n",
        "    else:\n",
        "        mood = \"balanced and calm\"\n",
        "\n",
        "    micro = textwrap.fill(\n",
        "        \" \".join([\n",
        "            f\"Color: {C['harmony']} harmony, mean ΔE={C['mean_deltaE']:.1f}, max ΔE={C['max_deltaE']:.1f}, \"\n",
        "            f\"entropy={C['palette_entropy']:.2f}, spatial={C['spatial_cohesion']:.2f}.\",\n",
        "            f\"Texture: LBP-H={T['lbp_entropy']:.2f}, rough={T['lbp_roughness']:.1f}, \"\n",
        "            f\"anisotropy={T['gabor_anisotropy']:.2f}, dom={T['gabor_dom_angle']:.0f}°.\",\n",
        "            f\"Composition: thirds Δ={P['thirds_delta']:.3f}, golden Δ={P['golden_delta']:.3f}, \"\n",
        "            f\"sym={P['symmetry']:.2f}, balance={P['edge_balance']:.2f}.\",\n",
        "            f\"Light: skew={I['lightness_skew']:.2f}, direction={I['light_direction_deg']}.\"\n",
        "        ]),\n",
        "        width=90\n",
        "    )\n",
        "\n",
        "    curatorial = textwrap.fill(\n",
        "        \" \".join([\n",
        "            f\"The work operates within {color_tone}, {contrast_phrase}.\",\n",
        "            texture_line, comp_tone, sym_phrase, balance_phrase, illum_phrase,\n",
        "            f\"The overall mood feels {mood}.\",\n",
        "            \"Together these elements invite a slow, attentive gaze, where color, gesture, and structure\"\n",
        "            \" are given room to breathe.\"\n",
        "        ]),\n",
        "        width=90\n",
        "    )\n",
        "    return micro, curatorial\n",
        "\n",
        "# -----------------------------\n",
        "# Visualization / Composite with Legend\n",
        "# -----------------------------\n",
        "def make_composite(img, M):\n",
        "    base = img.astype(np.float32)/255.0\n",
        "    H, W = base.shape[:2]\n",
        "\n",
        "    # Layers with soft alpha\n",
        "    # Color clusters (tinted)\n",
        "    color_layer = np.zeros_like(base)\n",
        "    for m, c in zip(M[\"color\"][\"masks\"], M[\"color\"][\"palette_rgb\"]):\n",
        "        if m.sum()==0: continue\n",
        "        mask = cv2.GaussianBlur((m>0).astype(np.float32), (0,0), 6)\n",
        "        color_layer += np.dstack([mask]*3) * (np.array(c)/255.0)\n",
        "    color_layer *= 0.18\n",
        "\n",
        "    # Texture (Gabor energy → warm amber)\n",
        "    gmap = M[\"texture\"][\"gabor_map\"]\n",
        "    gmap = cv2.GaussianBlur(gmap, (0,0), 1.2)\n",
        "    gmap = (gmap - gmap.min())/(gmap.max()-gmap.min()+1e-6)\n",
        "    tex_layer = np.dstack([gmap, gmap*0.45, 0*gmap]) * 0.28\n",
        "\n",
        "    # Local color-contrast ΔE proxy (magenta)\n",
        "    contrast = M[\"color\"][\"contrast_map\"]\n",
        "    contrast = cv2.GaussianBlur(contrast, (0,0), 1.2)\n",
        "    contrast = (contrast - contrast.min())/(contrast.max()-contrast.min()+1e-6)\n",
        "    de_layer = np.dstack([contrast*0.35, 0*contrast, contrast*0.35]) * 0.30\n",
        "\n",
        "    # Saliency (soft red)\n",
        "    sal = M[\"saliency\"][\"saliency_map\"].astype(np.float32)\n",
        "    sal = cv2.resize(sal, (W, H))\n",
        "    sal = cv2.normalize(sal, None, 0, 1, cv2.NORM_MINMAX)\n",
        "    sal_layer = np.dstack([sal*0.55, sal*0.2, sal*0.2]) * 0.24\n",
        "\n",
        "    # Lines (cyan/green/yellow by angle)\n",
        "    line_layer = np.zeros_like(base)\n",
        "    for (x1,y1,x2,y2) in M[\"composition\"][\"lines\"][:180]:\n",
        "        ang = (np.rad2deg(np.arctan2(y2-y1, x2-x1)) + 180) % 180\n",
        "        # vertical-ish (blue), horizontal-ish (green), diagonal (yellow)\n",
        "        col = (0,1,0) if 60<ang<120 else (0,0,1) if ang<30 or ang>150 else (1,1,0)\n",
        "        cv2.line(line_layer,(x1,y1),(x2,y2),(col[2],col[1],col[0]),1,cv2.LINE_AA)\n",
        "    line_layer = cv2.GaussianBlur(line_layer,(0,0),2)*0.45\n",
        "\n",
        "    # Blend\n",
        "    comp = base*0.85 + color_layer + tex_layer + de_layer + sal_layer + line_layer\n",
        "    comp = np.clip(comp, 0, 1)\n",
        "\n",
        "    # Subject contour + soft glow + focal rings\n",
        "    comp_bgr = (comp[:,:,::-1]*255).astype(np.uint8).copy()\n",
        "    mask = M[\"saliency\"][\"subject_mask\"]\n",
        "    cnts,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if cnts:\n",
        "        # soft glow\n",
        "        glow = np.zeros_like(comp_bgr)\n",
        "        cv2.drawContours(glow, cnts, -1, (255, 0, 255), thickness=cv2.FILLED)\n",
        "        glow = cv2.GaussianBlur(glow, (0,0), 15)\n",
        "        comp_bgr = cv2.addWeighted(glow, 0.10, comp_bgr, 0.90, 0)\n",
        "        # edge\n",
        "        cv2.drawContours(comp_bgr, cnts, -1, (255, 0, 255), 2)\n",
        "\n",
        "    fx, fy = M[\"saliency\"][\"focal\"]\n",
        "    for r in range(6, 28, 6):\n",
        "        cv2.circle(comp_bgr, (int(fx), int(fy)), r, (0,0,255), 1)\n",
        "\n",
        "    # Thirds & Golden nodes\n",
        "    thirds = [(W//3, H//3), (2*W//3, H//3), (W//3, 2*H//3), (2*W//3, 2*H//3)]\n",
        "    for (x,y) in thirds:\n",
        "        cv2.circle(comp_bgr, (int(x),int(y)), 3, (240,240,240), -1)\n",
        "    golden = 0.618\n",
        "    golds = [(golden*W,golden*H),((1-golden)*W,golden*H),\n",
        "             (golden*W,(1-golden)*H),((1-golden)*W,(1-golden)*H)]\n",
        "    for (x,y) in golds:\n",
        "        cv2.circle(comp_bgr, (int(x),int(y)), 3, (0,255,255), -1)\n",
        "\n",
        "    # Vanishing point + Light arrow\n",
        "    vp = M[\"composition\"].get(\"vanishing_point\")\n",
        "    if vp: cv2.circle(comp_bgr, tuple(map(int, vp)), 5, (0,255,255), -1)\n",
        "    ang = M[\"illumination\"].get(\"light_direction_deg\")\n",
        "    if ang is not None:\n",
        "        cx, cy = W-60, 60; r = min(H,W)//3\n",
        "        ex, ey = int(cx - r*np.cos(np.radians(ang))), int(cy + r*np.sin(np.radians(ang)))\n",
        "        cv2.arrowedLine(comp_bgr, (cx,cy), (ex,ey), (0,150,255), 3, tipLength=0.1)\n",
        "\n",
        "    comp_rgb = comp_bgr[:,:,::-1].astype(np.float32)/255.0\n",
        "\n",
        "    # Legend (dark bar) with labels and insets\n",
        "    legend_h = 160\n",
        "    legend = np.zeros((legend_h, W, 3), np.uint8)\n",
        "    f = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    cv2.putText(legend,\"Legend\",(20,36),f,1.0,(255,255,255),2)\n",
        "\n",
        "    # swatches\n",
        "    sw=[((140,10),(175,40),(0,0,255),\"Focal\"),\n",
        "        ((190,10),(225,40),(255,0,255),\"Subject\"),\n",
        "        ((240,10),(275,40),(0,255,255),\"Lines\"),\n",
        "        ((290,10),(325,40),(255,128,0),\"Texture\"),\n",
        "        ((340,10),(375,40),(255,0,255),\"ΔE\"),\n",
        "        ((390,10),(425,40),(255,255,255),\"Thirds\"),\n",
        "        ((440,10),(475,40),(0,255,255),\"Golden\"),\n",
        "        ((490,10),(525,40),(0,150,255),\"Light→\")]\n",
        "    for (x1,y1),(x2,y2),col,label in sw:\n",
        "        cv2.rectangle(legend,(x1,y1),(x2,y2),col,-1)\n",
        "        cv2.putText(legend,label,(x2+8,y2+22),f,0.55,(255,255,255),1)\n",
        "\n",
        "    # key metrics text blocks\n",
        "    C = M[\"color\"]; T = M[\"texture\"]; P = M[\"composition\"]; I = M[\"illumination\"]\n",
        "    txt1 = (f\"color: harm={C['harmony']}  meanΔE={C['mean_deltaE']:.1f}  \"\n",
        "            f\"maxΔE={C['max_deltaE']:.1f}  entropy={C['palette_entropy']:.2f}  \"\n",
        "            f\"spatial={C['spatial_cohesion']:.2f}\")\n",
        "    txt2 = (f\"texture: LBP-H={T['lbp_entropy']:.2f}  rough={T['lbp_roughness']:.1f}  \"\n",
        "            f\"anisotropy={T['gabor_anisotropy']:.2f}  dom={T['gabor_dom_angle']:.0f}°\")\n",
        "    txt3 = (f\"composition: thirdsΔ={P['thirds_delta']:.3f}  goldenΔ={P['golden_delta']:.3f}  \"\n",
        "            f\"sym={P['symmetry']:.2f}  balance={P['edge_balance']:.2f}\")\n",
        "    cv2.putText(legend, txt1, (20, 75), f, 0.60, (220,220,220), 1)\n",
        "    cv2.putText(legend, txt2, (20,105), f, 0.60, (220,220,220), 1)\n",
        "    cv2.putText(legend, txt3, (20,135), f, 0.60, (220,220,220), 1)\n",
        "\n",
        "    # insets on right: hue bar + orientation bar\n",
        "    hue_bar = make_hue_bar(C[\"hue_hist\"], width=min(500, max(360, W//2)), height=50)\n",
        "    ori_bar = make_orientation_bar(T[\"gabor_angles\"], T[\"gabor_energy\"],\n",
        "                                   width=min(500, max(360, W//2)), height=50)\n",
        "    hb_h, hb_w = hue_bar.shape[:2]\n",
        "    ob_h, ob_w = ori_bar.shape[:2]\n",
        "    x0 = max(0, W - max(hb_w, ob_w) - 20)\n",
        "\n",
        "    # clip hue/ori bars if they exceed legend width\n",
        "    hue_bar_resized = hue_bar[:, :min(hb_w, W - x0)]\n",
        "    ori_bar_resized = ori_bar[:, :min(ob_w, W - x0)]\n",
        "\n",
        "    legend[10:10 + hb_h, x0:x0 + hue_bar_resized.shape[1]] = hue_bar_resized\n",
        "    legend[10 + hb_h + 5:10 + hb_h + 5 + ob_h, x0:x0 + ori_bar_resized.shape[1]] = ori_bar_resized\n",
        "\n",
        "\n",
        "    final = np.vstack([to_uint8(safe_gamma(comp_rgb)), legend])\n",
        "    final = final.astype(np.uint8)\n",
        "    return final\n",
        "\n",
        "# -----------------------------\n",
        "# Pipeline\n",
        "# -----------------------------\n",
        "def analyze_artwork_high_fidelity(path):\n",
        "    start = time.time()\n",
        "    img = load_rgb(path)\n",
        "\n",
        "    color = analyze_color_deep(img, k=6)\n",
        "    texture = analyze_texture_nuanced(img)\n",
        "    sal = analyze_saliency(img)\n",
        "    comp = analyze_composition_nuanced(img, focal_xy=sal[\"focal\"])\n",
        "    illum = illumination(img)\n",
        "\n",
        "    M = dict(color=color, texture=texture, saliency=sal, composition=comp, illumination=illum)\n",
        "\n",
        "    # Build composite\n",
        "    composite = make_composite(img, M)\n",
        "\n",
        "    # Outputs\n",
        "    out_dir = os.path.splitext(path)[0] + \"_analysis\"\n",
        "    ensure_dir(out_dir)\n",
        "    out_png = os.path.join(out_dir, \"overlay_final_composite.png\")\n",
        "    cv2.imwrite(out_png, composite)\n",
        "\n",
        "    # Curatorial text\n",
        "    micro, narrative = generate_curatorial_summary(M)\n",
        "    out_txt = os.path.join(out_dir, \"curatorial_summary.txt\")\n",
        "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"--- MICRO SUMMARY ---\\n\")\n",
        "        f.write(micro + \"\\n\\n--- CURATORIAL SUMMARY ---\\n\")\n",
        "        f.write(narrative + \"\\n\")\n",
        "\n",
        "    # Metrics JSON (safe serialization for NumPy types)\n",
        "    def make_json_safe(obj):\n",
        "        if isinstance(obj, dict):\n",
        "            return {k: make_json_safe(v) for k, v in obj.items()}\n",
        "        elif isinstance(obj, (list, tuple)):\n",
        "            return [make_json_safe(x) for x in obj]\n",
        "        elif isinstance(obj, (np.generic, np.number)):\n",
        "            return obj.item()\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        else:\n",
        "            return obj\n",
        "\n",
        "    metrics_py = make_json_safe(M)\n",
        "    out_json = os.path.join(out_dir, \"metrics.json\")\n",
        "    with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metrics_py, f, indent=2)\n",
        "\n",
        "# -----------------------------\n",
        "# Run\n",
        "# -----------------------------\n",
        "if __name__==\"__main__\":\n",
        "    # ⬇️ Set your image path here:\n",
        "    IMAGE_PATH = \"/Users/alievanayasso/Documents/SlowMA/JMB.jpeg\"\n",
        "    analyze_artwork_high_fidelity(IMAGE_PATH)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
