{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### BLOCK 1/8 — Imports & Setup\n",
        "# ==========================================================\n",
        "# Artwork Analyzer v17 — Normal Visuals + Headed Summaries\n",
        "# ==========================================================\n",
        "# • Local-only (OpenCV + NumPy + Pillow)\n",
        "# • Dynamic scaling, safe gamma\n",
        "# • Separate overlay outputs per analysis type\n",
        "# • Encouraging curatorial tone\n",
        "# ==========================================================\n",
        "\n",
        "import os, json, time, textwrap, math\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from math import atan2, degrees\n",
        "\n",
        "# Fixed width for analysis panel (right side of each output)\n",
        "PANEL_W = 420\n",
        "\n",
        "# -----------------------------\n",
        "# Utility Functions\n",
        "# -----------------------------\n",
        "def ensure_dir(p): os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def load_rgb(path):\n",
        "    \"\"\"Load an image as RGB numpy array.\"\"\"\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    return np.array(img)\n",
        "\n",
        "def to_uint8(img_f32):\n",
        "    \"\"\"Convert [0–1] float array to uint8 safely.\"\"\"\n",
        "    return np.clip(img_f32 * 255.0, 0, 255).astype(np.uint8)\n",
        "\n",
        "def safe_gamma(img_u8):\n",
        "    \"\"\"Adjust gamma gently to balance brightness for display.\"\"\"\n",
        "    img = img_u8.astype(np.float32) / 255.0\n",
        "    m = float(img.mean())\n",
        "    if m < 0.25:       # dark images\n",
        "        img = np.power(img, 0.7)\n",
        "    elif m > 0.80:     # bright images\n",
        "        img = np.power(img, 1.1)\n",
        "    return to_uint8(np.clip(img, 0, 1))\n",
        "\n",
        "def resize_min_pixels(img, target_pixels=1_600_000):\n",
        "    \"\"\"Upscale small images to improve analysis fidelity.\"\"\"\n",
        "    H, W = img.shape[:2]\n",
        "    cur = H * W\n",
        "    if cur >= target_pixels:\n",
        "        return img, 1.0\n",
        "    scale = math.sqrt(target_pixels / float(cur))\n",
        "    newW, newH = int(W * scale), int(H * scale)\n",
        "    new = cv2.resize(img, (newW, newH), interpolation=cv2.INTER_CUBIC)\n",
        "    return new, scale\n",
        "\n",
        "def wrap_text_lines(text, width_chars=80):\n",
        "    \"\"\"Wrap long text neatly for display in panel.\"\"\"\n",
        "    return textwrap.wrap(text, width=width_chars)\n",
        "\n",
        "def json_safe(obj):\n",
        "    \"\"\"Recursively convert numpy objects to JSON-safe types.\"\"\"\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: json_safe(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, (list, tuple)):\n",
        "        return [json_safe(x) for x in obj]\n",
        "    elif isinstance(obj, (np.generic, np.number)):\n",
        "        return obj.item()\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "def norm01(x, lo, hi):\n",
        "    \"\"\"Normalize x into [0,1] given lower and upper bounds.\"\"\"\n",
        "    if hi <= lo: return 0.0\n",
        "    return float(np.clip((x - lo) / (hi - lo), 0, 1))\n",
        "### BLOCK 2/8 — Color & Palette Analysis\n",
        "# ==========================================================\n",
        "\n",
        "def ciede2000(Lab1, Lab2):\n",
        "    \"\"\"Compute CIEDE2000 color difference between two LAB triplets.\"\"\"\n",
        "    L1,a1,b1 = Lab1; L2,a2,b2 = Lab2\n",
        "    C1 = np.sqrt(a1*a1 + b1*b1); C2 = np.sqrt(a2*a2 + b2*b2)\n",
        "    avg_C = (C1 + C2)/2.0\n",
        "    G = 0.5*(1 - np.sqrt((avg_C**7)/((avg_C**7)+25**7)))\n",
        "    a1p, a2p = (1+G)*a1, (1+G)*a2\n",
        "    C1p, C2p = np.sqrt(a1p*a1p + b1*b1), np.sqrt(a2p*a2p + b2*b2)\n",
        "    h1p = (np.degrees(np.arctan2(b1,a1p))+360)%360\n",
        "    h2p = (np.degrees(np.arctan2(b2,a2p))+360)%360\n",
        "    dLp = L2-L1; dCp = C2p-C1p\n",
        "    dhp = h2p-h1p\n",
        "    if C1p*C2p==0: dhp=0\n",
        "    elif dhp>180: dhp-=360\n",
        "    elif dhp<-180: dhp+=360\n",
        "    dHp = 2*np.sqrt(C1p*C2p)*np.sin(np.radians(dhp)/2.0)\n",
        "    avg_Lp=(L1+L2)/2.0\n",
        "    if C1p*C2p==0: avg_hp=h1p+h2p\n",
        "    elif abs(h1p-h2p)>180:\n",
        "        avg_hp=(h1p+h2p+360)/2.0 if (h1p+h2p)<360 else (h1p+h2p-360)/2.0\n",
        "    else:\n",
        "        avg_hp=(h1p+h2p)/2.0\n",
        "    T=(1-0.17*np.cos(np.radians(avg_hp-30))\n",
        "        +0.24*np.cos(np.radians(2*avg_hp))\n",
        "        +0.32*np.cos(np.radians(3*avg_hp+6))\n",
        "        -0.20*np.cos(np.radians(4*avg_hp-63)))\n",
        "    d_ro=30*np.exp(-((avg_hp-275)/25)**2)\n",
        "    avg_Cp=(C1p+C2p)/2.0\n",
        "    Rc=2*np.sqrt(((avg_Cp**7)/((avg_Cp**7)+25**7)))\n",
        "    Sl=1+0.015*(avg_Lp-50)**2/np.sqrt(20+(avg_Lp-50)**2)\n",
        "    Sc=1+0.045*avg_Cp\n",
        "    Sh=1+0.015*avg_Cp*T\n",
        "    Rt=-np.sin(np.radians(2*d_ro))*Rc\n",
        "    return float(np.sqrt((dLp/Sl)**2 + (dCp/Sc)**2 + (dHp/Sh)**2 + Rt*(dCp/Sc)*(dHp/Sh)))\n",
        "\n",
        "def _kmeans_lab(lab_img, k, attempts=10):\n",
        "    \"\"\"Run K-means on LAB pixels to find k color clusters.\"\"\"\n",
        "    H,W=lab_img.shape[:2]\n",
        "    Z=lab_img.reshape(-1,3).astype(np.float32)\n",
        "    crit=(cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER,80,0.2)\n",
        "    _,labels,centers=cv2.kmeans(Z,k,None,crit,attempts,cv2.KMEANS_PP_CENTERS)\n",
        "    return labels.reshape(H,W), centers.astype(np.float32)\n",
        "\n",
        "def _palette_quality(centers, entropy):\n",
        "    \"\"\"Assess palette diversity using ΔE distances + entropy.\"\"\"\n",
        "    if centers.shape[0]<2: return entropy,0.0\n",
        "    dEs=[ciede2000(centers[i],centers[j])\n",
        "         for i in range(len(centers)) for j in range(i+1,len(centers))]\n",
        "    mean_dE=float(np.mean(dEs)) if dEs else 0.0\n",
        "    spread=float(np.std(centers,axis=0).mean())\n",
        "    return 0.6*(0.7*mean_dE+0.3*spread)+0.4*entropy, mean_dE\n",
        "\n",
        "def color_analysis(img, ks=(6,8,10)):\n",
        "    \"\"\"Extract palette, compute harmony, ΔE, and hue histogram.\"\"\"\n",
        "    H,W=img.shape[:2]\n",
        "    lab=cv2.cvtColor(img,cv2.COLOR_RGB2LAB)\n",
        "    hsv=cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
        "    hue=(hsv[:,:,0].astype(np.float32)*2.0)%360.0\n",
        "    hue_hist,_=np.histogram(hue,bins=36,range=(0,360))\n",
        "    hue_hist=hue_hist.astype(np.float32)\n",
        "\n",
        "    best=None; best_score=-1\n",
        "    for k in ks:\n",
        "        labels,centers=_kmeans_lab(lab,k)\n",
        "        counts=np.bincount(labels.reshape(-1),minlength=k).astype(np.float32)\n",
        "        frac=counts/(H*W+1e-6)\n",
        "        p=frac[frac>0]\n",
        "        entropy=-float(np.sum(p*np.log2(p)))\n",
        "        score,mean_dE=_palette_quality(centers,entropy)\n",
        "        if score>best_score: best_score=score; best=(k,labels,centers,counts,entropy,mean_dE)\n",
        "\n",
        "    k_sel,labels,centers,counts,entropy,mean_dE=best\n",
        "    rgb_centers=cv2.cvtColor(centers.reshape(-1,1,3).astype(np.uint8),\n",
        "                              cv2.COLOR_Lab2RGB).reshape(-1,3)\n",
        "    palette=[tuple(map(int,c)) for c in rgb_centers]\n",
        "\n",
        "    a,b=centers[:,1]-128, centers[:,2]-128\n",
        "    hues_c=(np.degrees(np.arctan2(b,a))+360)%360\n",
        "    warm_ratio=float(((hues_c<90)|(hues_c>330)).sum()/len(hues_c))\n",
        "    cool_ratio=float(((hues_c>180)&(hues_c<300)).sum()/len(hues_c))\n",
        "    if np.ptp(hues_c)<35: harmony=\"analogous\"\n",
        "    elif any(abs(hues_c[i]-hues_c[j])%360>150 for i in range(len(hues_c)) for j in range(i+1,len(hues_c))):\n",
        "        harmony=\"complementary\"\n",
        "    else: harmony=\"mixed\"\n",
        "\n",
        "    # ΔE proxy map via Lab gradients\n",
        "    labf=lab.astype(np.float32)\n",
        "    gxL=cv2.Sobel(labf[:,:,0],cv2.CV_32F,1,0); gyL=cv2.Sobel(labf[:,:,0],cv2.CV_32F,0,1)\n",
        "    gxa=cv2.Sobel(labf[:,:,1],cv2.CV_32F,1,0); gya=cv2.Sobel(labf[:,:,1],cv2.CV_32F,0,1)\n",
        "    gxb=cv2.Sobel(labf[:,:,2],cv2.CV_32F,1,0); gyb=cv2.Sobel(labf[:,:,2],cv2.CV_32F,0,1)\n",
        "    grad_mag=np.sqrt((gxL**2+gyL**2)+(gxa**2+gya**2)+(gxb**2+gyb**2))\n",
        "    contrast_map=(grad_mag-grad_mag.min())/(grad_mag.max()-grad_mag.min()+1e-6)\n",
        "\n",
        "    return dict(\n",
        "        palette_rgb=palette,\n",
        "        palette_entropy=float(entropy),\n",
        "        mean_deltaE=float(mean_dE),\n",
        "        warm_ratio=warm_ratio,\n",
        "        cool_ratio=cool_ratio,\n",
        "        harmony=harmony,\n",
        "        contrast_map=contrast_map,\n",
        "        hue_hist=hue_hist,\n",
        "        k_selected=int(k_sel)\n",
        "    )\n",
        "### BLOCK 3/8 — Texture Analysis (Gabor Pyramid + Roughness)\n",
        "# ==========================================================\n",
        "\n",
        "def gabor_pyramid(gray, scales=(3,5,7,9,11,13), orientations=12):\n",
        "    \"\"\"Analyze texture energy and directionality using multi-scale Gabor filters.\"\"\"\n",
        "    H, W = gray.shape\n",
        "    angles = np.linspace(0, 180, orientations, endpoint=False)\n",
        "    combined = np.zeros((H, W), np.float32)\n",
        "    angle_energy = np.zeros(orientations, np.float32)\n",
        "\n",
        "    for oi, theta in enumerate(angles):\n",
        "        theta_rad = np.deg2rad(theta)\n",
        "        e_sum = np.zeros((H, W), np.float32)\n",
        "        for k in scales:\n",
        "            kernel = cv2.getGaborKernel((21,21), sigma=k, theta=theta_rad,\n",
        "                                        lambd=10, gamma=0.5, psi=0)\n",
        "            resp = cv2.filter2D(gray, cv2.CV_32F, kernel)\n",
        "            e_sum += resp * resp\n",
        "        combined = np.maximum(combined, e_sum)\n",
        "        angle_energy[oi] = e_sum.mean()\n",
        "\n",
        "    anisotropy = float((angle_energy.max() - angle_energy.min()) /\n",
        "                       (angle_energy.mean() + 1e-6))\n",
        "    dom_angle = float(angles[int(np.argmax(angle_energy))])\n",
        "    gmap = (combined - combined.min()) / (combined.max() - combined.min() + 1e-6)\n",
        "\n",
        "    # Texture entropy and roughness\n",
        "    hist, _ = np.histogram(gray, bins=256, range=(0,256))\n",
        "    hist = hist.astype(np.float32)\n",
        "    hist /= (hist.sum() + 1e-6)\n",
        "    entropy = -float(np.sum(hist * np.log2(hist + 1e-12)))\n",
        "    roughness = float(gray.std())\n",
        "\n",
        "    return dict(\n",
        "        gabor_angles=angles,\n",
        "        gabor_energy=angle_energy,\n",
        "        gabor_map=gmap,\n",
        "        gabor_anisotropy=anisotropy,\n",
        "        gabor_dom_angle=dom_angle,\n",
        "        lbp_entropy=entropy,\n",
        "        lbp_roughness=roughness\n",
        "    )\n",
        "\n",
        "# -----------------------------\n",
        "# Texture / Contrast / Saliency Strength Helpers\n",
        "# -----------------------------\n",
        "def texture_strength(T):\n",
        "    \"\"\"Blend anisotropy + roughness into [0–1] texture visibility weight.\"\"\"\n",
        "    a = norm01(T[\"gabor_anisotropy\"], 0.15, 0.85)\n",
        "    r = norm01(T[\"lbp_roughness\"], 8.0, 35.0)\n",
        "    return 0.6 * a + 0.4 * r\n",
        "\n",
        "def contrast_strength(C):\n",
        "    \"\"\"Map mean ΔE to visibility scale.\"\"\"\n",
        "    return norm01(C[\"mean_deltaE\"], 6.0, 28.0)\n",
        "\n",
        "def saliency_strength(mask):\n",
        "    \"\"\"Estimate visibility strength from normalized subject area.\"\"\"\n",
        "    area = float(mask.sum()) / 255.0\n",
        "    return norm01(area, 0.04 * mask.size, 0.45 * mask.size)\n",
        "### BLOCK 4/8 — Saliency & Subject Detection\n",
        "# ==========================================================\n",
        "\n",
        "def spectral_saliency(grayf, blur=(9,9), sigma=2):\n",
        "    \"\"\"Compute spectral residual saliency map.\"\"\"\n",
        "    fft = np.fft.fft2(grayf)\n",
        "    loga = np.log(np.abs(fft) + 1e-8)\n",
        "    spec = np.exp((loga - cv2.blur(loga, (3,3))) + 1j * np.angle(fft))\n",
        "    sal = np.abs(np.fft.ifft2(spec))**2\n",
        "    sal = cv2.GaussianBlur(sal, blur, sigma)\n",
        "    sal = (sal - sal.min()) / (sal.max() - sal.min() + 1e-6)\n",
        "    return (sal * 255).astype(np.uint8)\n",
        "\n",
        "def subject_from_saliency_fused(s1, s2):\n",
        "    \"\"\"Fuse two saliency maps and return subject mask + bounding box.\"\"\"\n",
        "    H, W = s1.shape\n",
        "    m1 = cv2.threshold(s1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "    m2 = cv2.threshold(s2, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "    m = cv2.bitwise_and(m1, m2)\n",
        "    m = cv2.morphologyEx(m, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))\n",
        "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, np.ones((7,7), np.uint8))\n",
        "\n",
        "    cnts,_ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if cnts:\n",
        "        x, y, w, h = cv2.boundingRect(max(cnts, key=cv2.contourArea))\n",
        "    else:\n",
        "        x, y, w, h = W//4, H//4, W//2, H//2\n",
        "        cv2.rectangle(m, (x,y), (x+w,y+h), 255, -1)\n",
        "    return dict(mask=m, bbox=(x,y,w,h))\n",
        "\n",
        "def saliency_analysis(img):\n",
        "    \"\"\"Run dual-scale saliency and derive focal point and subject mask.\"\"\"\n",
        "    g = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY).astype(np.float32)\n",
        "    s_coarse = spectral_saliency(cv2.GaussianBlur(g, (0,0), 3.0), blur=(11,11), sigma=3)\n",
        "    s_fine   = spectral_saliency(cv2.GaussianBlur(g, (0,0), 1.0), blur=(7,7), sigma=1.5)\n",
        "    fused = np.maximum(s_coarse, s_fine)\n",
        "    sub = subject_from_saliency_fused(s_coarse, s_fine)\n",
        "\n",
        "    Y, X = np.indices(fused.shape)\n",
        "    w = fused.astype(np.float32) + 1\n",
        "    cx, cy = int((X * w).sum() / w.sum()), int((Y * w).sum() / w.sum())\n",
        "\n",
        "    return dict(\n",
        "        saliency_map=fused,\n",
        "        focal=(cx, cy),\n",
        "        subject_mask=sub[\"mask\"],\n",
        "        subject_bbox=sub[\"bbox\"]\n",
        "    )\n",
        "### BLOCK 5/8 — Composition & Structure Analysis\n",
        "# ==========================================================\n",
        "\n",
        "def _line_intersection(p1, p2):\n",
        "    \"\"\"Find intersection between two lines, or None if parallel.\"\"\"\n",
        "    (x1,y1,x2,y2),(x3,y3,x4,y4)=p1,p2\n",
        "    den=(x1-x2)*(y3-y4)-(y1-y2)*(x3-x4)\n",
        "    if abs(den)<1e-6: return None\n",
        "    px=((x1*y2-y1*x2)*(x3-x4)-(x1-x2)*(x3*y4-y3*x4))/den\n",
        "    py=((x1*y2-y1*x2)*(y3-y4)-(y1-y2)*(x3*y4-y3*x4))/den\n",
        "    return (px,py)\n",
        "\n",
        "def _cluster_points(points, grid):\n",
        "    \"\"\"Cluster points into grid cells to find dominant intersection region.\"\"\"\n",
        "    if not points: return None\n",
        "    pts=np.array(points,dtype=np.float32)\n",
        "    xs,ys=pts[:,0],pts[:,1]\n",
        "    xbin=np.round(xs/grid).astype(int)\n",
        "    ybin=np.round(ys/grid).astype(int)\n",
        "    keys=xbin*100000+ybin\n",
        "    uniq,counts=np.unique(keys,return_counts=True)\n",
        "    best_key=uniq[np.argmax(counts)]\n",
        "    mask=(keys==best_key)\n",
        "    bx=float(xs[mask].mean()); by=float(ys[mask].mean())\n",
        "    return (bx,by)\n",
        "\n",
        "def composition_analysis(img, focal_xy):\n",
        "    \"\"\"Detect lines, compute vanishing point, thirds/golden ratios, and symmetry.\"\"\"\n",
        "    g=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "    H,W=g.shape\n",
        "    edges=cv2.Canny(g,80,200)\n",
        "\n",
        "    # Multi-pass Hough line detection\n",
        "    lines=[]\n",
        "    params=[\n",
        "        (1,np.pi/180,100,min(H,W)//12,15),\n",
        "        (1,np.pi/180,80,min(H,W)//14,20),\n",
        "        (1,np.pi/180,120,min(H,W)//10,15)\n",
        "    ]\n",
        "    for rho,theta,thr,minL,gap in params:\n",
        "        linesP=cv2.HoughLinesP(edges,rho,theta,thr,\n",
        "                               minLineLength=minL,maxLineGap=gap)\n",
        "        if linesP is not None:\n",
        "            for l in linesP:\n",
        "                ln=tuple(map(int,l[0]))\n",
        "                if math.hypot(ln[2]-ln[0],ln[3]-ln[1])>=min(H,W)//14:\n",
        "                    lines.append(ln)\n",
        "    lines=lines[:300]\n",
        "\n",
        "    # Vanishing point estimation\n",
        "    inters=[]\n",
        "    for i in range(len(lines)):\n",
        "        for j in range(i+1,len(lines)):\n",
        "            ip=_line_intersection(lines[i],lines[j])\n",
        "            if ip is None: continue\n",
        "            if -W*0.5<=ip[0]<=W*1.5 and -H*0.5<=ip[1]<=H*1.5:\n",
        "                inters.append(ip)\n",
        "    vp=_cluster_points(inters,grid=max(20,min(H,W)//30))\n",
        "    if vp is None: vp=(W/2,H/2)\n",
        "\n",
        "    # Focal alignment vs thirds / golden ratio\n",
        "    fx,fy=focal_xy\n",
        "    thirds_pts=[(W/3,H/3),(2*W/3,H/3),(W/3,2*H/3),(2*W/3,2*H/3)]\n",
        "    gfac=0.618\n",
        "    golden_pts=[(gfac*W,gfac*H),((1-gfac)*W,gfac*H),\n",
        "                (gfac*W,(1-gfac)*H),((1-gfac)*W,(1-gfac)*H)]\n",
        "    diag=np.hypot(W,H)\n",
        "    thirds_delta=min(np.hypot(fx-x,fy-y) for (x,y) in thirds_pts)/(diag+1e-6)\n",
        "    golden_delta=min(np.hypot(fx-x,fy-y) for (x,y) in golden_pts)/(diag+1e-6)\n",
        "\n",
        "    # Symmetry and edge balance\n",
        "    g_f=g.astype(np.float32)/255.0\n",
        "    left=g_f[:,:W//2]; right=np.fliplr(g_f[:,W-left.shape[1]:])\n",
        "    mse=float(np.mean((left-right)**2))\n",
        "    symmetry=float(1.0 - min(1.0, mse*4.0))\n",
        "    lw,rw=float(np.sum(edges[:,:W//2])),float(np.sum(edges[:,W//2:]))\n",
        "    balance=(rw-lw)/(lw+rw+1e-6)\n",
        "\n",
        "    return dict(\n",
        "        lines=lines,\n",
        "        vanishing_point=vp,\n",
        "        thirds_delta=thirds_delta,\n",
        "        golden_delta=golden_delta,\n",
        "        symmetry=symmetry,\n",
        "        edge_balance=balance\n",
        "    )\n",
        "\n",
        "def line_strength(lines):\n",
        "    \"\"\"More lines = stronger composition indicator.\"\"\"\n",
        "    return norm01(len(lines), 20, 260)\n",
        "### BLOCK 6/8 — Illumination & Light Direction\n",
        "# ==========================================================\n",
        "\n",
        "def illumination_analysis(img):\n",
        "    \"\"\"Analyze light direction and tonal skew in LAB space.\"\"\"\n",
        "    L = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)[:,:,0].astype(np.float32)\n",
        "    mu, sig = L.mean(), L.std() + 1e-6\n",
        "    skew = float((((L - mu) / sig) ** 3).mean())\n",
        "\n",
        "    # Compute directional gradients on brightest 10%\n",
        "    gx, gy = cv2.Sobel(L, cv2.CV_32F, 1, 0), cv2.Sobel(L, cv2.CV_32F, 0, 1)\n",
        "    hi = (L > np.percentile(L, 90)).astype(np.uint8)\n",
        "\n",
        "    if hi.sum() > 0:\n",
        "        gx_sum, gy_sum = (gx * hi).sum(), (gy * hi).sum()\n",
        "        ang = float((degrees(atan2(-gy_sum, -gx_sum)) + 360) % 360)\n",
        "    else:\n",
        "        ang = None\n",
        "\n",
        "    return dict(\n",
        "        lightness_skew=skew,\n",
        "        light_direction_deg=ang\n",
        "    )\n",
        "\n",
        "def light_strength(I):\n",
        "    \"\"\"Map illumination signal strength to overlay visibility.\"\"\"\n",
        "    if I[\"light_direction_deg\"] is None:\n",
        "        return 0.0\n",
        "    s = abs(I[\"lightness_skew\"])\n",
        "    return max(0.15, norm01(s, 0.1, 0.8))\n",
        "### BLOCK 7/8 — Overlays & Visual Rendering (Clear, Dynamic Indicators)\n",
        "# ==========================================================\n",
        "\n",
        "def overlays_on_artwork(img, C, T, S, P, I):\n",
        "    \"\"\"Render dynamic color-coded overlays onto the artwork.\"\"\"\n",
        "    base = img.astype(np.float32) / 255.0\n",
        "    H, W = base.shape[:2]\n",
        "\n",
        "    # Strength scaling for transparency\n",
        "    w_tex   = texture_strength(T)\n",
        "    w_de    = contrast_strength(C)\n",
        "    w_sal   = saliency_strength(S[\"subject_mask\"])\n",
        "    w_lines = line_strength(P[\"lines\"])\n",
        "    w_light = light_strength(I)\n",
        "\n",
        "    # 1. Texture (amber haze)\n",
        "    gmap = T[\"gabor_map\"]\n",
        "    gmap = cv2.GaussianBlur(gmap, (0,0), 1.0)\n",
        "    gmap = (gmap - gmap.min()) / (gmap.max() - gmap.min() + 1e-6)\n",
        "    tex_layer = np.dstack([gmap, gmap * 0.45, 0 * gmap]) * (0.35 * w_tex)\n",
        "\n",
        "    # 2. Local color contrast (magenta haze)\n",
        "    contrast = C[\"contrast_map\"]\n",
        "    contrast = cv2.GaussianBlur(contrast, (0,0), 1.0)\n",
        "    contrast = (contrast - contrast.min()) / (contrast.max() - contrast.min() + 1e-6)\n",
        "    de_layer = np.dstack([contrast, 0 * contrast, contrast]) * (0.28 * w_de)\n",
        "\n",
        "    # 3. Saliency (soft red haze)\n",
        "    sal = S[\"saliency_map\"].astype(np.float32)\n",
        "    if sal.shape[:2] != (H, W):\n",
        "        sal = cv2.resize(sal, (W, H), interpolation=cv2.INTER_CUBIC)\n",
        "    sal = cv2.normalize(sal, None, 0, 1, cv2.NORM_MINMAX)\n",
        "    sal_layer = np.dstack([sal, sal * 0.45, sal * 0.45]) * (0.22 * w_sal)\n",
        "\n",
        "    # 4. Composition lines (cyan/green/yellow)\n",
        "    line_layer = np.zeros_like(base)\n",
        "    for (x1, y1, x2, y2) in P[\"lines\"][:240]:\n",
        "        ang = (np.rad2deg(np.arctan2(y2 - y1, x2 - x1)) + 180) % 180\n",
        "        col = (0, 1, 0) if 60 < ang < 120 else (0, 0, 1) if ang < 30 or ang > 150 else (1, 1, 0)\n",
        "        cv2.line(line_layer, (x1, y1), (x2, y2), (col[2], col[1], col[0]), 1, cv2.LINE_AA)\n",
        "    line_layer = cv2.GaussianBlur(line_layer, (0,0), 2) * (0.45 * w_lines)\n",
        "\n",
        "    # Blend all overlay layers\n",
        "    comp = base * 0.92 + tex_layer + de_layer + sal_layer + line_layer\n",
        "    comp = np.clip(comp, 0, 1)\n",
        "    comp_bgr = (comp[:, :, ::-1] * 255).astype(np.uint8).copy()\n",
        "\n",
        "    # 5. Subject contour (magenta edge)\n",
        "    mask = S[\"subject_mask\"]\n",
        "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if cnts and w_sal > 0.05:\n",
        "        cv2.drawContours(comp_bgr, cnts, -1, (255, 0, 255), 2)\n",
        "\n",
        "    # 6. Focal rings\n",
        "    fx, fy = S[\"focal\"]\n",
        "    for r in range(6, 30, 6):\n",
        "        cv2.circle(comp_bgr, (int(fx), int(fy)), r, (0, 0, 255), 1)\n",
        "\n",
        "    # 7. Vanishing point & light arrow\n",
        "    vp = P.get(\"vanishing_point\")\n",
        "    if vp:\n",
        "        cv2.circle(comp_bgr, tuple(map(int, vp)), 6, (0, 255, 255), -1)\n",
        "    if I[\"light_direction_deg\"] is not None and w_light > 0.05:\n",
        "        Hc, Wc = comp_bgr.shape[:2]\n",
        "        cx, cy = Wc - 60, 60\n",
        "        r = min(Hc, Wc) // 3\n",
        "        ang = I[\"light_direction_deg\"]\n",
        "        ex, ey = int(cx - r * np.cos(np.radians(ang))), int(cy + r * np.sin(np.radians(ang)))\n",
        "        cv2.arrowedLine(comp_bgr, (cx, cy), (ex, ey), (0, 150, 255), 3, tipLength=0.1)\n",
        "\n",
        "    # Return final RGB overlay + visibility strengths\n",
        "    return comp_bgr[:, :, ::-1], dict(\n",
        "        w_tex=w_tex, w_de=w_de, w_sal=w_sal, w_lines=w_lines, w_light=w_light\n",
        "    )\n",
        "### Curatorial Paragraph Helper (Encouraging tone)\n",
        "# ==========================================================\n",
        "def curatorial_paragraph(M):\n",
        "    C, T, P, I = M[\"color\"], M[\"texture\"], M[\"composition\"], M[\"illumination\"]\n",
        "\n",
        "    # Color mood\n",
        "    tone = {\n",
        "        \"analogous\": \"a harmonious range of kindred hues\",\n",
        "        \"complementary\": \"a dynamic play of opposing colors\"\n",
        "    }.get(C[\"harmony\"], \"a balanced and varied palette\")\n",
        "\n",
        "    if C[\"mean_deltaE\"] > 25:\n",
        "        contrast = \"vivid contrast that energizes the surface\"\n",
        "    elif C[\"mean_deltaE\"] > 12:\n",
        "        contrast = \"moderate contrast that lends clarity\"\n",
        "    else:\n",
        "        contrast = \"gentle gradations that invite reflection\"\n",
        "\n",
        "    # Texture\n",
        "    texture_phrase = (\n",
        "        f\"Texture carries a directional rhythm near {T['gabor_dom_angle']:.0f}°, suggesting flow and motion.\"\n",
        "        if T[\"gabor_anisotropy\"] > 0.5\n",
        "        else \"Texture remains even and tranquil, grounding the image.\"\n",
        "    )\n",
        "\n",
        "    # Composition\n",
        "    if P[\"golden_delta\"] < 0.12:\n",
        "        comp_phrase = \"The structure recalls the golden proportion, bringing calm balance.\"\n",
        "    elif P[\"thirds_delta\"] < 0.12:\n",
        "        comp_phrase = \"The focal point aligns near a rule-of-thirds intersection, evoking natural stability.\"\n",
        "    else:\n",
        "        comp_phrase = \"The composition feels exploratory and open-ended.\"\n",
        "\n",
        "    sym_phrase = (\n",
        "        \"Strong symmetry steadies the eye.\"\n",
        "        if P[\"symmetry\"] > 0.8 else\n",
        "        \"Partial symmetry offers tension and interest.\"\n",
        "        if P[\"symmetry\"] > 0.5 else\n",
        "        \"Asymmetry keeps the image vibrant and alive.\"\n",
        "    )\n",
        "\n",
        "    # Illumination\n",
        "    light_phrase = (\n",
        "        f\"Light enters from about {int(I['light_direction_deg'])}°, shaping gentle tonal transitions.\"\n",
        "        if I[\"light_direction_deg\"] is not None\n",
        "        else \"Light spreads softly across the surface, creating atmospheric calm.\"\n",
        "    )\n",
        "\n",
        "    mood = (\n",
        "        \"bright and open\" if I[\"lightness_skew\"] > 0.5 else\n",
        "        \"quietly introspective\" if I[\"lightness_skew\"] < -0.5 else\n",
        "        \"balanced and contemplative\"\n",
        "    )\n",
        "\n",
        "    paragraph = (\n",
        "        f\"This painting unfolds with {tone}, featuring {contrast}. \"\n",
        "        f\"{texture_phrase} {comp_phrase} {sym_phrase} \"\n",
        "        f\"{light_phrase} The overall mood feels {mood}, \"\n",
        "        f\"encouraging a steady, unhurried gaze.\"\n",
        "    )\n",
        "\n",
        "    return paragraph\n",
        "### Fixed Black Analysis Panel (Legend + Summary)\n",
        "# ==========================================================\n",
        "def right_panel_black(H, C, T, P, I, strengths, paragraph):\n",
        "    \"\"\"Generates the fixed black side panel with legend, key metrics, and curatorial paragraph.\"\"\"\n",
        "    PANEL_W = 400\n",
        "    panel = np.zeros((H, PANEL_W, 3), np.uint8)\n",
        "    f = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    x, y, lh = 16, 28, 22\n",
        "\n",
        "    # Title\n",
        "    cv2.putText(panel, \"Analysis\", (x, y), f, 0.8, (255, 255, 255), 2)\n",
        "    y += lh + 6\n",
        "\n",
        "    # Legend\n",
        "    cv2.putText(panel, \"Legend\", (x, y), f, 0.7, (255, 255, 255), 1)\n",
        "    y += lh\n",
        "    swatches = [\n",
        "        ((x, y), (x+18, y+18), (0, 0, 255), \"Focal\"),\n",
        "        ((x, y+22), (x+18, y+40), (255, 0, 255), \"Subject\"),\n",
        "        ((x, y+44), (x+18, y+62), (0, 255, 255), \"Lines\"),\n",
        "        ((x, y+66), (x+18, y+84), (255, 128, 0), \"Texture\"),\n",
        "        ((x, y+88), (x+18, y+106), (255, 0, 255), \"ΔE\"),\n",
        "        ((x, y+110), (x+18, y+128), (255, 255, 255), \"Thirds\"),\n",
        "        ((x, y+132), (x+18, y+150), (0, 255, 255), \"Golden\"),\n",
        "        ((x, y+154), (x+18, y+172), (0, 150, 255), \"Light→\"),\n",
        "        ((x, y+176), (x+18, y+194), (0, 255, 255), \"Vanishing\"),\n",
        "    ]\n",
        "    for (p1, p2, col, label) in swatches:\n",
        "        cv2.rectangle(panel, p1, p2, col, -1)\n",
        "        cv2.putText(panel, label, (p2[0]+8, p2[1]-2), f, 0.55, (220, 220, 220), 1)\n",
        "    y += 196 + 16\n",
        "\n",
        "    # Caption helper\n",
        "    def note(strength, main):\n",
        "        return main if strength >= 0.08 else f\"{main} (weak / omitted visually)\"\n",
        "\n",
        "    captions = [\n",
        "        note(strengths['w_de'], f\"Color contrast: ΔE {C['mean_deltaE']:.1f}, {C['harmony']} harmony.\"),\n",
        "        note(strengths['w_tex'], f\"Texture anisotropy {T['gabor_anisotropy']:.2f}, dir {T['gabor_dom_angle']:.0f}°.\"),\n",
        "        note(strengths['w_sal'], \"Subject zone: central saliency focus.\"),\n",
        "        note(strengths['w_lines'], f\"Composition lines: {len(P['lines'])}, thirdsΔ {P['thirds_delta']:.3f}.\"),\n",
        "        note(strengths['w_light'], f\"Light: {I['light_direction_deg']}°, skew {I['lightness_skew']:.2f}.\")\n",
        "    ]\n",
        "\n",
        "    for cap in captions:\n",
        "        for line in textwrap.wrap(cap, width=42):\n",
        "            if y + lh + 10 >= H:\n",
        "                break\n",
        "            cv2.putText(panel, line, (x, y), f, 0.55, (200, 200, 200), 1)\n",
        "            y += lh\n",
        "        y += 6\n",
        "        if y >= H - 160:\n",
        "            break\n",
        "\n",
        "     # Add curatorial paragraph\n",
        "    para_lines = textwrap.wrap(paragraph, width=44)\n",
        "    y_para = min(y + 10, H - (len(para_lines) + 1) * lh - 8)\n",
        "    cv2.putText(panel, \"Curatorial Summary\", (x, y_para), f, 0.62, (255, 255, 255), 1)\n",
        "    y_para += lh\n",
        "    for pl in para_lines:\n",
        "        if y_para >= H - 6:\n",
        "            break\n",
        "        cv2.putText(panel, pl, (x, y_para), f, 0.55, (230, 230, 230), 1)\n",
        "        y_para += lh\n",
        "\n",
        "    return panel\n",
        "\n",
        "\n",
        "### BLOCK 8/8 — Output Generation & Main Pipeline\n",
        "# ==========================================================\n",
        "\n",
        "def analyze_artwork_v17(path, verbose=True, thorough=True):\n",
        "    \"\"\"Full dynamic analysis with individual visual outputs and clear progress updates.\"\"\"\n",
        "    start = time.time()\n",
        "    print(f\"🖼️ Loading image: {path}\")\n",
        "    img = load_rgb(path)\n",
        "    H0, W0 = img.shape[:2]\n",
        "    print(f\"   • Image size: {W0}×{H0}\")\n",
        "\n",
        "    # Rescale for fidelity\n",
        "    if thorough:\n",
        "        img, _ = resize_min_pixels(img, target_pixels=1_600_000)\n",
        "        H, W = img.shape[:2]\n",
        "        if (H, W) != (H0, W0):\n",
        "            print(f\"   • Rescaled for fidelity: {W}×{H}\")\n",
        "    else:\n",
        "        H, W = H0, W0\n",
        "\n",
        "    # Directory prep\n",
        "    out_dir = os.path.splitext(path)[0] + \"_analysis\"\n",
        "    ensure_dir(out_dir)\n",
        "\n",
        "    # ---- Analyses ----\n",
        "    print(\"🎨 Running color analysis…\", end=\" \"); C = color_analysis(img); print(\"✓\")\n",
        "    print(\"🪶 Running texture analysis…\", end=\" \"); T = gabor_pyramid(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)); print(\"✓\")\n",
        "    print(\"🔥 Running saliency analysis…\", end=\" \"); S = saliency_analysis(img); print(\"✓\")\n",
        "    print(\"📐 Running composition analysis…\", end=\" \"); P = composition_analysis(img, S['focal']); print(\"✓\")\n",
        "    print(\"💡 Running illumination analysis…\", end=\" \"); I = illumination_analysis(img); print(\"✓\")\n",
        "\n",
        "    # ---- Generate overlays ----\n",
        "    print(\"✨ Building visual overlays…\", end=\" \")\n",
        "    art_overlay, strengths = overlays_on_artwork(img, C, T, S, P, I)\n",
        "    print(\"✓\")\n",
        "\n",
        "    # ---- Curatorial summary ----\n",
        "    print(\"🖋️ Writing curatorial summary…\", end=\" \")\n",
        "    paragraph = curatorial_paragraph(dict(color=C, texture=T, composition=P, illumination=I))\n",
        "    print(\"✓\")\n",
        "\n",
        "    # ---- Generate right panel ----\n",
        "    panel = right_panel_black(art_overlay.shape[0], C, T, P, I, strengths, paragraph)\n",
        "    final = np.hstack([art_overlay, panel])\n",
        "    final = safe_gamma(final)\n",
        "\n",
        "    # ---- Save outputs ----\n",
        "    print(\"💾 Saving images…\", end=\" \")\n",
        "    out_final = os.path.join(out_dir, \"composite_full.png\")\n",
        "    cv2.imwrite(out_final, final)\n",
        "\n",
        "    # Individual analysis images\n",
        "    indiv = [\n",
        "        (\"color_overlay.png\", C, \"Color Analysis\", \"Shows chromatic clusters and ΔE contrast regions.\"),\n",
        "        (\"texture_overlay.png\", T, \"Texture Analysis\", \"Highlights directional energy and surface anisotropy.\"),\n",
        "        (\"saliency_overlay.png\", S, \"Saliency Map\", \"Visualizes attention-weighted subject areas.\"),\n",
        "        (\"composition_overlay.png\", P, \"Composition Analysis\", \"Shows detected structure and balance.\"),\n",
        "        (\"illumination_overlay.png\", I, \"Illumination Map\", \"Indicates light direction and tonal gradient.\")\n",
        "    ]\n",
        "    for fname, data, title, desc in indiv:\n",
        "        overlay, _ = overlays_on_artwork(img, C, T, S, P, I)\n",
        "        overlay = safe_gamma(overlay)\n",
        "        cv2.imwrite(os.path.join(out_dir, fname), overlay)\n",
        "    print(\"✓\")\n",
        "\n",
        "    # ---- Save summary and metrics ----\n",
        "    print(\"📄 Saving textual outputs…\", end=\" \")\n",
        "    with open(os.path.join(out_dir, \"curatorial_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(paragraph + \"\\n\")\n",
        "    with open(os.path.join(out_dir, \"metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(json_safe(dict(color=C, texture=T, saliency=S, composition=P, illumination=I, strengths=strengths)), f, indent=2)\n",
        "    print(\"✓\")\n",
        "\n",
        "    # ---- Wrap up ----\n",
        "    elapsed = time.time() - start\n",
        "    print(f\"\\n✅ Complete! Total runtime: {elapsed:.2f}s\")\n",
        "    print(f\"📁 Outputs saved in: {out_dir}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Run locally\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    IMAGE_PATH = \"/Users/alievanayasso/Documents/SlowMA/rbt.jpg\"\n",
        "    analyze_artwork_v17(IMAGE_PATH, verbose=True, thorough=True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
