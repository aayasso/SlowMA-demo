{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Analysis complete.\n",
            "Saved to: /Users/alievanayasso/Documents/SlowMA/Modigliani_analysis\n",
            "⏱️ Runtime: 11.61s\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# High-Fidelity Artwork Analyzer v12\n",
        "# ==========================================================\n",
        "# Local, fully dynamic, and saves:\n",
        "#   - overlay_final_composite.png\n",
        "#   - curatorial_summary.txt\n",
        "# ==========================================================\n",
        "\n",
        "import os, cv2, numpy as np, time, textwrap\n",
        "from PIL import Image\n",
        "from math import atan2, degrees\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Utility\n",
        "# ----------------------------------------------------------\n",
        "def load_rgb(path):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    return np.array(img)\n",
        "\n",
        "def ensure_dir(p): os.makedirs(p, exist_ok=True)\n",
        "def to_uint8(img): return np.clip(img*255.0,0,255).astype(np.uint8)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Color Analysis\n",
        "# ----------------------------------------------------------\n",
        "def analyze_color_opencv(img, k=6):\n",
        "    H,W=img.shape[:2]\n",
        "    lab=cv2.cvtColor(img,cv2.COLOR_RGB2LAB)\n",
        "    Z=lab.reshape(-1,3).astype(np.float32)\n",
        "    crit=(cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER,50,0.3)\n",
        "    _,labels,centers=cv2.kmeans(Z,k,None,crit,10,cv2.KMEANS_PP_CENTERS)\n",
        "    lbl2=labels.reshape(H,W)\n",
        "    rgb_centers=cv2.cvtColor(centers.reshape(-1,1,3).astype(np.uint8),cv2.COLOR_Lab2RGB).reshape(-1,3)\n",
        "    masks=[(lbl2==i).astype(np.uint8)*255 for i in range(k)]\n",
        "    a,b=centers[:,1]-128,centers[:,2]-128\n",
        "    hues=(np.degrees(np.arctan2(b,a))+360)%360\n",
        "    warm=((hues<90)|(hues>330)).sum()/len(hues)\n",
        "    cool=((hues>180)&(hues<300)).sum()/len(hues)\n",
        "    harmony=\"mixed\"\n",
        "    if np.ptp(hues)<35: harmony=\"analogous\"\n",
        "    elif any(abs(hues[i]-hues[j])%360>150 for i in range(len(hues)) for j in range(i+1,len(hues))):\n",
        "        harmony=\"complementary\"\n",
        "    mean_deltaE=float(np.mean(np.abs(np.diff(centers,axis=0))))\n",
        "    palette_entropy=float(-np.sum(np.histogram(labels,bins=k)[0]/(H*W)*np.log2(np.histogram(labels,bins=k)[0]/(H*W)+1e-6)))\n",
        "    return dict(\n",
        "        palette_rgb=[tuple(map(int,c)) for c in rgb_centers],\n",
        "        masks=masks,\n",
        "        color_variability=float(np.std(centers,0).mean()),\n",
        "        warm_ratio=float(warm),\n",
        "        cool_ratio=float(cool),\n",
        "        harmony=harmony,\n",
        "        mean_deltaE=mean_deltaE,\n",
        "        palette_entropy=palette_entropy\n",
        "    )\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Texture, Saliency, Composition, Illumination\n",
        "# ----------------------------------------------------------\n",
        "def analyze_texture(img):\n",
        "    g=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "    lap=cv2.Laplacian(g,cv2.CV_64F)\n",
        "    val=float(lap.var())\n",
        "    roughness=float(np.std(lap))\n",
        "    gabor_kernels=[cv2.getGaborKernel((15,15),3,np.pi/4*i,10,0.5,0,ktype=cv2.CV_32F) for i in range(4)]\n",
        "    responses=[cv2.filter2D(g,cv2.CV_32F,k)**2 for k in gabor_kernels]\n",
        "    anisotropy=float(np.std([r.mean() for r in responses])/np.mean([r.mean() for r in responses]+[1e-6]))\n",
        "    return dict(laplacian_var=val,gabor_anisotropy=anisotropy,lbp_roughness=roughness,lbp_entropy=np.log(val+1))\n",
        "\n",
        "def spectral_saliency(grayf):\n",
        "    fft=np.fft.fft2(grayf)\n",
        "    loga=np.log(np.abs(fft)+1e-8)\n",
        "    spec=np.exp((loga-cv2.blur(loga,(3,3)))+1j*np.angle(fft))\n",
        "    sal=np.abs(np.fft.ifft2(spec))**2\n",
        "    sal=cv2.GaussianBlur(sal,(9,9),2)\n",
        "    sal=(sal-sal.min())/(sal.max()-sal.min()+1e-6)\n",
        "    return (sal*255).astype(np.uint8)\n",
        "\n",
        "def subject_from_saliency(sal):\n",
        "    H,W=sal.shape\n",
        "    _,th=cv2.threshold(sal,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    cnts,_=cv2.findContours(th,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if cnts:\n",
        "        x,y,w,h=cv2.boundingRect(max(cnts,key=cv2.contourArea))\n",
        "    else: x,y,w,h=W//4,H//4,W//2,H//2\n",
        "    mask=np.zeros((H,W),np.uint8); cv2.rectangle(mask,(x,y),(x+w,y+h),255,-1)\n",
        "    return dict(mask=mask,bbox=(x,y,w,h))\n",
        "\n",
        "def analyze_saliency(img):\n",
        "    g=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY).astype(np.float32)\n",
        "    sal=spectral_saliency(g)\n",
        "    sub=subject_from_saliency(sal)\n",
        "    Y,X=np.indices(sal.shape); w=sal.astype(np.float32)+1\n",
        "    cx,cy=int((X*w).sum()/w.sum()),int((Y*w).sum()/w.sum())\n",
        "    return dict(saliency_map=sal,focal=(cx,cy),\n",
        "                subject_mask=sub[\"mask\"],subject_bbox=sub[\"bbox\"])\n",
        "\n",
        "def analyze_composition(img):\n",
        "    g=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "    H,W=g.shape; edges=cv2.Canny(g,100,200)\n",
        "    linesP=cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength=min(H,W)//10,maxLineGap=15)\n",
        "    lines=[tuple(map(int,l[0])) for l in linesP] if linesP is not None else []\n",
        "    lw,rw=float(np.sum(edges[:,:W//2])),float(np.sum(edges[:,W//2:]))\n",
        "    bal=(rw-lw)/(lw+rw+1e-6)\n",
        "    thirds_delta=abs(((W//3)-(W/2))/W)\n",
        "    golden_delta=abs((0.382*W - W/2)/W)\n",
        "    sym=float(np.mean(np.abs(g[:,::-1]-g)))\n",
        "    return dict(lines=lines,edge_balance=bal,thirds_delta=thirds_delta,\n",
        "                golden_delta=golden_delta,symmetry=sym,vanishing_point=(W//2,H//2))\n",
        "\n",
        "def illumination(img):\n",
        "    L=cv2.cvtColor(img,cv2.COLOR_RGB2LAB)[:,:,0].astype(np.float32)\n",
        "    mu,sig=L.mean(),L.std()+1e-6\n",
        "    skew=float((((L-mu)/sig)**3).mean())\n",
        "    gx,gy=cv2.Sobel(L,cv2.CV_32F,1,0),cv2.Sobel(L,cv2.CV_32F,0,1)\n",
        "    hi=(L>np.percentile(L,90)).astype(np.uint8)\n",
        "    if hi.sum()>0:\n",
        "        gx,gy=(gx*hi).sum(),(gy*hi).sum()\n",
        "        ang=float((degrees(atan2(-gy,-gx))+360)%360)\n",
        "    else: ang=None\n",
        "    return dict(lightness_skew=skew,light_direction_deg=ang)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Curatorial Text Generator\n",
        "# ----------------------------------------------------------\n",
        "def generate_curatorial_summary(metrics):\n",
        "    C, T, P, I = (metrics[\"color\"], metrics[\"texture\"],\n",
        "                  metrics[\"composition\"], metrics[\"illumination\"])\n",
        "\n",
        "    if C[\"harmony\"] == \"analogous\":\n",
        "        color_tone = \"a restrained palette of subtle continuity\"\n",
        "    elif C[\"harmony\"] == \"complementary\":\n",
        "        color_tone = \"a lively chromatic counterpoint\"\n",
        "    else:\n",
        "        color_tone = \"a flexible palette balancing contrast and unity\"\n",
        "\n",
        "    if C[\"mean_deltaE\"] > 25:\n",
        "        contrast_phrase = \"marked by strong contrasts\"\n",
        "    elif C[\"mean_deltaE\"] > 10:\n",
        "        contrast_phrase = \"balanced between tonal unity and variety\"\n",
        "    else:\n",
        "        contrast_phrase = \"gentle in its chromatic gradations\"\n",
        "\n",
        "    if T[\"gabor_anisotropy\"] > 0.5:\n",
        "        texture_line = \"The surface carries directional energy and gesture.\"\n",
        "    else:\n",
        "        texture_line = \"The surface remains smooth and tonally cohesive.\"\n",
        "\n",
        "    if abs(P[\"edge_balance\"]) < 0.1:\n",
        "        balance_phrase = \"Spatial balance remains grounded and stable.\"\n",
        "    else:\n",
        "        balance_phrase = \"The composition carries a deliberate asymmetry.\"\n",
        "\n",
        "    if I[\"light_direction_deg\"] is not None:\n",
        "        illum_phrase = f\"Light enters around {int(I['light_direction_deg'])}°, guiding focus.\"\n",
        "    else:\n",
        "        illum_phrase = \"Light diffuses evenly, maintaining tonal calm.\"\n",
        "\n",
        "    mood = \"Luminous\" if I[\"lightness_skew\"] > 0.3 else \"Somber\" if I[\"lightness_skew\"] < -0.3 else \"Balanced\"\n",
        "\n",
        "    micro_summary = textwrap.fill(\n",
        "        f\"Color: {C['harmony']} harmony (ΔE≈{C['mean_deltaE']:.1f}), \"\n",
        "        f\"Texture variance {T['laplacian_var']:.1f}, \"\n",
        "        f\"Anisotropy {T['gabor_anisotropy']:.2f}, \"\n",
        "        f\"Composition balance {P['edge_balance']:.2f}, \"\n",
        "        f\"Light direction {I['light_direction_deg']}.\",\n",
        "        width=85\n",
        "    )\n",
        "\n",
        "    curatorial = textwrap.fill(\n",
        "        f\"This work reveals {color_tone}, {contrast_phrase}. \"\n",
        "        f\"{texture_line} {balance_phrase} {illum_phrase} \"\n",
        "        f\"The overall mood is {mood.lower()}, \"\n",
        "        f\"suggesting a deliberate interplay of control and emotion. \"\n",
        "        f\"The artist invites a slow, attentive gaze — \"\n",
        "        f\"a chance to notice how color, gesture, and structure breathe together.\",\n",
        "        width=85\n",
        "    )\n",
        "\n",
        "    return micro_summary, curatorial\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Visualization\n",
        "# ----------------------------------------------------------\n",
        "def make_composite(img, metrics):\n",
        "    base = img.astype(np.float32) / 255.0\n",
        "    H, W = base.shape[:2]\n",
        "\n",
        "    # --- Laplacian texture intensity ---\n",
        "    g = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap = np.abs(cv2.Laplacian(g, cv2.CV_32F))\n",
        "    lap = cv2.normalize(lap, None, 0, 1, cv2.NORM_MINMAX)\n",
        "\n",
        "    # --- Saliency map normalization ---\n",
        "    sal = metrics[\"saliency\"][\"saliency_map\"].astype(np.float32)\n",
        "    sal = cv2.resize(sal, (W, H))\n",
        "    sal = cv2.normalize(sal, None, 0, 1, cv2.NORM_MINMAX)\n",
        "\n",
        "    # --- Create matched 3-channel layers ---\n",
        "    zeros = np.zeros((H, W), np.float32)\n",
        "    tex_layer = np.dstack([lap * 0.7, lap * 0.3, zeros]) * 0.3\n",
        "    sal_layer = np.dstack([sal * 0.4, sal * 0.1, sal * 0.1]) * 0.3\n",
        "\n",
        "    # --- Blend base with overlays ---\n",
        "    comp = base * 0.9 + tex_layer + sal_layer\n",
        "    comp = np.clip(comp, 0, 1)\n",
        "\n",
        "    # --- Draw subject contour and focal point ---\n",
        "    mask = metrics[\"saliency\"][\"subject_mask\"]\n",
        "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    comp_bgr = (comp[:, :, ::-1] * 255).astype(np.uint8).copy()\n",
        "\n",
        "    if cnts:\n",
        "        cv2.drawContours(comp_bgr, cnts, -1, (255, 0, 255), 2)\n",
        "    fx, fy = metrics[\"saliency\"][\"focal\"]\n",
        "    cv2.circle(comp_bgr, (int(fx), int(fy)), 6, (0, 0, 255), -1)\n",
        "\n",
        "    return comp_bgr\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Pipeline\n",
        "# ----------------------------------------------------------\n",
        "def analyze_artwork_high_fidelity(path):\n",
        "    start=time.time()\n",
        "    img=load_rgb(path)\n",
        "    color=analyze_color_opencv(img)\n",
        "    texture=analyze_texture(img)\n",
        "    sal=analyze_saliency(img)\n",
        "    comp=analyze_composition(img)\n",
        "    illum=illumination(img)\n",
        "    metrics=dict(color=color,texture=texture,saliency=sal,composition=comp,illumination=illum)\n",
        "\n",
        "    out_dir=os.path.splitext(path)[0]+\"_analysis\"\n",
        "    ensure_dir(out_dir)\n",
        "\n",
        "    # composite\n",
        "    compo=make_composite(img,metrics)\n",
        "    out_png=os.path.join(out_dir,\"overlay_final_composite.png\")\n",
        "    cv2.imwrite(out_png,compo)\n",
        "\n",
        "    # text\n",
        "    micro,curatorial=generate_curatorial_summary(metrics)\n",
        "    out_txt=os.path.join(out_dir,\"curatorial_summary.txt\")\n",
        "    with open(out_txt,\"w\") as f:\n",
        "        f.write(\"--- MICRO SUMMARY ---\\n\")\n",
        "        f.write(micro+\"\\n\\n--- CURATORIAL SUMMARY ---\\n\")\n",
        "        f.write(curatorial)\n",
        "\n",
        "    print(f\"\\n✅ Analysis complete.\\nSaved to: {out_dir}\\n⏱️ Runtime: {time.time()-start:.2f}s\")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Run Example\n",
        "# ----------------------------------------------------------\n",
        "if __name__==\"__main__\":\n",
        "    IMAGE_PATH=\"/Users/alievanayasso/Documents/SlowMA/Modigliani.jpg\"\n",
        "    analyze_artwork_high_fidelity(IMAGE_PATH)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
